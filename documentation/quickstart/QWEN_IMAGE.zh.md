## Qwen Image å¿«é€Ÿå…¥é—¨

> ğŸ†• æƒ³è¦ç¼–è¾‘æ£€æŸ¥ç‚¹ï¼Ÿè¯·å‚é˜… [Qwen Image Edit å¿«é€Ÿå…¥é—¨](./QWEN_EDIT.md) è·å–æˆå¯¹å‚è€ƒè®­ç»ƒè¯´æ˜ã€‚

æœ¬ç¤ºä¾‹å°†è®­ç»ƒ Qwen Image çš„ LoRAã€‚Qwen Image æ˜¯ä¸€ä¸ª 20B å‚æ•°çš„è§†è§‰è¯­è¨€æ¨¡å‹ã€‚ç”±äºä½“ç§¯å¾ˆå¤§ï¼Œéœ€è¦é‡‡ç”¨æ¿€è¿›çš„å†…å­˜ä¼˜åŒ–ã€‚

24GB GPU æ˜¯æœ€ä½é…ç½®ï¼Œå³ä¾¿å¦‚æ­¤ä¹Ÿéœ€è¦å¤§é‡é‡åŒ–å’Œè°¨æ…é…ç½®ã€‚å»ºè®® 40GB+ ä»¥è·å¾—æ›´é¡ºç•…ä½“éªŒã€‚

åœ¨ 24G ä¸Šè®­ç»ƒæ—¶ï¼ŒéªŒè¯å¯èƒ½ä¼š OOMï¼Œé™¤éé™ä½åˆ†è¾¨ç‡æˆ–ä½¿ç”¨æ¯” int8 æ›´æ¿€è¿›çš„é‡åŒ–ã€‚

### ç¡¬ä»¶è¦æ±‚

Qwen Image æ˜¯ä¸€ä¸ª 20B å‚æ•°æ¨¡å‹ï¼Œä»…æ–‡æœ¬ç¼–ç å™¨åœ¨é‡åŒ–å‰å°±æ¶ˆè€— ~16GB VRAMã€‚æ¨¡å‹ä½¿ç”¨è‡ªå®šä¹‰ 16 é€šé“ VAEã€‚

**é‡è¦é™åˆ¶ï¼š**
- **ä¸æ”¯æŒ AMD ROCm æˆ– MacOS**ï¼ˆç¼ºä¹é«˜æ•ˆçš„ Flash Attentionï¼‰
- æ‰¹å¤§å° > 1 ç›®å‰æ— æ³•æ­£ç¡®è¿è¡Œï¼›è¯·ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
- TREADï¼ˆText-Representation Enhanced Adversarial Diffusionï¼‰å°šä¸æ”¯æŒ

### å‰ææ¡ä»¶

ç¡®ä¿å·²å®‰è£… Pythonï¼›SimpleTuner åœ¨ 3.10 åˆ° 3.12 ç‰ˆæœ¬ä¸Šè¿è¡Œè‰¯å¥½ã€‚

æ‚¨å¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤æ£€æŸ¥ï¼š

```bash
python --version
```

å¦‚æœæ‚¨çš„ Ubuntu ç³»ç»Ÿæœªå®‰è£… Python 3.12ï¼Œå¯ä»¥å°è¯•ä»¥ä¸‹å‘½ä»¤ï¼š

```bash
apt -y install python3.12 python3.12-venv
```

#### å®¹å™¨é•œåƒä¾èµ–

å¯¹äº Vastã€RunPod å’Œ TensorDockï¼ˆä»¥åŠå…¶ä»–å¹³å°ï¼‰ï¼Œåœ¨ CUDA 12.2-12.8 é•œåƒä¸Šå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯ç”¨ CUDA æ‰©å±•ç¼–è¯‘ï¼š

```bash
apt -y install nvidia-cuda-toolkit
```

### å®‰è£…

é€šè¿‡ pip å®‰è£… SimpleTunerï¼š

```bash
pip install simpletuner[cuda]
```

å¦‚éœ€æ‰‹åŠ¨å®‰è£…æˆ–å¼€å‘ç¯å¢ƒè®¾ç½®ï¼Œè¯·å‚é˜…[å®‰è£…æ–‡æ¡£](../INSTALL.md)ã€‚

### è®¾ç½®ç¯å¢ƒ

è¦è¿è¡Œ SimpleTunerï¼Œæ‚¨éœ€è¦è®¾ç½®é…ç½®æ–‡ä»¶ã€æ•°æ®é›†å’Œæ¨¡å‹ç›®å½•ï¼Œä»¥åŠæ•°æ®åŠ è½½å™¨é…ç½®æ–‡ä»¶ã€‚

#### é…ç½®æ–‡ä»¶

ä¸€ä¸ªå®éªŒæ€§è„šæœ¬ `configure.py` å¯èƒ½é€šè¿‡äº¤äº’å¼çš„é€æ­¥é…ç½®è®©æ‚¨å®Œå…¨è·³è¿‡æœ¬èŠ‚ã€‚å®ƒåŒ…å«ä¸€äº›å®‰å…¨åŠŸèƒ½ï¼Œæœ‰åŠ©äºé¿å…å¸¸è§é™·é˜±ã€‚

**æ³¨æ„ï¼š**è¿™ä¸ä¼šé…ç½®æ‚¨çš„æ•°æ®åŠ è½½å™¨ã€‚æ‚¨ç¨åä»éœ€æ‰‹åŠ¨é…ç½®ã€‚

è¿è¡Œæ–¹å¼ï¼š

```bash
simpletuner configure
```

> âš ï¸ å¯¹äºä½äº Hugging Face Hub è®¿é—®å—é™å›½å®¶çš„ç”¨æˆ·ï¼Œæ‚¨åº”è¯¥æ ¹æ®ç³»ç»Ÿä½¿ç”¨çš„ `$SHELL` å°† `HF_ENDPOINT=https://hf-mirror.com` æ·»åŠ åˆ° `~/.bashrc` æˆ– `~/.zshrc` ä¸­ã€‚

å¦‚æœæ‚¨æ›´å–œæ¬¢æ‰‹åŠ¨é…ç½®ï¼š

å°† `config/config.json.example` å¤åˆ¶ä¸º `config/config.json`ï¼š

```bash
cp config/config.json.example config/config.json
```

æ‚¨å¯èƒ½éœ€è¦ä¿®æ”¹ä»¥ä¸‹å˜é‡ï¼š

- `model_type` - è®¾ç½®ä¸º `lora`ã€‚
- `lora_type` - PEFT LoRA è®¾ä¸º `standard`ï¼ŒLoKr è®¾ä¸º `lycoris`ã€‚
- `model_family` - è®¾ç½®ä¸º `qwen_image`ã€‚
- `model_flavour` - è®¾ç½®ä¸º `v1.0`ã€‚
- `output_dir` - è®¾ç½®ä¸ºæ‚¨æƒ³è¦å­˜å‚¨æ£€æŸ¥ç‚¹å’ŒéªŒè¯å›¾åƒçš„ç›®å½•ã€‚å»ºè®®ä½¿ç”¨å®Œæ•´è·¯å¾„ã€‚
- `train_batch_size` - å¿…é¡»ä¸º 1ï¼ˆæ‰¹å¤§å° > 1 ç›®å‰æ— æ³•æ­£ç¡®å·¥ä½œï¼‰ã€‚
- `gradient_accumulation_steps` - è®¾ä¸º 2-8 æ¨¡æ‹Ÿæ›´å¤§ batchã€‚
- `validation_resolution` - å»ºè®® `1024x1024` æˆ–æ›´ä½ï¼Œä»¥é€‚åº”å†…å­˜é™åˆ¶ã€‚
  - 24G æ— æ³•å¤„ç† 1024x1024 éªŒè¯ï¼Œéœ€è¦é™ä½å°ºå¯¸
  - å…¶ä»–åˆ†è¾¨ç‡å¯ç”¨é€—å·åˆ†éš”ï¼š`1024x1024,768x768,512x512`
- `validation_guidance` - ä½¿ç”¨ 3.0-4.0 å·¦å³ã€‚
- `validation_num_inference_steps` - çº¦ 30ã€‚
- `use_ema` - è®¾ä¸º `true` å¯è·å¾—æ›´å¹³æ»‘çš„ç»“æœï¼Œä½†ä¼šå ç”¨æ›´å¤šå†…å­˜ã€‚

- `optimizer` - æ¨è `optimi-lion`ï¼Œå¦‚æœ‰ä½™é‡å¯ç”¨ `adamw-bf16`ã€‚
- `mixed_precision` - Qwen Image å¿…é¡»è®¾ä¸º `bf16`ã€‚
- `gradient_checkpointing` - **å¿…é¡»**å¯ç”¨ï¼ˆ`true`ï¼‰ä»¥è·å¾—åˆç†å†…å­˜å ç”¨ã€‚
- `base_model_precision` - **å¼ºçƒˆæ¨è**è®¾ä¸º `int8-quanto` æˆ– `nf4-bnb`ï¼ˆ24GB æ˜¾å¡ï¼‰ã€‚
- `quantize_via` - è®¾ä¸º `cpu`ï¼Œé¿å…å°æ˜¾å¡é‡åŒ–æ—¶ OOMã€‚
- `quantize_activations` - ä¿æŒ `false` ä»¥ç»´æŒè®­ç»ƒè´¨é‡ã€‚

24GB GPU çš„å†…å­˜ä¼˜åŒ–å»ºè®®ï¼š
- `lora_rank` - ä½¿ç”¨ 8 æˆ–æ›´ä½ã€‚
- `lora_alpha` - ä¸ lora_rank ç›¸åŒã€‚
- `flow_schedule_shift` - è®¾ä¸º 1.73ï¼ˆæˆ–åœ¨ 1.0-3.0 é—´æ¢ç´¢ï¼‰ã€‚

æœ€å°é…ç½®ç¤ºä¾‹ï¼š

<details>
<summary>æŸ¥çœ‹ç¤ºä¾‹é…ç½®</summary>

```json
{
    "model_type": "lora",
    "model_family": "qwen_image",
    "model_flavour": "v1.0",
    "lora_type": "standard",
    "lora_rank": 8,
    "lora_alpha": 8,
    "output_dir": "output/models-qwen_image",
    "train_batch_size": 1,
    "gradient_accumulation_steps": 4,
    "validation_resolution": "1024x1024",
    "validation_guidance": 4.0,
    "validation_num_inference_steps": 30,
    "validation_seed": 42,
    "validation_prompt": "A photo-realistic image of a cat",
    "validation_step_interval": 100,
    "vae_batch_size": 1,
    "seed": 42,
    "resume_from_checkpoint": "latest",
    "resolution": 1024,
    "resolution_type": "pixel_area",
    "report_to": "tensorboard",
    "optimizer": "optimi-lion",
    "num_train_epochs": 0,
    "num_eval_images": 1,
    "mixed_precision": "bf16",
    "minimum_image_size": 0,
    "max_train_steps": 1000,
    "max_grad_norm": 0.01,
    "lr_warmup_steps": 100,
    "lr_scheduler": "constant_with_warmup",
    "learning_rate": "1e-4",
    "gradient_checkpointing": "true",
    "base_model_precision": "int2-quanto",
    "quantize_via": "cpu",
    "quantize_activations": false,
    "flow_schedule_shift": 1.73,
    "disable_benchmark": false,
    "data_backend_config": "config/qwen_image/multidatabackend.json",
    "checkpoints_total_limit": 5,
    "checkpoint_step_interval": 500,
    "caption_dropout_probability": 0.0,
    "aspect_bucket_rounding": 2
}
```
</details>

> â„¹ï¸ å¤š GPU ç”¨æˆ·å¯å‚è€ƒ[æ­¤æ–‡æ¡£](../OPTIONS.md#environment-configuration-variables)äº†è§£ GPU æ•°é‡é…ç½®ã€‚

> âš ï¸ **24GB GPU å…³é”®ç‚¹**ï¼šä»…æ–‡æœ¬ç¼–ç å™¨å°±éœ€ ~16GB VRAMã€‚`int2-quanto` æˆ– `nf4-bnb` å¯å¤§å¹…é™ä½ã€‚

å¿«é€ŸéªŒè¯å¯ç”¨ä»¥ä¸‹å·²çŸ¥é…ç½®ï¼š

**é€‰é¡¹ 1ï¼ˆæ¨è - pip å®‰è£…ï¼‰ï¼š**
```bash
pip install simpletuner[cuda]
simpletuner train example=qwen_image.peft-lora
```

**é€‰é¡¹ 2ï¼ˆGit clone æ–¹å¼ï¼‰ï¼š**
```bash
simpletuner train env=examples/qwen_image.peft-lora
```

**é€‰é¡¹ 3ï¼ˆLegacy æ–¹å¼ - ä»å¯ç”¨ï¼‰ï¼š**
```bash
ENV=examples/qwen_image.peft-lora ./train.sh
```

### é«˜çº§å®éªŒåŠŸèƒ½

<details>
<summary>æ˜¾ç¤ºé«˜çº§å®éªŒè¯¦æƒ…</summary>


SimpleTuner åŒ…å«å¯æ˜¾è‘—æé«˜è®­ç»ƒç¨³å®šæ€§å’Œæ€§èƒ½çš„å®éªŒåŠŸèƒ½ã€‚

*   **[è®¡åˆ’é‡‡æ ·ï¼ˆRolloutï¼‰](../experimental/SCHEDULED_SAMPLING.md)ï¼š**é€šè¿‡è®©æ¨¡å‹åœ¨è®­ç»ƒæœŸé—´ç”Ÿæˆè‡ªå·±çš„è¾“å…¥æ¥å‡å°‘æ›å…‰åå·®å¹¶æé«˜è¾“å‡ºè´¨é‡ã€‚

> âš ï¸ è¿™äº›åŠŸèƒ½ä¼šå¢åŠ è®­ç»ƒçš„è®¡ç®—å¼€é”€ã€‚

#### éªŒè¯æç¤ºè¯

`config/config.json` ä¸­åŒ…å«â€œä¸»éªŒè¯æç¤ºè¯â€ï¼Œé€šå¸¸ä¸ºä½ æ­£åœ¨è®­ç»ƒçš„ä¸»ä½“æˆ–é£æ ¼çš„ instance_promptã€‚æ­¤å¤–ï¼Œå¯åˆ›å»ºä¸€ä¸ª JSON æ–‡ä»¶åŒ…å«é¢å¤–éªŒè¯æç¤ºè¯ã€‚

ç¤ºä¾‹é…ç½®æ–‡ä»¶ `config/user_prompt_library.json.example` æ ¼å¼å¦‚ä¸‹ï¼š

```json
{
  "nickname": "the prompt goes here",
  "another_nickname": "another prompt goes here"
}
```

æ˜µç§°å°†ä½œä¸ºéªŒè¯æ–‡ä»¶åï¼Œè¯·ä¿æŒç®€çŸ­å¹¶ä¸æ–‡ä»¶ç³»ç»Ÿå…¼å®¹ã€‚

è¦è®©è®­ç»ƒå™¨ä½¿ç”¨è¯¥æç¤ºè¯åº“ï¼Œè¯·åœ¨ config.json ä¸­æ·»åŠ ï¼š
```json
  "validation_prompt_library": "config/user_prompt_library.json",
```

å¤šæ ·åŒ–æç¤ºè¯æœ‰åŠ©äºåˆ¤æ–­æ¨¡å‹æ˜¯å¦åœ¨æ­£å¸¸å­¦ä¹ ï¼š

```json
{
    "anime_style": "a breathtaking anime-style portrait with vibrant colors and expressive features",
    "chef_cooking": "a high-quality, detailed photograph of a sous-chef immersed in culinary creation",
    "portrait": "a lifelike and intimate portrait showcasing unique personality and charm",
    "cinematic": "a cinematic, visually stunning photo with dramatic and captivating presence",
    "elegant": "an elegant and timeless portrait exuding grace and sophistication",
    "adventurous": "a dynamic and adventurous photo captured in an exciting moment",
    "mysterious": "a mysterious and enigmatic portrait shrouded in shadows and intrigue",
    "vintage": "a vintage-style portrait evoking the charm and nostalgia of a bygone era",
    "artistic": "an artistic and abstract representation blending creativity with visual storytelling",
    "futuristic": "a futuristic and cutting-edge portrayal set against advanced technology"
}
```

#### CLIP åˆ†æ•°è·Ÿè¸ª

å¦‚éœ€å¯ç”¨è¯„ä¼°ä»¥è¯„åˆ†æ¨¡å‹æ€§èƒ½ï¼Œè¯·å‚é˜…[æ­¤æ–‡æ¡£](../evaluation/CLIP_SCORES.md)ã€‚

#### ç¨³å®šè¯„ä¼°æŸå¤±

å¦‚éœ€ä½¿ç”¨ç¨³å®šçš„ MSE æŸå¤±è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼Œè¯·å‚é˜…[æ­¤æ–‡æ¡£](../evaluation/EVAL_LOSS.md)ã€‚

#### éªŒè¯é¢„è§ˆ

SimpleTuner æ”¯æŒä½¿ç”¨ Tiny AutoEncoder åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­æµå¼è¾“å‡ºä¸­é—´éªŒè¯é¢„è§ˆã€‚è¿™æ ·å¯ä»¥é€šè¿‡ webhook å›è°ƒå®æ—¶æŸ¥çœ‹é€æ­¥ç”Ÿæˆçš„éªŒè¯å›¾åƒã€‚

å¯ç”¨æ–¹å¼ï¼š
```json
{
  "validation_preview": true,
  "validation_preview_steps": 1
}
```

**è¦æ±‚ï¼š**
- Webhook é…ç½®
- éªŒè¯å·²å¯ç”¨

å°† `validation_preview_steps` æé«˜ï¼ˆä¾‹å¦‚ 3 æˆ– 5ï¼‰å¯é™ä½ Tiny AutoEncoder å¼€é”€ã€‚è‹¥ `validation_num_inference_steps=20` ä¸” `validation_preview_steps=5`ï¼Œä½ ä¼šåœ¨ç¬¬ 5ã€10ã€15ã€20 æ­¥æ”¶åˆ°é¢„è§ˆå›¾ã€‚

#### Flow schedule shifting

Qwen Image æ˜¯æµåŒ¹é…æ¨¡å‹ï¼Œæ”¯æŒé€šè¿‡æ—¶é—´è¡¨åç§»æ¥æ§åˆ¶è®­ç»ƒè¦†ç›–çš„ç”Ÿæˆè¿‡ç¨‹éƒ¨åˆ†ã€‚

`flow_schedule_shift` å‚æ•°æ§åˆ¶ï¼š
- è¾ƒä½å€¼ï¼ˆ0.1-1.0ï¼‰ï¼šå…³æ³¨ç»†èŠ‚
- ä¸­ç­‰å€¼ï¼ˆ1.0-3.0ï¼‰ï¼šå¹³è¡¡è®­ç»ƒï¼ˆæ¨èï¼‰
- è¾ƒé«˜å€¼ï¼ˆ3.0-6.0ï¼‰ï¼šå…³æ³¨å¤§æ„å›¾ç‰¹å¾

##### è‡ªåŠ¨åç§»

å¯å¯ç”¨åˆ†è¾¨ç‡ç›¸å…³æ—¶é—´æ­¥åç§» `--flow_schedule_auto_shift`ã€‚å®ƒå¯¹å¤§å›¾ä½¿ç”¨æ›´é«˜ shift å€¼ï¼Œå¯¹å°å›¾ä½¿ç”¨æ›´ä½å€¼ï¼Œç»“æœæ›´ç¨³å®šä½†å¯èƒ½è¾ƒä¸ºä¸­åº¸ã€‚

##### æ‰‹åŠ¨æŒ‡å®š

`--flow_schedule_shift` çš„èµ·å§‹æ¨èå€¼ä¸º 1.73ï¼Œä½†éœ€æ ¹æ®æ•°æ®é›†å’Œç›®æ ‡è‡ªè¡Œè°ƒæ•´ã€‚

#### æ•°æ®é›†æ³¨æ„äº‹é¡¹

æ¨¡å‹è®­ç»ƒéœ€è¦è¶³å¤Ÿå¤§çš„æ•°æ®é›†ã€‚æ•°æ®é›†è§„æ¨¡å­˜åœ¨é™åˆ¶ï¼Œä½ å¿…é¡»ç¡®ä¿æ•°æ®é›†è¶³å¤Ÿå¤§æ‰èƒ½æœ‰æ•ˆè®­ç»ƒæ¨¡å‹ã€‚

> â„¹ï¸ è‹¥å›¾åƒè¿‡å°‘ï¼Œå¯èƒ½å‡ºç° **no images detected in dataset** æç¤ºâ€”â€”å¢åŠ  `repeats` å€¼å¯è§£å†³ã€‚

> âš ï¸ **é‡è¦**ï¼šç”±äºå½“å‰é™åˆ¶ï¼Œè¯·ä¿æŒ `train_batch_size` ä¸º 1ï¼Œç”¨ `gradient_accumulation_steps` æ¨¡æ‹Ÿæ›´å¤§ batchã€‚

åˆ›å»º `--data_backend_config`ï¼ˆ`config/multidatabackend.json`ï¼‰æ–‡æ¡£å¦‚ä¸‹ï¼š

```json
[
  {
    "id": "pseudo-camera-10k-qwen",
    "type": "local",
    "crop": true,
    "crop_aspect": "square",
    "crop_style": "center",
    "resolution": 1024,
    "minimum_image_size": 512,
    "maximum_image_size": 1024,
    "target_downsample_size": 1024,
    "resolution_type": "pixel_area",
    "cache_dir_vae": "cache/vae/qwen_image/pseudo-camera-10k",
    "instance_data_dir": "datasets/pseudo-camera-10k",
    "disabled": false,
    "skip_file_discovery": "",
    "caption_strategy": "filename",
    "metadata_backend": "discovery",
    "repeats": 0,
    "is_regularisation_data": true
  },
  {
    "id": "dreambooth-subject",
    "type": "local",
    "crop": false,
    "resolution": 1024,
    "minimum_image_size": 512,
    "maximum_image_size": 1024,
    "target_downsample_size": 1024,
    "resolution_type": "pixel_area",
    "cache_dir_vae": "cache/vae/qwen_image/dreambooth-subject",
    "instance_data_dir": "datasets/dreambooth-subject",
    "caption_strategy": "instanceprompt",
    "instance_prompt": "the name of your subject goes here",
    "metadata_backend": "discovery",
    "repeats": 1000
  },
  {
    "id": "text-embeds",
    "type": "local",
    "dataset_type": "text_embeds",
    "default": true,
    "cache_dir": "cache/text/qwen_image",
    "disabled": false,
    "write_batch_size": 16
  }
]
```

> â„¹ï¸ å¦‚æœä½ æœ‰åŒ…å« caption çš„ `.txt` æ–‡ä»¶ï¼Œè¯·ä½¿ç”¨ `caption_strategy=textfile`ã€‚
> See caption_strategy options and requirements in [DATALOADER.md](../DATALOADER.md#caption_strategy).
> â„¹ï¸ æ³¨æ„ text embeds ä½¿ç”¨è¾ƒå°çš„ `write_batch_size` ä»¥é¿å… OOMã€‚

ç„¶ååˆ›å»º `datasets` ç›®å½•ï¼š

```bash
mkdir -p datasets
pushd datasets
    huggingface-cli download --repo-type=dataset bghira/pseudo-camera-10k --local-dir=pseudo-camera-10k
    mkdir dreambooth-subject
    # place your images into dreambooth-subject/ now
popd
```

è¿™å°†æŠŠçº¦ 10k å¼ ç…§ç‰‡æ ·æœ¬ä¸‹è½½åˆ° `datasets/pseudo-camera-10k` ç›®å½•ï¼Œå¹¶è‡ªåŠ¨åˆ›å»ºã€‚

Dreambooth å›¾ç‰‡åº”æ”¾åˆ° `datasets/dreambooth-subject`ã€‚

#### ç™»å½• WandB ä¸ Huggingface Hub

åœ¨è®­ç»ƒå¼€å§‹å‰ç™»å½• WandB ä¸ HF Hubï¼Œå°¤å…¶å½“ä½ ä½¿ç”¨ `--push_to_hub` å’Œ `--report_to=wandb` æ—¶ã€‚

å¦‚æœæ‰‹åŠ¨æ¨é€åˆ° Git LFS ä»“åº“ï¼Œè¿˜åº”è¿è¡Œ `git config --global credential.helper store`ã€‚

è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

```bash
wandb login
```

ä»¥åŠ

```bash
huggingface-cli login
```

æŒ‰æç¤ºå®Œæˆç™»å½•ã€‚

</details>

### æ‰§è¡Œè®­ç»ƒ

åœ¨ SimpleTuner ç›®å½•ä¸­ï¼Œç›´æ¥è¿è¡Œï¼š

```bash
./train.sh
```

è¿™å°†å¼€å§‹å°†æ–‡æœ¬åµŒå…¥ä¸ VAE è¾“å‡ºç¼“å­˜åˆ°ç£ç›˜ã€‚

æ›´å¤šä¿¡æ¯è¯·å‚é˜… [dataloader](../DATALOADER.md) å’Œ [tutorial](../TUTORIAL.md) æ–‡æ¡£ã€‚

### å†…å­˜ä¼˜åŒ–å»ºè®®

#### æœ€ä½ VRAM é…ç½®ï¼ˆ24GB æœ€ä½ï¼‰

Qwen Image çš„æœ€ä½ VRAM é…ç½®çº¦ä¸º 24GBï¼š

- OS: Ubuntu Linux 24
- GPU: å•å¼  NVIDIA CUDAï¼ˆè‡³å°‘ 24GBï¼‰
- ç³»ç»Ÿå†…å­˜: å»ºè®® 64GB+
- åŸºç¡€æ¨¡å‹ç²¾åº¦:
  - NVIDIA ç³»ç»Ÿï¼š`int2-quanto` æˆ– `nf4-bnb`ï¼ˆ24GB å¿…éœ€ï¼‰
  - `int4-quanto` å¯ç”¨ä½†è´¨é‡å¯èƒ½æ›´ä½
- ä¼˜åŒ–å™¨ï¼š`optimi-lion` æˆ– `bnb-lion8bit-paged` æ›´çœå†…å­˜
- åˆ†è¾¨ç‡ï¼šå…ˆç”¨ 512px æˆ– 768pxï¼Œå†…å­˜å…è®¸å†å‡åˆ° 1024px
- æ‰¹å¤§å°ï¼š1ï¼ˆå½“å‰é™åˆ¶ï¼‰
- æ¢¯åº¦ç´¯ç§¯ï¼š2-8 æ¨¡æ‹Ÿæ›´å¤§ batch
- å¯ç”¨ `--gradient_checkpointing`ï¼ˆå¿…éœ€ï¼‰
- ä½¿ç”¨ `--quantize_via=cpu` é¿å…å¯åŠ¨ OOM
- ä½¿ç”¨è¾ƒå° LoRA rankï¼ˆ1-8ï¼‰
- è®¾ç½®ç¯å¢ƒå˜é‡ `PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True` æœ‰åŠ©äºå‡å°‘ VRAM

**æ³¨æ„**ï¼šé¢„ç¼“å­˜ VAE åµŒå…¥ä¸æ–‡æœ¬ç¼–ç å™¨è¾“å‡ºä¼šå ç”¨å¤§é‡å†…å­˜ã€‚è‹¥ OOMï¼Œå¯å¯ç”¨ `offload_during_startup=true`ã€‚

### è®­ç»ƒåçš„ LoRA æ¨ç†

ç”±äº Qwen Image æ˜¯æ–°æ¨¡å‹ï¼Œä»¥ä¸‹ä¸ºå¯ç”¨æ¨ç†ç¤ºä¾‹ï¼š

<details>
<summary>Show Python inference example</summary>

```python
import torch
from diffusers import QwenImagePipeline, QwenImageTransformer2DModel
from transformers import Qwen2Tokenizer, Qwen2_5_VLForConditionalGeneration

model_id = 'Qwen/Qwen-Image'
adapter_id = 'your-username/your-lora-name'

# Load the pipeline
pipeline = QwenImagePipeline.from_pretrained(
    model_id,
    torch_dtype=torch.bfloat16
)

# Load LoRA weights
pipeline.load_lora_weights(adapter_id)

# Optional: quantize the model to save VRAM
from optimum.quanto import quantize, freeze, qint8
quantize(pipeline.transformer, weights=qint8)
freeze(pipeline.transformer)

# Move to device
pipeline.to('cuda' if torch.cuda.is_available() else 'cpu')

# Generate an image
prompt = "Your test prompt here"
negative_prompt = 'ugly, cropped, blurry, low-quality, mediocre average'

image = pipeline(
    prompt=prompt,
    negative_prompt=negative_prompt,
    num_inference_steps=30,
    guidance_scale=4.0,
    generator=torch.Generator(device='cuda').manual_seed(42),
    width=1024,
    height=1024,
).images[0]

image.save("output.png", format="PNG")
```
</details>

### æ³¨æ„äº‹é¡¹ä¸æ’é”™æç¤º

#### æ‰¹å¤§å°é™åˆ¶

ç”±äºæ–‡æœ¬ç¼–ç å™¨çš„åºåˆ—é•¿åº¦å¤„ç†é—®é¢˜ï¼ŒQwen Image å½“å‰æ— æ³•ä½¿ç”¨æ‰¹å¤§å° > 1ã€‚è¯·å§‹ç»ˆä½¿ç”¨ï¼š
- `train_batch_size: 1`
- `gradient_accumulation_steps: 2-8` æ¨¡æ‹Ÿæ›´å¤§ batch

#### é‡åŒ–

- `int2-quanto` å†…å­˜èŠ‚çœæœ€å¤šï¼Œä½†å¯èƒ½å½±å“è´¨é‡
- `nf4-bnb` åœ¨å†…å­˜ä¸è´¨é‡ä¹‹é—´æ›´å¹³è¡¡
- `int4-quanto` ä¸ºæŠ˜ä¸­æ–¹æ¡ˆ
- é™¤éæœ‰ 40GB+ VRAMï¼Œå¦åˆ™é¿å… `int8`

#### å­¦ä¹ ç‡

LoRA è®­ç»ƒï¼š
- å° LoRAï¼ˆrank 1-8ï¼‰ï¼šå­¦ä¹ ç‡çº¦ 1e-4
- å¤§ LoRAï¼ˆrank 16-32ï¼‰ï¼šå­¦ä¹ ç‡çº¦ 5e-5
- ä½¿ç”¨ Prodigy ä¼˜åŒ–å™¨æ—¶ï¼šä» 1.0 å¼€å§‹è‡ªé€‚åº”

#### å›¾åƒä¼ªå½±

è‹¥å‡ºç°ä¼ªå½±ï¼š
- é™ä½å­¦ä¹ ç‡
- æé«˜æ¢¯åº¦ç´¯ç§¯
- ç¡®ä¿å›¾åƒè´¨é‡é«˜ä¸”é¢„å¤„ç†æ­£ç¡®
- åˆæœŸä½¿ç”¨è¾ƒä½åˆ†è¾¨ç‡

#### å¤šåˆ†è¾¨ç‡è®­ç»ƒ

å…ˆç”¨ä½åˆ†è¾¨ç‡ï¼ˆ512px æˆ– 768pxï¼‰è®­ç»ƒï¼Œå†åœ¨ 1024px ä¸Šå¾®è°ƒã€‚ä¸åŒåˆ†è¾¨ç‡è®­ç»ƒæ—¶å»ºè®®å¯ç”¨ `--flow_schedule_auto_shift`ã€‚

### å¹³å°é™åˆ¶

**ä¸æ”¯æŒï¼š**
- AMD ROCmï¼ˆç¼ºä¹é«˜æ•ˆ Flash Attention å®ç°ï¼‰
- Apple Silicon/MacOSï¼ˆå†…å­˜ä¸æ³¨æ„åŠ›é™åˆ¶ï¼‰
- VRAM < 24GB çš„æ¶ˆè´¹çº§ GPU

### å½“å‰å·²çŸ¥é—®é¢˜

1. æ‰¹å¤§å° > 1 æ— æ³•æ­£å¸¸å·¥ä½œï¼ˆè¯·ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯ï¼‰
2. å°šä¸æ”¯æŒ TREAD
3. æ–‡æœ¬ç¼–ç å™¨å†…å­˜å ç”¨é«˜ï¼ˆé‡åŒ–å‰çº¦ 16GBï¼‰
4. åºåˆ—é•¿åº¦å¤„ç†é—®é¢˜ï¼ˆ[ä¸Šæ¸¸é—®é¢˜](https://github.com/huggingface/diffusers/issues/12075)ï¼‰

å¦‚éœ€æ›´å¤šå¸®åŠ©ä¸æ’æŸ¥ï¼Œè¯·å‚é˜… [SimpleTuner æ–‡æ¡£](/documentation) æˆ–åŠ å…¥ç¤¾åŒº Discordã€‚
