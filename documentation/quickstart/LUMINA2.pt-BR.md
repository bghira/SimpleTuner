## Guia de In√≠cio R√°pido do Lumina2

Neste exemplo, vamos treinar um LoRA do Lumina2 ou fazer fine-tuning do modelo completo.

### Requisitos de hardware

O Lumina2 √© um modelo de 2B par√¢metros, tornando-o muito mais acess√≠vel do que modelos maiores como Flux ou SD3. O tamanho menor do modelo significa:

Ao treinar um LoRA rank-16, ele usa:
- Aproximadamente 12-14GB de VRAM para treinamento LoRA
- Aproximadamente 16-20GB de VRAM para fine-tuning completo
- Cerca de 20-30GB de RAM do sistema durante a inicializa√ß√£o

Voc√™ vai precisar:
- **M√≠nimo**: Uma √∫nica RTX 3060 12GB ou RTX 4060 Ti 16GB
- **Recomendado**: RTX 3090, RTX 4090 ou A100 para treinamento mais r√°pido
- **RAM do sistema**: Pelo menos 32GB recomendados

### Pr√©-requisitos

Certifique-se de que voc√™ tenha Python instalado; o SimpleTuner funciona bem com 3.10 at√© 3.12.

Voc√™ pode verificar executando:

```bash
python --version
```

Se voc√™ n√£o tem Python 3.12 instalado no Ubuntu, pode tentar o seguinte:

```bash
apt -y install python3.13 python3.13-venv
```

#### Depend√™ncias da imagem de cont√™iner

Para Vast, RunPod e TensorDock (entre outros), o seguinte funciona em uma imagem CUDA 12.2-12.8:

```bash
apt -y install nvidia-cuda-toolkit
```

### Instala√ß√£o

Instale o SimpleTuner via pip:

```bash
pip install 'simpletuner[cuda]'

# CUDA 13 / Blackwell users (NVIDIA B-series GPUs)
pip install 'simpletuner[cuda13]' --extra-index-url https://download.pytorch.org/whl/cu130
```

Para instala√ß√£o manual ou setup de desenvolvimento, veja a [documenta√ß√£o de instala√ß√£o](../INSTALL.md).

### Configurando o ambiente

Para rodar o SimpleTuner, voc√™ precisar√° configurar um arquivo de configura√ß√£o, os diret√≥rios de dataset e modelo, e um arquivo de configura√ß√£o do dataloader.

#### Arquivo de configura√ß√£o

Copie `config/config.json.example` para `config/config.json`:

```bash
cp config/config.json.example config/config.json
```

L√°, voc√™ precisar√° modificar as seguintes vari√°veis:

- `model_type` - Defina como `lora` para treinamento LoRA ou `full` para fine-tuning completo.
- `model_family` - Defina como `lumina2`.
- `output_dir` - Defina o diret√≥rio onde deseja armazenar seus checkpoints e imagens de valida√ß√£o. √â recomendado usar um caminho completo aqui.
- `train_batch_size` - Pode ser 1-4 dependendo da mem√≥ria da sua GPU e do tamanho do dataset.
- `validation_resolution` - O Lumina2 suporta m√∫ltiplas resolu√ß√µes. Op√ß√µes comuns: `1024x1024`, `512x512`, `768x768`.
- `validation_guidance` - O Lumina2 usa classifier-free guidance. Valores de 3.5-7.0 funcionam bem.
- `validation_num_inference_steps` - 20-30 steps funcionam bem para o Lumina2.
- `gradient_accumulation_steps` - Pode ser usado para simular lotes maiores. Um valor de 2-4 funciona bem.
- `optimizer` - `adamw_bf16` √© recomendado. `lion` e `optimi-stableadamw` tamb√©m funcionam bem.
- `mixed_precision` - Mantenha em `bf16` para melhores resultados.
- `gradient_checkpointing` - Defina como `true` para economizar VRAM.
- `learning_rate` - Para LoRA: `1e-4` a `5e-5`. Para fine-tuning completo: `1e-5` a `1e-6`.

#### Exemplo de configura√ß√£o do Lumina2

Isso vai no `config.json`

<details>
<summary>Ver exemplo de configura√ß√£o</summary>

```json
{
    "base_model_precision": "int8-torchao",
    "checkpoint_step_interval": 50,
    "data_backend_config": "config/lumina2/multidatabackend.json",
    "disable_bucket_pruning": true,
    "eval_steps_interval": 50,
    "evaluation_type": "clip",
    "flow_schedule_auto_shift": true,
    "gradient_checkpointing": true,
    "hub_model_id": "lumina2-lora",
    "learning_rate": 1e-4,
    "lora_alpha": 16,
    "lora_rank": 16,
    "lora_type": "standard",
    "lr_scheduler": "constant",
    "max_train_steps": 400000,
    "model_family": "lumina2",
    "model_type": "lora",
    "num_train_epochs": 0,
    "optimizer": "adamw_bf16",
    "output_dir": "output/lumina2",
    "push_checkpoints_to_hub": true,
    "push_to_hub": true,
    "quantize_via": "cpu",
    "report_to": "wandb",
    "seed": 42,
    "tracker_project_name": "lumina2-training",
    "tracker_run_name": "lumina2-lora",
    "train_batch_size": 4,
    "use_ema": true,
    "vae_batch_size": 1,
    "validation_disable_unconditional": true,
    "validation_guidance": 4.0,
    "validation_guidance_rescale": 0.0,
    "validation_negative_prompt": "ugly, cropped, blurry, low-quality, mediocre average",
    "validation_num_inference_steps": 40,
    "validation_prompt": "A photo-realistic image of a cat",
    "validation_prompt_library": false,
    "validation_resolution": "1024x1024",
    "validation_seed": 42,
    "validation_step_interval": 50
}
```
</details>

Para treinamento Lycoris, altere `lora_type` para `lycoris`

### Recursos experimentais avan√ßados

<details>
<summary>Mostrar detalhes experimentais avan√ßados</summary>


O SimpleTuner inclui recursos experimentais que podem melhorar significativamente a estabilidade e o desempenho do treinamento.

*   **[Scheduled Sampling (Rollout)](../experimental/SCHEDULED_SAMPLING.md):** reduz o vi√©s de exposi√ß√£o e melhora a qualidade de sa√≠da ao deixar o modelo gerar suas pr√≥prias entradas durante o treinamento.

> ‚ö†Ô∏è Esses recursos aumentam a sobrecarga computacional do treinamento.

#### Prompts de valida√ß√£o

Dentro de `config/config.json` est√° o "prompt de valida√ß√£o prim√°rio". Al√©m disso, crie um arquivo de biblioteca de prompts:

```json
{
  "portrait": "a high-quality portrait photograph with natural lighting",
  "landscape": "a breathtaking landscape photograph with dramatic lighting",
  "artistic": "an artistic rendering with vibrant colors and creative composition",
  "detailed": "a highly detailed image with sharp focus and rich textures",
  "stylized": "a stylized illustration with unique artistic flair"
}
```

Adicione ao seu config:
```json
{
  "--user_prompt_library": "config/user_prompt_library.json"
}
```

#### Considera√ß√µes sobre o dataset

O Lumina2 se beneficia de dados de treinamento de alta qualidade. Crie um `--data_backend_config` (`config/multidatabackend.json`):

> üí° **Dica:** Para datasets grandes em que espa√ßo em disco √© uma preocupa√ß√£o, voc√™ pode usar `--vae_cache_disable` para realizar codifica√ß√£o VAE online sem armazenar os resultados no disco.

```json
[
  {
    "id": "lumina2-training",
    "type": "local",
    "crop": true,
    "crop_aspect": "square",
    "crop_style": "center",
    "resolution": 1024,
    "minimum_image_size": 512,
    "maximum_image_size": 2048,
    "target_downsample_size": 1024,
    "resolution_type": "pixel_area",
    "cache_dir_vae": "cache/vae/lumina2/training",
    "instance_data_dir": "/datasets/training",
    "caption_strategy": "textfile",
    "metadata_backend": "discovery"
  },
  {
    "id": "text-embeds",
    "type": "local",
    "dataset_type": "text_embeds",
    "default": true,
    "cache_dir": "cache/text/lumina2",
    "disabled": false,
    "write_batch_size": 128
  }
]
```

> Veja op√ß√µes e requisitos de caption_strategy em [DATALOADER.md](../DATALOADER.md#caption_strategy).

Crie o diret√≥rio do seu dataset. N√£o se esque√ßa de atualizar esse caminho para o local real.

```bash
mkdir -p /datasets/training
</details>

# Coloque suas imagens e arquivos de caption em /datasets/training/
```

Arquivos de caption devem ter o mesmo nome da imagem com a extens√£o `.txt`.

#### Login no WandB

O SimpleTuner tem suporte **opcional** a trackers, com foco principal no Weights & Biases. Voc√™ pode desativar com `report_to=none`.

Para habilitar o wandb, execute os seguintes comandos:

```bash
wandb login
```

#### Login no Huggingface Hub

Para enviar checkpoints ao Huggingface Hub, garanta que:
```bash
huggingface-cli login
```

### Executando o treinamento

A partir do diret√≥rio do SimpleTuner, voc√™ tem v√°rias op√ß√µes para iniciar o treinamento:

**Op√ß√£o 1 (Recomendado - pip install):**
```bash
pip install 'simpletuner[cuda]'

# CUDA 13 / Blackwell users (NVIDIA B-series GPUs)
pip install 'simpletuner[cuda13]' --extra-index-url https://download.pytorch.org/whl/cu130
simpletuner train
```

**Op√ß√£o 2 (M√©todo Git clone):**
```bash
simpletuner train
```

**Op√ß√£o 3 (M√©todo legado - ainda funciona):**
```bash
./train.sh
```

Isso vai iniciar o cache de text embeds e sa√≠das VAE em disco.

## Dicas de treinamento para Lumina2

### Taxas de aprendizado

#### Treinamento LoRA
- Comece com `1e-4` e ajuste com base nos resultados
- O Lumina2 treina r√°pido, ent√£o monitore as primeiras itera√ß√µes de perto
- Ranks 8-32 funcionam bem para a maioria dos casos, 64-128 podem exigir monitoramento mais pr√≥ximo, e 256-512 podem ser √∫teis para treinar novas tarefas no modelo

#### Fine-tuning completo
- Use taxas de aprendizado menores: `1e-5` a `5e-6`
- Considere usar EMA (Exponential Moving Average) para estabilidade
- √â recomendado clipping de gradiente (`max_grad_norm`) de 1.0

### Considera√ß√µes de resolu√ß√£o

O Lumina2 suporta resolu√ß√µes flex√≠veis:
- Treinar em 1024x1024 oferece a melhor qualidade
- Treinamento em resolu√ß√£o mista (512px, 768px, 1024px) ainda n√£o foi testado para impacto de qualidade
- Bucketing de propor√ß√£o funciona bem com o Lumina2

### Dura√ß√£o do treinamento

Devido ao tamanho eficiente de 2B par√¢metros do Lumina2:
- Treinamento LoRA frequentemente converge em 500-2000 steps
- Fine-tuning completo pode precisar de 2000-5000 steps
- Monitore imagens de valida√ß√£o frequentemente, pois o modelo treina r√°pido

### Problemas comuns e solu√ß√µes

1. **Modelo convergindo r√°pido demais**: Diminua a taxa de aprendizado, troque do otimizador Lion para AdamW
2. **Artefatos nas imagens geradas**: Garanta dados de treinamento de alta qualidade e considere reduzir a taxa de aprendizado
3. **Sem mem√≥ria**: Habilite gradient checkpointing e reduza o tamanho do batch
4. **Overfitting f√°cil**: Use datasets de regulariza√ß√£o

## Dicas de infer√™ncia

### Usando seu modelo treinado

Modelos Lumina2 podem ser usados com:
- Biblioteca Diffusers diretamente
- ComfyUI com os n√≥s apropriados
- Outros frameworks de infer√™ncia que suportam modelos baseados em Gemma2

### Configura√ß√µes ideais de infer√™ncia

- Guidance scale: 4.0-6.0
- Steps de infer√™ncia: 20-50
- Use a mesma resolu√ß√£o em que voc√™ treinou para melhores resultados

## Notas

### Vantagens do Lumina2

- Treinamento r√°pido devido ao tamanho de 2B par√¢metros
- Boa rela√ß√£o qualidade/tamanho
- Suporta v√°rios modos de treinamento (LoRA, LyCORIS, full)
- Uso eficiente de mem√≥ria

### Limita√ß√µes atuais

- Sem suporte a ControlNet por enquanto
- Limitado a gera√ß√£o texto-para-imagem
- Exige alta qualidade de captions para melhores resultados

### Otimiza√ß√£o de mem√≥ria

Ao contr√°rio de modelos maiores, o Lumina2 normalmente n√£o requer:
- Quantiza√ß√£o de modelo
- T√©cnicas extremas de otimiza√ß√£o de mem√≥ria
- Estrat√©gias complexas de mixed precision
