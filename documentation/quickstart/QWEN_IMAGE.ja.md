## Qwen Image ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

> ğŸ†• edit ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’æ¢ã—ã¦ã„ã¾ã™ã‹ï¼Ÿ å‚ç…§ãƒšã‚¢å­¦ç¿’ã®æ‰‹é †ã¯ [Qwen Image Edit quickstart](./QWEN_EDIT.md) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

ã“ã®ä¾‹ã§ã¯ã€20B ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã® Vision-Language ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹ Qwen Image ã® LoRA ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã™ã€‚ã‚µã‚¤ã‚ºãŒå¤§ãã„ãŸã‚ã€ç©æ¥µçš„ãªãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ãŒå¿…è¦ã§ã™ã€‚

24GB GPU ã¯æœ€ä½ãƒ©ã‚¤ãƒ³ã§ã€ã•ã‚‰ã«å¼·ã„é‡å­åŒ–ã¨æ…é‡ãªè¨­å®šãŒå¿…è¦ã§ã™ã€‚ã‚¹ãƒ ãƒ¼ã‚ºãªé‹ç”¨ã«ã¯ 40GB+ ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚

24G ã§å­¦ç¿’ã™ã‚‹å ´åˆã€æ¤œè¨¼ã¯ãƒ¡ãƒ¢ãƒªä¸è¶³ã«ãªã‚Šã‚„ã™ã„ãŸã‚ã€ä½è§£åƒåº¦ã‚„ int8 ã‚’è¶…ãˆã‚‹å¼·ã„é‡å­åŒ–ãŒå¿…è¦ã§ã™ã€‚

### ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢è¦ä»¶

Qwen Image ã¯ 20B ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã§ã€æ´—ç·´ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã ã‘ã§ã‚‚é‡å­åŒ–å‰ã§ ~16GB VRAM ã‚’æ¶ˆè²»ã—ã¾ã™ã€‚16 ãƒãƒ£ãƒ³ãƒãƒ«ã®ç‹¬è‡ª VAE ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

**é‡è¦ãªåˆ¶é™:**
- **AMD ROCm ã¨ MacOS ã¯æœªå¯¾å¿œ**ï¼ˆåŠ¹ç‡çš„ãª Flash Attention ãŒãªã„ãŸã‚ï¼‰
- ãƒãƒƒãƒã‚µã‚¤ã‚º > 1 ã¯ç¾åœ¨æ­£ã—ãå‹•ä½œã—ãªã„ãŸã‚ã€gradient accumulation ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„
- TREADï¼ˆText-Representation Enhanced Adversarial Diffusionï¼‰ã¯æœªå¯¾å¿œ

### å‰ææ¡ä»¶

Python ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚SimpleTuner ã¯ 3.10 ã‹ã‚‰ 3.12 ã§ã†ã¾ãå‹•ä½œã—ã¾ã™ã€‚

ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¦ç¢ºèªã§ãã¾ã™:

```bash
python --version
```

Ubuntu ã« Python 3.12 ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã€ä»¥ä¸‹ã‚’è©¦ã—ã¦ãã ã•ã„:

```bash
apt -y install python3.13 python3.13-venv
```

#### ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã®ä¾å­˜é–¢ä¿‚

Vastã€RunPodã€TensorDockï¼ˆãªã©ï¼‰ã®å ´åˆã€CUDA 12.2-12.8 ã‚¤ãƒ¡ãƒ¼ã‚¸ã§ CUDA æ‹¡å¼µã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã«ã¯ä»¥ä¸‹ãŒæ©Ÿèƒ½ã—ã¾ã™:

```bash
apt -y install nvidia-cuda-toolkit
```

### ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

pip ã§ SimpleTuner ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™:

```bash
pip install 'simpletuner[cuda]'

# CUDA 13 / Blackwell users (NVIDIA B-series GPUs)
pip install 'simpletuner[cuda13]' --extra-index-url https://download.pytorch.org/whl/cu130
```

æ‰‹å‹•ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¾ãŸã¯é–‹ç™ºã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã«ã¤ã„ã¦ã¯ã€[ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](../INSTALL.md)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

### ç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

SimpleTuner ã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯ã€è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€ãŠã‚ˆã³ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

#### è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«

å®Ÿé¨“çš„ãªã‚¹ã‚¯ãƒªãƒ—ãƒˆ `configure.py` ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã®è¨­å®šã§ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Œå…¨ã«ã‚¹ã‚­ãƒƒãƒ—ã§ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ä¸€èˆ¬çš„ãªè½ã¨ã—ç©´ã‚’é¿ã‘ã‚‹ãŸã‚ã®å®‰å…¨æ©Ÿèƒ½ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚

**æ³¨æ„:** ã“ã‚Œã¯ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’è¨­å®šã—ã¾ã›ã‚“ã€‚å¾Œã§æ‰‹å‹•ã§è¨­å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

å®Ÿè¡Œã™ã‚‹ã«ã¯:

```bash
simpletuner configure
```

> âš ï¸ Hugging Face Hub ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã«ãã„å›½ã«ã„ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã€ã‚·ã‚¹ãƒ†ãƒ ãŒä½¿ç”¨ã™ã‚‹ `$SHELL` ã«å¿œã˜ã¦ `~/.bashrc` ã¾ãŸã¯ `~/.zshrc` ã« `HF_ENDPOINT=https://hf-mirror.com` ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚

æ‰‹å‹•ã§è¨­å®šã—ãŸã„å ´åˆ:

`config/config.json.example` ã‚’ `config/config.json` ã«ã‚³ãƒ”ãƒ¼ã—ã¾ã™:

```bash
cp config/config.json.example config/config.json
```

ãã“ã§ã€ä»¥ä¸‹ã®å¤‰æ•°ã‚’å¤‰æ›´ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™:

- `model_type` - `lora` ã«è¨­å®šã—ã¾ã™ã€‚
- `lora_type` - PEFT LoRA ã¯ `standard`ã€LoKr ã¯ `lycoris` ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
- `model_family` - `qwen_image` ã«è¨­å®šã—ã¾ã™ã€‚
- `model_flavour` - `v1.0` ã«è¨­å®šã—ã¾ã™ã€‚
- `output_dir` - ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¨æ¤œè¨¼ç”»åƒã‚’ä¿å­˜ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«è¨­å®šã—ã¾ã™ã€‚ãƒ•ãƒ«ãƒ‘ã‚¹ã®ä½¿ç”¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚
- `train_batch_size` - 1 ã«å›ºå®šï¼ˆãƒãƒƒãƒã‚µã‚¤ã‚º > 1 ã¯ç¾åœ¨å‹•ä½œã—ã¾ã›ã‚“ï¼‰ã€‚
- `gradient_accumulation_steps` - 2ã€œ8 ã‚’è¨­å®šã—ã¦å®ŸåŠ¹ãƒãƒƒãƒã‚’å¤§ããã—ã¾ã™ã€‚
- `validation_resolution` - `1024x1024` ã‚‚ã—ãã¯ãƒ¡ãƒ¢ãƒªåˆ¶ç´„ã®ãŸã‚ã‚ˆã‚Šä½ã„å€¤ã«è¨­å®šã—ã¾ã™ã€‚
  - 24G ã¯ç¾çŠ¶ 1024x1024 æ¤œè¨¼ã«å¯¾å¿œã§ãã¾ã›ã‚“ã€‚ã‚µã‚¤ã‚ºã‚’ä¸‹ã’ã¦ãã ã•ã„ã€‚
  - ä»–ã®è§£åƒåº¦ã¯ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§æŒ‡å®šã§ãã¾ã™: `1024x1024,768x768,512x512`
- `validation_guidance` - 3.0ã€œ4.0 å‰å¾ŒãŒè‰¯å¥½ã§ã™ã€‚
- `validation_num_inference_steps` - 30 å‰å¾Œã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
- `use_ema` - `true` ã«è¨­å®šã™ã‚‹ã¨æ»‘ã‚‰ã‹ãªçµæœãŒå¾—ã‚‰ã‚Œã¾ã™ãŒãƒ¡ãƒ¢ãƒªã‚’è¿½åŠ ã§æ¶ˆè²»ã—ã¾ã™ã€‚

- `optimizer` - è‰¯å¥½ãªçµæœã®ãŸã‚ `optimi-lion` ã‚’ä½¿ç”¨ã™ã‚‹ã‹ã€ä½™è£•ãŒã‚ã‚Œã° `adamw-bf16`ã€‚
- `mixed_precision` - Qwen Image ã¯ `bf16` å¿…é ˆã§ã™ã€‚
- `gradient_checkpointing` - **å¿…é ˆ**ï¼ˆ`true`ï¼‰ã€‚å¦¥å½“ãªãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ãŸã‚å¿…è¦ã§ã™ã€‚
- `base_model_precision` - **å¼·ãæ¨å¥¨** `int8-quanto` ã¾ãŸã¯ `nf4-bnb`ï¼ˆ24GB ã§ã¯å¿…é ˆï¼‰ã€‚
- `quantize_via` - å°å‹ GPU ã®é‡å­åŒ– OOM ã‚’é¿ã‘ã‚‹ãŸã‚ `cpu` ã«è¨­å®šã—ã¾ã™ã€‚
- `quantize_activations` - å­¦ç¿’å“è³ªç¶­æŒã®ãŸã‚ `false` ã«ã—ã¾ã™ã€‚

24GB GPU å‘ã‘ã®ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–è¨­å®š:
- `lora_rank` - 8 ä»¥ä¸‹ã‚’ä½¿ç”¨ã€‚
- `lora_alpha` - `lora_rank` ã¨åŒã˜å€¤ã«ã™ã‚‹ã€‚
- `flow_schedule_shift` - 1.73 ã«è¨­å®šï¼ˆ1.0ã€œ3.0 ã§èª¿æ•´ï¼‰ã€‚

æœ€å°æ§‹æˆã® `config.json` ä¾‹:

<details>
<summary>è¨­å®šä¾‹ã‚’è¡¨ç¤º</summary>

```json
{
    "model_type": "lora",
    "model_family": "qwen_image",
    "model_flavour": "v1.0",
    "lora_type": "standard",
    "lora_rank": 8,
    "lora_alpha": 8,
    "output_dir": "output/models-qwen_image",
    "train_batch_size": 1,
    "gradient_accumulation_steps": 4,
    "validation_resolution": "1024x1024",
    "validation_guidance": 4.0,
    "validation_num_inference_steps": 30,
    "validation_seed": 42,
    "validation_prompt": "A photo-realistic image of a cat",
    "validation_step_interval": 100,
    "vae_batch_size": 1,
    "seed": 42,
    "resume_from_checkpoint": "latest",
    "resolution": 1024,
    "resolution_type": "pixel_area",
    "report_to": "tensorboard",
    "optimizer": "optimi-lion",
    "num_train_epochs": 0,
    "num_eval_images": 1,
    "mixed_precision": "bf16",
    "minimum_image_size": 0,
    "max_train_steps": 1000,
    "max_grad_norm": 0.01,
    "lr_warmup_steps": 100,
    "lr_scheduler": "constant_with_warmup",
    "learning_rate": "1e-4",
    "gradient_checkpointing": "true",
    "base_model_precision": "int2-quanto",
    "quantize_via": "cpu",
    "quantize_activations": false,
    "flow_schedule_shift": 1.73,
    "disable_benchmark": false,
    "data_backend_config": "config/qwen_image/multidatabackend.json",
    "checkpoints_total_limit": 5,
    "checkpoint_step_interval": 500,
    "caption_dropout_probability": 0.0,
    "aspect_bucket_rounding": 2
}
```
</details>

> â„¹ï¸ ãƒãƒ«ãƒ GPU ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã€ä½¿ç”¨ã™ã‚‹ GPU æ•°ã®è¨­å®šã«ã¤ã„ã¦ã¯ [ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](../OPTIONS.md#environment-configuration-variables) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

> âš ï¸ **24GB GPU ã§é‡è¦:** ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€å˜ä½“ã§ ~16GB VRAM ã‚’æ¶ˆè²»ã—ã¾ã™ã€‚`int2-quanto` ã¾ãŸã¯ `nf4-bnb` ã‚’ä½¿ã†ã“ã¨ã§å¤§å¹…ã«å‰Šæ¸›ã§ãã¾ã™ã€‚

å‹•ä½œç¢ºèªç”¨ã®æ—¢çŸ¥æ§‹æˆ:

**ã‚ªãƒ—ã‚·ãƒ§ãƒ³ 1ï¼ˆæ¨å¥¨ - pip installï¼‰:**
```bash
pip install 'simpletuner[cuda]'

# CUDA 13 / Blackwell users (NVIDIA B-series GPUs)
pip install 'simpletuner[cuda13]' --extra-index-url https://download.pytorch.org/whl/cu130
simpletuner train example=qwen_image.peft-lora
```

**ã‚ªãƒ—ã‚·ãƒ§ãƒ³ 2ï¼ˆGit clone æ–¹æ³•ï¼‰:**
```bash
simpletuner train env=examples/qwen_image.peft-lora
```

**ã‚ªãƒ—ã‚·ãƒ§ãƒ³ 3ï¼ˆãƒ¬ã‚¬ã‚·ãƒ¼æ–¹æ³• - ã¾ã å‹•ä½œã—ã¾ã™ï¼‰:**
```bash
ENV=examples/qwen_image.peft-lora ./train.sh
```

### é«˜åº¦ãªå®Ÿé¨“çš„æ©Ÿèƒ½

<details>
<summary>é«˜åº¦ãªå®Ÿé¨“çš„è©³ç´°ã‚’è¡¨ç¤º</summary>


SimpleTuner ã«ã¯ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®å®‰å®šæ€§ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹å®Ÿé¨“çš„æ©Ÿèƒ½ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚

*   **[Scheduled Sampling (Rollout)](../experimental/SCHEDULED_SAMPLING.md):** ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«ãƒ¢ãƒ‡ãƒ«ãŒè‡ªèº«ã®å…¥åŠ›ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§éœ²å‡ºãƒã‚¤ã‚¢ã‚¹ã‚’æ¸›ã‚‰ã—ã€å‡ºåŠ›å“è³ªã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚

> âš ï¸ ã“ã‚Œã‚‰ã®æ©Ÿèƒ½ã¯ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®è¨ˆç®—ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚’å¢—åŠ ã•ã›ã¾ã™ã€‚

#### æ¤œè¨¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ

`config/config.json` å†…ã«ã¯ã€Œãƒ—ãƒ©ã‚¤ãƒãƒªæ¤œè¨¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€ãŒã‚ã‚Šã€ã“ã‚Œã¯é€šå¸¸ã€å˜ä¸€ã®è¢«å†™ä½“ã‚„ã‚¹ã‚¿ã‚¤ãƒ«ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã„ã‚‹ãƒ¡ã‚¤ãƒ³ã® instance_prompt ã§ã™ã€‚ã•ã‚‰ã«ã€æ¤œè¨¼ä¸­ã«å®Ÿè¡Œã™ã‚‹è¿½åŠ ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å«ã‚€ JSON ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã§ãã¾ã™ã€‚

è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¾‹ `config/user_prompt_library.json.example` ã«ã¯ä»¥ä¸‹ã®å½¢å¼ãŒå«ã¾ã‚Œã¦ã„ã¾ã™:

```json
{
  "nickname": "the prompt goes here",
  "another_nickname": "another prompt goes here"
}
```

ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ã¯æ¤œè¨¼ã®ãƒ•ã‚¡ã‚¤ãƒ«åã«ãªã‚‹ãŸã‚ã€çŸ­ããƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã¨äº’æ›æ€§ã®ã‚ã‚‹ã‚‚ã®ã«ã—ã¦ãã ã•ã„ã€‚

ã“ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€`config.json` ã«ä»¥ä¸‹ã‚’è¿½åŠ ã—ã¾ã™:
```json
  "validation_prompt_library": "config/user_prompt_library.json",
```

å¤šæ§˜ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã‚»ãƒƒãƒˆã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒæ­£ã—ãå­¦ç¿’ã—ã¦ã„ã‚‹ã‹ã‚’åˆ¤æ–­ã™ã‚‹åŠ©ã‘ã«ãªã‚Šã¾ã™:

```json
{
    "anime_style": "a breathtaking anime-style portrait with vibrant colors and expressive features",
    "chef_cooking": "a high-quality, detailed photograph of a sous-chef immersed in culinary creation",
    "portrait": "a lifelike and intimate portrait showcasing unique personality and charm",
    "cinematic": "a cinematic, visually stunning photo with dramatic and captivating presence",
    "elegant": "an elegant and timeless portrait exuding grace and sophistication",
    "adventurous": "a dynamic and adventurous photo captured in an exciting moment",
    "mysterious": "a mysterious and enigmatic portrait shrouded in shadows and intrigue",
    "vintage": "a vintage-style portrait evoking the charm and nostalgia of a bygone era",
    "artistic": "an artistic and abstract representation blending creativity with visual storytelling",
    "futuristic": "a futuristic and cutting-edge portrayal set against advanced technology"
}
```

#### CLIP ã‚¹ã‚³ã‚¢ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°

ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã™ã‚‹ãŸã‚ã®è©•ä¾¡ã‚’æœ‰åŠ¹ã«ã—ãŸã„å ´åˆã¯ã€CLIP ã‚¹ã‚³ã‚¢ã®è¨­å®šã¨è§£é‡ˆã«é–¢ã™ã‚‹æƒ…å ±ã«ã¤ã„ã¦ [ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](../evaluation/CLIP_SCORES.md) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

#### å®‰å®šã—ãŸè©•ä¾¡æå¤±

ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã™ã‚‹ãŸã‚ã«å®‰å®šã—ãŸ MSE æå¤±ã‚’ä½¿ç”¨ã—ãŸã„å ´åˆã¯ã€è©•ä¾¡æå¤±ã®è¨­å®šã¨è§£é‡ˆã«é–¢ã™ã‚‹æƒ…å ±ã«ã¤ã„ã¦ [ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](../evaluation/EVAL_LOSS.md) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

#### æ¤œè¨¼ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼

SimpleTuner ã¯ Tiny AutoEncoder ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ç”Ÿæˆä¸­ã®ä¸­é–“æ¤œè¨¼ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€webhook ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä»‹ã—ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æ¤œè¨¼ç”»åƒãŒç”Ÿæˆã•ã‚Œã‚‹ã®ã‚’æ®µéšçš„ã«ç¢ºèªã§ãã¾ã™ã€‚

æœ‰åŠ¹ã«ã™ã‚‹ã«ã¯:
```json
{
  "validation_preview": true,
  "validation_preview_steps": 1
}
```

**è¦ä»¶:**
- Webhook è¨­å®š
- æ¤œè¨¼ãŒæœ‰åŠ¹

Tiny AutoEncoder ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚’å‰Šæ¸›ã™ã‚‹ã«ã¯ã€`validation_preview_steps` ã‚’ã‚ˆã‚Šé«˜ã„å€¤ï¼ˆä¾‹: 3 ã¾ãŸã¯ 5ï¼‰ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚`validation_num_inference_steps=20` ã¨ `validation_preview_steps=5` ã®å ´åˆã€ã‚¹ãƒ†ãƒƒãƒ— 5ã€10ã€15ã€20 ã§ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»åƒã‚’å—ã‘å–ã‚Šã¾ã™ã€‚

#### Flow ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚·ãƒ•ãƒˆ

Qwen Image ã¯ãƒ•ãƒ­ãƒ¼ãƒãƒƒãƒãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ã€ç”Ÿæˆéç¨‹ã®ã©ã®éƒ¨åˆ†ã‚’å­¦ç¿’ã™ã‚‹ã‹ã‚’åˆ¶å¾¡ã™ã‚‹ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã‚·ãƒ•ãƒˆã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚

`flow_schedule_shift` ã®ç›®å®‰:
- ä½ã„å€¤ï¼ˆ0.1ã€œ1.0ï¼‰: ç´°éƒ¨é‡è¦–
- ä¸­ç¨‹åº¦ï¼ˆ1.0ã€œ3.0ï¼‰: ãƒãƒ©ãƒ³ã‚¹ï¼ˆæ¨å¥¨ï¼‰
- é«˜ã„å€¤ï¼ˆ3.0ã€œ6.0ï¼‰: å¤§åŸŸçš„æ§‹å›³é‡è¦–

##### è‡ªå‹•ã‚·ãƒ•ãƒˆ
`--flow_schedule_auto_shift` ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã¨ã€è§£åƒåº¦ä¾å­˜ã®ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã‚·ãƒ•ãƒˆãŒé©ç”¨ã•ã‚Œã¾ã™ã€‚å¤§ããªç”»åƒã«ã¯é«˜ã„ã‚·ãƒ•ãƒˆå€¤ã€å°ã•ãªç”»åƒã«ã¯ä½ã„ã‚·ãƒ•ãƒˆå€¤ãŒä½¿ç”¨ã•ã‚Œã€å®‰å®šã™ã‚‹ä¸€æ–¹ã§å¹³å‡¡ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚

##### æ‰‹å‹•æŒ‡å®š
Qwen Image ã§ã¯ `--flow_schedule_shift` ã‚’ 1.73 ã«ã™ã‚‹ã®ãŒå‡ºç™ºç‚¹ã¨ã—ã¦æ¨å¥¨ã•ã‚Œã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚„ç›®çš„ã«å¿œã˜ã¦èª¿æ•´ã—ã¦ãã ã•ã„ã€‚

#### ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è€ƒæ…®äº‹é …

ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã«ã¯ååˆ†ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒä¸å¯æ¬ ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚ºã«ã¯åˆ¶é™ãŒã‚ã‚Šã€ãƒ¢ãƒ‡ãƒ«ã‚’åŠ¹æœçš„ã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã§ãã‚‹ååˆ†ãªå¤§ãã•ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

> â„¹ï¸ ç”»åƒãŒå°‘ãªã™ãã‚‹å ´åˆã€**no images detected in dataset** ã¨ã„ã†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚`repeats` å€¤ã‚’å¢—ã‚„ã™ã“ã¨ã§ã“ã®åˆ¶é™ã‚’å…‹æœã§ãã¾ã™ã€‚

> âš ï¸ **é‡è¦**: ç¾åœ¨ã®åˆ¶ç´„ã«ã‚ˆã‚Š `train_batch_size` ã¯ 1 ã«å›ºå®šã—ã€ä»£ã‚ã‚Šã« `gradient_accumulation_steps` ã§å®ŸåŠ¹ãƒãƒƒãƒã‚’å¢—ã‚„ã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã‚’å«ã‚€ `--data_backend_config`ï¼ˆ`config/multidatabackend.json`ï¼‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆã—ã¾ã™:

```json
[
  {
    "id": "pseudo-camera-10k-qwen",
    "type": "local",
    "crop": true,
    "crop_aspect": "square",
    "crop_style": "center",
    "resolution": 1024,
    "minimum_image_size": 512,
    "maximum_image_size": 1024,
    "target_downsample_size": 1024,
    "resolution_type": "pixel_area",
    "cache_dir_vae": "cache/vae/qwen_image/pseudo-camera-10k",
    "instance_data_dir": "datasets/pseudo-camera-10k",
    "disabled": false,
    "skip_file_discovery": "",
    "caption_strategy": "filename",
    "metadata_backend": "discovery",
    "repeats": 0,
    "is_regularisation_data": true
  },
  {
    "id": "dreambooth-subject",
    "type": "local",
    "crop": false,
    "resolution": 1024,
    "minimum_image_size": 512,
    "maximum_image_size": 1024,
    "target_downsample_size": 1024,
    "resolution_type": "pixel_area",
    "cache_dir_vae": "cache/vae/qwen_image/dreambooth-subject",
    "instance_data_dir": "datasets/dreambooth-subject",
    "caption_strategy": "instanceprompt",
    "instance_prompt": "the name of your subject goes here",
    "metadata_backend": "discovery",
    "repeats": 1000
  },
  {
    "id": "text-embeds",
    "type": "local",
    "dataset_type": "text_embeds",
    "default": true,
    "cache_dir": "cache/text/qwen_image",
    "disabled": false,
    "write_batch_size": 16
  }
]
```

> â„¹ï¸ `.txt` ã®ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãŒã‚ã‚‹å ´åˆã¯ `caption_strategy=textfile` ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
> caption_strategy ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã¨è¦ä»¶ã«ã¤ã„ã¦ã¯ [DATALOADER.md](../DATALOADER.md#caption_strategy) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚
> â„¹ï¸ OOM ã‚’é¿ã‘ã‚‹ãŸã‚ã€ãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ã® `write_batch_size` ã¯å°ã•ãã—ã¦ã„ã¾ã™ã€‚

æ¬¡ã«ã€`datasets` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã¾ã™:

```bash
mkdir -p datasets
pushd datasets
    huggingface-cli download --repo-type=dataset bghira/pseudo-camera-10k --local-dir=pseudo-camera-10k
    mkdir dreambooth-subject
    # place your images into dreambooth-subject/ now
popd
```

ã“ã‚Œã«ã‚ˆã‚Šã€ç´„ 10k ã®å†™çœŸã‚µãƒ³ãƒ—ãƒ«ãŒ `datasets/pseudo-camera-10k` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã€è‡ªå‹•çš„ã«ä½œæˆã•ã‚Œã¾ã™ã€‚

Dreambooth ã®ç”»åƒã¯ `datasets/dreambooth-subject` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«å…¥ã‚Œã¦ãã ã•ã„ã€‚

#### WandB ã¨ Huggingface Hub ã¸ã®ãƒ­ã‚°ã‚¤ãƒ³

ç‰¹ã« `--push_to_hub` ã¨ `--report_to=wandb` ã‚’ä½¿ã†å ´åˆã¯ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹å‰ã« WandB ã¨ HF Hub ã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãŠãå¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

Git LFS ãƒªãƒã‚¸ãƒˆãƒªã«æ‰‹å‹•ã§ã‚¢ã‚¤ãƒ†ãƒ ã‚’ãƒ—ãƒƒã‚·ãƒ¥ã™ã‚‹å ´åˆã¯ã€`git config --global credential.helper store` ã‚‚å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™:

```bash
wandb login
```

ãŠã‚ˆã³

```bash
huggingface-cli login
```

æŒ‡ç¤ºã«å¾“ã£ã¦ä¸¡æ–¹ã®ã‚µãƒ¼ãƒ“ã‚¹ã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„ã€‚

</details>

### ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®å®Ÿè¡Œ

SimpleTuner ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ã€ä»¥ä¸‹ã‚’å®Ÿè¡Œã™ã‚‹ã ã‘ã§ã™:

```bash
./train.sh
```

ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ã¨ VAE å‡ºåŠ›ã®ãƒ‡ã‚£ã‚¹ã‚¯ã¸ã®ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãŒé–‹å§‹ã•ã‚Œã¾ã™ã€‚

è©³ç´°ã«ã¤ã„ã¦ã¯ã€[ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼](../DATALOADER.md) ã¨ [ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](../TUTORIAL.md) ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

### ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã®ãƒ’ãƒ³ãƒˆ

#### æœ€ä½ VRAM æ§‹æˆï¼ˆ24GB æœ€ä½ï¼‰

Qwen Image ã®æœ€ä½ VRAM æ§‹æˆã¯ç´„ 24GB å¿…è¦ã§ã™:

- OS: Ubuntu Linux 24
- GPU: å˜ä¸€ã® NVIDIA CUDA ãƒ‡ãƒã‚¤ã‚¹ï¼ˆ24GB æœ€ä½ï¼‰
- ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒª: 64GB+ æ¨å¥¨
- ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ç²¾åº¦:
  - NVIDIA: `int2-quanto` ã¾ãŸã¯ `nf4-bnb`ï¼ˆ24GB å¿…é ˆï¼‰
  - `int4-quanto` ã§ã‚‚å‹•ä½œã™ã‚‹ãŒå“è³ªä½ä¸‹ã®å¯èƒ½æ€§
- ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶: `optimi-lion` ã¾ãŸã¯ `bnb-lion8bit-paged` ã§ãƒ¡ãƒ¢ãƒªåŠ¹ç‡é‡è¦–
- è§£åƒåº¦: ã¾ãš 512px ã¾ãŸã¯ 768pxã€ä½™è£•ãŒã‚ã‚Œã° 1024px
- ãƒãƒƒãƒã‚µã‚¤ã‚º: 1ï¼ˆåˆ¶ç´„ã®ãŸã‚å¿…é ˆï¼‰
- å‹¾é…è“„ç©: 2ã€œ8 ã§å®ŸåŠ¹ãƒãƒƒãƒã‚’ç¨¼ã
- `--gradient_checkpointing` ã‚’æœ‰åŠ¹åŒ–ï¼ˆå¿…é ˆï¼‰
- `--quantize_via=cpu` ã‚’ä½¿ç”¨ã—ã¦èµ·å‹•æ™‚ OOM ã‚’å›é¿
- å°ã•ãª LoRA rankï¼ˆ1ã€œ8ï¼‰ã‚’ä½¿ç”¨
- ç’°å¢ƒå¤‰æ•° `PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True` ã‚’è¨­å®šã™ã‚‹ã¨ VRAM ä½¿ç”¨ã‚’æœ€å°åŒ–ã§ãã¾ã™

**æ³¨**: VAE åŸ‹ã‚è¾¼ã¿ã‚„ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€å‡ºåŠ›ã®äº‹å‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯ãƒ¡ãƒ¢ãƒªã‚’å¤šãä½¿ã„ã¾ã™ã€‚OOM ãŒå‡ºã‚‹å ´åˆã¯ `offload_during_startup=true` ã‚’æœ‰åŠ¹ã«ã—ã¦ãã ã•ã„ã€‚

### LoRA ã®æ¨è«–

Qwen Image ã¯æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã®ãŸã‚ã€ä»¥ä¸‹ã«å‹•ä½œã™ã‚‹æ¨è«–ä¾‹ã‚’ç¤ºã—ã¾ã™:

<details>
<summary>Python æ¨è«–ä¾‹ã‚’è¡¨ç¤º</summary>

```python
import torch
from diffusers import QwenImagePipeline, QwenImageTransformer2DModel
from transformers import Qwen2Tokenizer, Qwen2_5_VLForConditionalGeneration

model_id = 'Qwen/Qwen-Image'
adapter_id = 'your-username/your-lora-name'

# Load the pipeline
pipeline = QwenImagePipeline.from_pretrained(
    model_id,
    torch_dtype=torch.bfloat16
)

# Load LoRA weights
pipeline.load_lora_weights(adapter_id)

# Optional: quantize the model to save VRAM
from optimum.quanto import quantize, freeze, qint8
quantize(pipeline.transformer, weights=qint8)
freeze(pipeline.transformer)

# Move to device
pipeline.to('cuda' if torch.cuda.is_available() else 'cpu')

# Generate an image
prompt = "Your test prompt here"
negative_prompt = 'ugly, cropped, blurry, low-quality, mediocre average'

image = pipeline(
    prompt=prompt,
    negative_prompt=negative_prompt,
    num_inference_steps=30,
    guidance_scale=4.0,
    generator=torch.Generator(device='cuda').manual_seed(42),
    width=1024,
    height=1024,
).images[0]

image.save("output.png", format="PNG")
```
</details>

### æ³¨æ„äº‹é …ã¨ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã®ãƒ’ãƒ³ãƒˆ

#### ãƒãƒƒãƒã‚µã‚¤ã‚ºã®åˆ¶é™

ç¾åœ¨ã€Qwen Image ã¯ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·å‡¦ç†ã®é–¢ä¿‚ã§ãƒãƒƒãƒã‚µã‚¤ã‚º > 1 ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚å¿…ãšä»¥ä¸‹ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„:
- `train_batch_size: 1`
- å®ŸåŠ¹ãƒãƒƒãƒã‚’ç¨¼ããŸã‚ `gradient_accumulation_steps: 2-8`

#### é‡å­åŒ–

- `int2-quanto` ã¯æœ€ã‚‚å¼·ã„çœãƒ¡ãƒ¢ãƒªã ãŒå“è³ªã«å½±éŸ¿ã™ã‚‹å¯èƒ½æ€§
- `nf4-bnb` ã¯ãƒ¡ãƒ¢ãƒªã¨å“è³ªã®ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„
- `int4-quanto` ã¯ä¸­é–“çš„
- 40GB+ ã® VRAM ãŒã‚ã‚‹å ´åˆã‚’é™¤ã `int8` ã¯é¿ã‘ã‚‹

#### å­¦ç¿’ç‡

LoRA ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®å ´åˆ:
- å°ã•ãª LoRAï¼ˆrank 1ã€œ8ï¼‰: 1e-4 å‰å¾Œ
- å¤§ããª LoRAï¼ˆrank 16ã€œ32ï¼‰: 5e-5 å‰å¾Œ
- Prodigy ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶: 1.0 ã‹ã‚‰é–‹å§‹ã—è‡ªå‹•é©å¿œ

#### ç”»åƒã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆ

ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆãŒå‡ºã‚‹å ´åˆ:
- å­¦ç¿’ç‡ã‚’ä¸‹ã’ã‚‹
- å‹¾é…è“„ç©ã‚’å¢—ã‚„ã™
- ç”»åƒå“è³ªã¨å‰å‡¦ç†ã‚’ç¢ºèª
- åˆæœŸã¯ä½è§£åƒåº¦ã‹ã‚‰é–‹å§‹ã™ã‚‹

#### è¤‡æ•°è§£åƒåº¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°

ã¾ãš 512px ã¾ãŸã¯ 768px ã§å­¦ç¿’ã—ã€ãã®å¾Œ 1024px ã§å¾®èª¿æ•´ã—ã¾ã™ã€‚ç•°ãªã‚‹è§£åƒåº¦ã§å­¦ç¿’ã™ã‚‹å ´åˆã¯ `--flow_schedule_auto_shift` ã‚’æœ‰åŠ¹ã«ã—ã¦ãã ã•ã„ã€‚

### ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã®åˆ¶é™

**æœªå¯¾å¿œ:**
- AMD ROCmï¼ˆåŠ¹ç‡çš„ãª Flash Attention ãŒãªã„ï¼‰
- Apple Silicon/MacOSï¼ˆãƒ¡ãƒ¢ãƒªã¨æ³¨æ„æ©Ÿæ§‹ã®åˆ¶é™ï¼‰
- 24GB æœªæº€ã®ã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒ GPU

### æ—¢çŸ¥ã®å•é¡Œ

1. ãƒãƒƒãƒã‚µã‚¤ã‚º > 1 ã¯æ­£ã—ãå‹•ä½œã—ãªã„ï¼ˆå‹¾é…è“„ç©ã‚’ä½¿ç”¨ï¼‰
2. TREAD ã¯æœªå¯¾å¿œ
3. ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã®ãƒ¡ãƒ¢ãƒªæ¶ˆè²»ãŒå¤§ãã„ï¼ˆé‡å­åŒ–å‰ ~16GBï¼‰
4. ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·å‡¦ç†ã®å•é¡Œï¼ˆ[ä¸Šæµ issue](https://github.com/huggingface/diffusers/issues/12075)ï¼‰

è¿½åŠ ã®ãƒ˜ãƒ«ãƒ—ã¨ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã¯ [SimpleTuner documentation](/documentation) ã‚’å‚ç…§ã™ã‚‹ã‹ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ Discord ã«å‚åŠ ã—ã¦ãã ã•ã„ã€‚
