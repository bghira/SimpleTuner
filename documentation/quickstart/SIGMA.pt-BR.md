## Guia de In√≠cio R√°pido do PixArt Sigma

Neste exemplo, vamos treinar um modelo PixArt Sigma usando o SimpleTuner e o tipo de modelo `full`, j√° que por ser menor deve caber na VRAM.

### Pr√©-requisitos

Certifique-se de que voc√™ tem Python instalado; o SimpleTuner funciona bem com 3.10 at√© 3.12.

Voc√™ pode verificar executando:

```bash
python --version
```

Se voc√™ n√£o tem o Python 3.12 instalado no Ubuntu, pode tentar o seguinte:

```bash
apt -y install python3.13 python3.13-venv
```

#### Depend√™ncias da imagem de cont√™iner

Para Vast, RunPod e TensorDock (entre outros), o seguinte funciona em uma imagem CUDA 12.2-12.8 para habilitar a compila√ß√£o de extens√µes CUDA:

```bash
apt -y install nvidia-cuda-toolkit
```

### Instala√ß√£o

Instale o SimpleTuner via pip:

```bash
pip install 'simpletuner[cuda]'

# CUDA 13 / Blackwell users (NVIDIA B-series GPUs)
pip install 'simpletuner[cuda13]' --extra-index-url https://download.pytorch.org/whl/cu130
```

Para instala√ß√£o manual ou setup de desenvolvimento, veja a [documenta√ß√£o de instala√ß√£o](../INSTALL.md).

#### Etapas adicionais para AMD ROCm

O seguinte deve ser executado para um AMD MI300X ser utiliz√°vel:

```bash
apt install amd-smi-lib
pushd /opt/rocm/share/amd_smi
python3 -m pip install --upgrade pip
python3 -m pip install .
popd
```

### Configurando o ambiente

Para rodar o SimpleTuner, voc√™ precisar√° configurar um arquivo de configura√ß√£o, os diret√≥rios de dataset e modelo, e um arquivo de configura√ß√£o do dataloader.

#### Arquivo de configura√ß√£o

Um script experimental, `configure.py`, pode permitir que voc√™ pule esta se√ß√£o inteiramente por meio de uma configura√ß√£o interativa passo a passo. Ele cont√©m alguns recursos de seguran√ßa que ajudam a evitar armadilhas comuns.

**Nota:** Isso n√£o configura seu dataloader. Voc√™ ainda precisar√° fazer isso manualmente depois.

Para execut√°-lo:

```bash
simpletuner configure
```
> ‚ö†Ô∏è Para usu√°rios localizados em pa√≠ses onde o Hugging Face Hub n√£o √© facilmente acess√≠vel, voc√™ deve adicionar `HF_ENDPOINT=https://hf-mirror.com` ao seu `~/.bashrc` ou `~/.zshrc` dependendo de qual `$SHELL` seu sistema usa.

Se voc√™ preferir configurar manualmente:

Copie `config/config.json.example` para `config/config.json`:

```bash
cp config/config.json.example config/config.json
```

L√°, voc√™ precisar√° modificar as seguintes vari√°veis:

<details>
<summary>Ver exemplo de config</summary>

```json
{
  "model_type": "full",
  "use_bitfit": false,
  "pretrained_model_name_or_path": "pixart-alpha/pixart-sigma-xl-2-1024-ms",
  "model_family": "pixart_sigma",
  "output_dir": "/home/user/output/models",
  "validation_resolution": "1024x1024,1280x768",
  "validation_guidance": 3.5
}
```
</details>

- `pretrained_model_name_or_path` - Defina como `PixArt-alpha/PixArt-Sigma-XL-2-1024-MS`.
- `MODEL_TYPE` - Defina como `full`.
- `USE_BITFIT` - Defina como `false`.
- `MODEL_FAMILY` - Defina como `pixart_sigma`.
- `OUTPUT_DIR` - Defina como o diret√≥rio onde voc√™ quer armazenar seus checkpoints e imagens de valida√ß√£o. √â recomendado usar um caminho completo aqui.
- `VALIDATION_RESOLUTION` - Como PixArt Sigma vem em formato 1024px ou 2048px, voc√™ deve definir com cuidado para `1024x1024` neste exemplo.
  - Al√©m disso, o PixArt foi fine-tuned em buckets multi-aspect, e outras resolu√ß√µes podem ser especificadas usando v√≠rgulas: `1024x1024,1280x768`
- `VALIDATION_GUIDANCE` - PixArt se beneficia de um valor bem baixo. Defina entre `3.6` e `4.4`.

H√° mais alguns ajustes se estiver usando um Mac M-series:

- `mixed_precision` deve ser definido como `no`.

> üí° **Dica:** Para datasets grandes em que o espa√ßo em disco √© uma preocupa√ß√£o, voc√™ pode usar `--vae_cache_disable` para fazer encoding do VAE online sem cachear os resultados em disco.

#### Considera√ß√µes sobre o dataset

√â crucial ter um dataset substancial para treinar seu modelo. Existem limita√ß√µes no tamanho do dataset, e voc√™ precisa garantir que seu dataset seja grande o suficiente para treinar de forma eficaz. Note que o tamanho m√≠nimo do dataset √© `TRAIN_BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS`. O dataset n√£o ser√° detect√°vel pelo trainer se for pequeno demais.

Dependendo do dataset que voc√™ tem, ser√° necess√°rio configurar seu diret√≥rio de dataset e o arquivo de configura√ß√£o do dataloader de forma diferente. Neste exemplo, usaremos [pseudo-camera-10k](https://huggingface.co/datasets/bghira/pseudo-camera-10k) como dataset.

No seu diret√≥rio `/home/user/simpletuner/config`, crie um multidatabackend.json:

<details>
<summary>Ver exemplo de config</summary>

```json
[
  {
    "id": "pseudo-camera-10k-pixart",
    "type": "local",
    "crop": true,
    "crop_aspect": "square",
    "crop_style": "random",
    "resolution": 1.0,
    "minimum_image_size": 0.25,
    "maximum_image_size": 1.0,
    "target_downsample_size": 1.0,
    "resolution_type": "area",
    "cache_dir_vae": "cache/vae/pixart/pseudo-camera-10k",
    "instance_data_dir": "/home/user/simpletuner/datasets/pseudo-camera-10k",
    "disabled": false,
    "skip_file_discovery": "",
    "caption_strategy": "filename",
    "metadata_backend": "discovery"
  },
  {
    "id": "text-embeds",
    "type": "local",
    "dataset_type": "text_embeds",
    "default": true,
    "cache_dir": "cache/text/pixart/pseudo-camera-10k",
    "disabled": false,
    "write_batch_size": 128
  }
]
```
</details>

> Veja op√ß√µes e requisitos de caption_strategy em [DATALOADER.md](../DATALOADER.md#caption_strategy).

Depois, crie um diret√≥rio `datasets`:

```bash
mkdir -p datasets
pushd datasets
    huggingface-cli download --repo-type=dataset bghira/pseudo-camera-10k --local-dir=pseudo-camera-10k
popd
```

Isso vai baixar cerca de 10k amostras de fotografias para o diret√≥rio `datasets/pseudo-camera-10k`, que ser√° criado automaticamente.

#### Login no WandB e Huggingface Hub

Voc√™ vai querer fazer login no WandB e no HF Hub antes de iniciar o treinamento, especialmente se estiver usando `push_to_hub: true` e `--report_to=wandb`.

Se voc√™ pretende enviar itens para um reposit√≥rio Git LFS manualmente, tamb√©m deve executar `git config --global credential.helper store`.

Execute os seguintes comandos:

```bash
wandb login
```

e

```bash
huggingface-cli login
```

Siga as instru√ß√µes para fazer login em ambos os servi√ßos.

### Executando o treinamento

A partir do diret√≥rio do SimpleTuner, basta executar:

```bash
bash train.sh
```

Isso vai iniciar o cache em disco das embeddings de texto e sa√≠das do VAE.

Para mais informa√ß√µes, veja os documentos do [dataloader](../DATALOADER.md) e do [tutorial](../TUTORIAL.md).

### Rastreamento de score CLIP

Se voc√™ quiser habilitar avalia√ß√µes para pontuar o desempenho do modelo, veja [este documento](../evaluation/CLIP_SCORES.md) para informa√ß√µes sobre como configurar e interpretar scores CLIP.

# Perda de avalia√ß√£o est√°vel

Se voc√™ quiser usar perda MSE est√°vel para pontuar o desempenho do modelo, veja [este documento](../evaluation/EVAL_LOSS.md) para informa√ß√µes sobre como configurar e interpretar a perda de avalia√ß√£o.

#### Pr√©vias de valida√ß√£o

SimpleTuner suporta streaming de pr√©vias intermedi√°rias de valida√ß√£o durante a gera√ß√£o usando modelos Tiny AutoEncoder. Isso permite ver imagens de valida√ß√£o sendo geradas passo a passo em tempo real via callbacks de webhook.

Para habilitar:
<details>
<summary>Ver exemplo de config</summary>

```json
{
  "validation_preview": true,
  "validation_preview_steps": 1
}
```
</details>

**Requisitos:**
- Configura√ß√£o de webhook
- Valida√ß√£o habilitada

Defina `validation_preview_steps` para um valor maior (por exemplo, 3 ou 5) para reduzir o overhead do Tiny AutoEncoder. Com `validation_num_inference_steps=20` e `validation_preview_steps=5`, voc√™ receber√° imagens de pr√©via nos steps 5, 10, 15 e 20.

### SageAttention

Ao usar `--attention_mechanism=sageattention`, a infer√™ncia pode ficar mais r√°pida durante a valida√ß√£o.

**Nota**: Isso n√£o √© compat√≠vel com _todas_ as configura√ß√µes de modelo, mas vale a tentativa.

### Recursos experimentais avan√ßados

<details>
<summary>Mostrar detalhes experimentais avan√ßados</summary>


SimpleTuner inclui recursos experimentais que podem melhorar significativamente a estabilidade e o desempenho do treinamento.

*   **[Scheduled Sampling (Rollout)](../experimental/SCHEDULED_SAMPLING.md):** reduz vi√©s de exposi√ß√£o e melhora a qualidade ao permitir que o modelo gere suas pr√≥prias entradas durante o treinamento.
*   **[Diff2Flow](../experimental/DIFF2FLOW.md):** permite treinar com um objetivo de Flow Matching, potencialmente melhorando linearidade e qualidade de gera√ß√£o.

> ‚ö†Ô∏è Esses recursos aumentam o overhead computacional do treinamento.
</details>
