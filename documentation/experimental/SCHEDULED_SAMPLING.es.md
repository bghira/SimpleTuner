# Scheduled Sampling (Rollout)

## Antecedentes

El entrenamiento est치ndar de difusi칩n se basa en "Teacher Forcing". Tomamos una imagen limpia, le a침adimos una cantidad precisa de ruido y pedimos al modelo que prediga ese ruido (o la velocidad/imagen original). La entrada al modelo siempre est치 "perfectamente" ruidosa: se encuentra exactamente en el schedule te칩rico de ruido.

Sin embargo, durante la inferencia (generaci칩n), el modelo se alimenta de sus propias salidas. Si comete un peque침o error en el paso $t$, ese error alimenta el paso $t-1$. Estos errores se acumulan, causando que la generaci칩n se desv칤e del manifold de im치genes v치lidas. Esta discrepancia entre entrenamiento (entradas perfectas) e inferencia (entradas imperfectas) se llama **sesgo de exposici칩n**.

**Scheduled Sampling** (a menudo llamado "Rollout" en este contexto) aborda esto entrenando al modelo con sus propias salidas generadas.

## C칩mo funciona

En lugar de simplemente a침adir ruido a una imagen limpia, el bucle de entrenamiento realiza ocasionalmente una mini sesi칩n de inferencia:

1.  Elegir un **timestep objetivo** $t$ (el paso en el que queremos entrenar).
2.  Elegir un **timestep fuente** $t+k$ (un paso m치s ruidoso m치s atr치s en el schedule).
3.  Usar los pesos *actuales* del modelo para generar (denoise) de $t+k$ hasta $t$.
4.  Usar este latente autogenerado y ligeramente imperfecto en el paso $t$ como entrada para la pasada de entrenamiento.

Al hacer esto, el modelo ve entradas que contienen exactamente los artefactos y errores que produce en ese momento. Aprende a decir: "Ah, comet칤 este error, as칤 lo corrijo", llevando efectivamente la generaci칩n de vuelta al camino v치lido.

## Configuraci칩n

Esta funci칩n es experimental y a침ade overhead computacional, pero puede mejorar significativamente la adherencia al prompt y la estabilidad estructural, especialmente en datasets peque침os (Dreambooth).

Para habilitarla, debes configurar un `max_step_offset` distinto de cero.

### Configuraci칩n b치sica

Agrega lo siguiente a tu `config.json`:

```json
{
  "scheduled_sampling_max_step_offset": 10,
  "scheduled_sampling_probability": 1.0,
  "scheduled_sampling_sampler": "unipc"
}
```

### Referencia de opciones

#### `scheduled_sampling_max_step_offset` (Integer)
**Default:** `0` (Desactivado)
El n칰mero m치ximo de pasos a desplegar. Si se establece en `10`, el trainer elegir치 una longitud de rollout aleatoria entre 0 y 10 para cada muestra.
> 游릭 **Recomendaci칩n:** Empieza peque침o (p. ej., `5` a `10`). Incluso rollouts cortos ayudan al modelo a aprender correcci칩n de errores sin ralentizar dr치sticamente el entrenamiento.

#### `scheduled_sampling_probability` (Float)
**Default:** `0.0`
La probabilidad (0.0 a 1.0) de que cualquier elemento del batch haga rollout.
*   `1.0`: Cada muestra hace rollout (m치s costoso).
*   `0.5`: 50% de muestras con entrenamiento est치ndar, 50% con rollout.

#### `scheduled_sampling_ramp_steps` (Integer)
**Default:** `0`
Si se configura, la probabilidad subir치 linealmente desde `scheduled_sampling_prob_start` (por defecto 0.0) hasta `scheduled_sampling_prob_end` (por defecto 0.5) a lo largo de este n칰mero de pasos globales.
> 游릭 **Tip:** Esto act칰a como un "warmup". Permite que el modelo aprenda a denoising b치sico antes de introducir la tarea m치s dif칤cil de corregir sus propios errores.

#### `scheduled_sampling_sampler` (String)
**Default:** `unipc`
El solver usado para los pasos de generaci칩n del rollout.
*   **Opciones:** `unipc` (recomendado, r치pido y preciso), `euler`, `dpm`, `rk4`.
*   `unipc` suele ser el mejor equilibrio entre velocidad y precisi칩n para estas r치fagas cortas de sampling.

### Flow Matching + ReflexFlow

Para modelos de flow-matching (`--prediction_type flow_matching`), scheduled sampling ahora soporta mitigaci칩n de sesgo de exposici칩n estilo ReflexFlow:

*   `scheduled_sampling_reflexflow`: Habilita mejoras de ReflexFlow durante el rollout (se habilita autom치ticamente para modelos flow-matching cuando scheduled sampling est치 activo; pasa `--scheduled_sampling_reflexflow=false` para desactivarlo).
*   `scheduled_sampling_reflexflow_alpha`: Escala el peso de p칠rdida basado en sesgo de exposici칩n (compensaci칩n de frecuencia).
*   `scheduled_sampling_reflexflow_beta1`: Escala el regularizador direccional anti-deriva (por defecto 10.0 para igualar el paper).
*   `scheduled_sampling_reflexflow_beta2`: Escala la p칠rdida compensada por frecuencia (por defecto 1.0).

Estos reutilizan las predicciones/latentes de rollout que ya calculas, evitando una pasada adicional de gradiente, y ayudan a mantener rollouts sesgados alineados con la trayectoria limpia mientras enfatizan componentes faltantes de baja frecuencia al inicio del denoising.

### Impacto en el rendimiento

> 丘멆잺 **Advertencia:** Habilitar rollout requiere ejecutar el modelo en modo de inferencia *dentro* del bucle de entrenamiento.
>
> Si configuras `max_step_offset=10`, el modelo puede ejecutar hasta 10 pasadas forward extra por paso de entrenamiento. Esto reducir치 tu `it/s` (iteraciones por segundo). Ajusta `scheduled_sampling_probability` para equilibrar la velocidad de entrenamiento vs. ganancias de calidad.
