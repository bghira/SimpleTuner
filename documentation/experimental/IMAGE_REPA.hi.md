# REPA और U-REPA (इमेज रेगुलराइज़ेशन)

रिप्रेज़ेंटेशन अलाइनमेंट (REPA) एक रेगुलराइज़ेशन तकनीक है जो डिफ्यूज़न मॉडल के हिडन स्टेट्स को फ्रोज़न विज़न एनकोडर फीचर्स (आमतौर पर DINOv2) के साथ अलाइन करती है। प्री-ट्रेंड विज़ुअल रिप्रेज़ेंटेशन का उपयोग करके यह जेनरेशन क्वालिटी और ट्रेनिंग एफिशिएंसी में सुधार करती है।

SimpleTuner दो वेरिएंट को सपोर्ट करता है:

- **REPA** DiT-बेस्ड इमेज मॉडल्स के लिए (Flux, SD3, Chroma, Sana, PixArt, आदि) - PR #2562
- **U-REPA** UNet-बेस्ड इमेज मॉडल्स के लिए (SDXL, SD1.5, Kolors) - PR #2563

> **वीडियो मॉडल्स की तलाश है?** टेम्पोरल अलाइनमेंट वाले वीडियो मॉडल्स पर CREPA सपोर्ट के लिए [VIDEO_CREPA.hi.md](VIDEO_CREPA.hi.md) देखें।

## कब उपयोग करें

### REPA (DiT मॉडल्स)
- आप DiT-बेस्ड इमेज मॉडल्स को ट्रेन कर रहे हैं और तेज़ कन्वर्जेंस चाहते हैं
- आपने क्वालिटी इश्यूज़ नोटिस किए हैं या मज़बूत सेमांटिक ग्राउंडिंग चाहते हैं
- सपोर्टेड मॉडल फैमिलीज़: `flux`, `flux2`, `sd3`, `chroma`, `sana`, `pixart`, `hidream`, `auraflow`, `lumina2`, और अन्य

### U-REPA (UNet मॉडल्स)
- आप UNet-बेस्ड इमेज मॉडल्स (SDXL, SD1.5, Kolors) को ट्रेन कर रहे हैं
- आप UNet आर्किटेक्चर के लिए ऑप्टिमाइज़्ड रिप्रेज़ेंटेशन अलाइनमेंट का उपयोग करना चाहते हैं
- U-REPA **मिड-ब्लॉक** अलाइनमेंट (अर्ली लेयर्स नहीं) का उपयोग करता है और बेहतर रिलेटिव सिमिलैरिटी स्ट्रक्चर के लिए **मैनिफोल्ड लॉस** जोड़ता है

## क्विक सेटअप (WebUI)

### DiT मॉडल्स के लिए (REPA)

1. **Training → Loss functions** खोलें।
2. **CREPA** इनेबल करें (यही ऑप्शन इमेज मॉडल्स के लिए REPA इनेबल करता है)।
3. **CREPA Block Index** को अर्ली एनकोडर लेयर पर सेट करें:
   - Flux / Flux2: `8`
   - SD3: `8`
   - Chroma: `8`
   - Sana / PixArt: `10`
4. शुरू करने के लिए **Weight** को `0.5` पर सेट करें।
5. विज़न एनकोडर के लिए डिफॉल्ट्स रखें (`dinov2_vitg14`, रेज़ोल्यूशन `518`)।

### UNet मॉडल्स के लिए (U-REPA)

1. **Training → Loss functions** खोलें।
2. **U-REPA** इनेबल करें।
3. **U-REPA Weight** को `0.5` पर सेट करें (पेपर डिफॉल्ट)।
4. **U-REPA Manifold Weight** को `3.0` पर सेट करें (पेपर डिफॉल्ट)।
5. विज़न एनकोडर के लिए डिफॉल्ट्स रखें।

## क्विक सेटअप (config JSON / CLI)

### DiT मॉडल्स के लिए (REPA)

```json
{
  "crepa_enabled": true,
  "crepa_block_index": 8,
  "crepa_lambda": 0.5,
  "crepa_encoder": "dinov2_vitg14",
  "crepa_encoder_image_size": 518
}
```

### UNet मॉडल्स के लिए (U-REPA)

```json
{
  "urepa_enabled": true,
  "urepa_lambda": 0.5,
  "urepa_manifold_weight": 3.0,
  "urepa_model": "dinov2_vitg14",
  "urepa_encoder_image_size": 518
}
```

## मुख्य अंतर: REPA vs U-REPA

| पहलू | REPA (DiT) | U-REPA (UNet) |
|------|-----------|---------------|
| आर्किटेक्चर | Transformer ब्लॉक्स | मिड-ब्लॉक वाला UNet |
| अलाइनमेंट पॉइंट | अर्ली transformer लेयर्स | मिड-ब्लॉक (बॉटलनेक) |
| हिडन स्टेट शेप | `(B, S, D)` सीक्वेंस | `(B, C, H, W)` कन्वोल्यूशनल |
| लॉस कंपोनेंट्स | कोसाइन अलाइनमेंट | कोसाइन + मैनिफोल्ड लॉस |
| डिफॉल्ट वेट | 0.5 | 0.5 |
| कॉन्फिग प्रीफिक्स | `crepa_*` | `urepa_*` |

## U-REPA स्पेसिफिक्स

U-REPA दो प्रमुख इनोवेशंस के साथ UNet आर्किटेक्चर के लिए REPA को अडैप्ट करता है:

### मिड-ब्लॉक अलाइनमेंट
DiT-बेस्ड REPA जो अर्ली transformer लेयर्स का उपयोग करता है, उसके विपरीत, U-REPA UNet के **मिड-ब्लॉक** (बॉटलनेक) से फीचर्स एक्सट्रैक्ट करता है। यहीं पर UNet में सबसे ज़्यादा सेमांटिक इन्फॉर्मेशन कम्प्रेस्ड होती है।

- **SDXL/Kolors**: 1024x1024 इमेजेज़ के लिए मिड-ब्लॉक `(B, 1280, 16, 16)` आउटपुट देता है
- **SD1.5**: 512x512 इमेजेज़ के लिए मिड-ब्लॉक `(B, 1280, 8, 8)` आउटपुट देता है

### मैनिफोल्ड लॉस
कोसाइन अलाइनमेंट के अलावा, U-REPA एक **मैनिफोल्ड लॉस** जोड़ता है जो रिलेटिव सिमिलैरिटी स्ट्रक्चर को अलाइन करता है:

```
L_manifold = ||sim(y[i],y[j]) - sim(h[i],h[j])||^2_F
```

यह सुनिश्चित करता है कि अगर दो एनकोडर पैचेज़ सिमिलर हैं, तो संबंधित प्रोजेक्टेड पैचेज़ भी सिमिलर होने चाहिए। `urepa_manifold_weight` पैरामीटर (डिफॉल्ट 3.0) डायरेक्ट अलाइनमेंट और मैनिफोल्ड अलाइनमेंट के बीच बैलेंस को कंट्रोल करता है।

## ट्यूनिंग नॉब्स

### REPA (DiT मॉडल्स)
- `crepa_lambda`: अलाइनमेंट लॉस वेट (डिफॉल्ट 0.5)
- `crepa_block_index`: कौन सा transformer ब्लॉक टैप करना है (0-इंडेक्स्ड)
- `crepa_spatial_align`: टोकन्स को मैच करने के लिए इंटरपोलेट करें (डिफॉल्ट true)
- `crepa_encoder`: विज़न एनकोडर मॉडल (डिफॉल्ट `dinov2_vitg14`)
- `crepa_encoder_image_size`: इनपुट रेज़ोल्यूशन (डिफॉल्ट 518)

### U-REPA (UNet मॉडल्स)
- `urepa_lambda`: अलाइनमेंट लॉस वेट (डिफॉल्ट 0.5)
- `urepa_manifold_weight`: मैनिफोल्ड लॉस वेट (डिफॉल्ट 3.0)
- `urepa_model`: विज़न एनकोडर मॉडल (डिफॉल्ट `dinov2_vitg14`)
- `urepa_encoder_image_size`: इनपुट रेज़ोल्यूशन (डिफॉल्ट 518)
- `urepa_use_tae`: तेज़ डिकोडिंग के लिए Tiny AutoEncoder का उपयोग करें

## कोएफिशिएंट शेड्यूलिंग

REPA और U-REPA दोनों ट्रेनिंग के दौरान रेगुलराइज़ेशन को डिके करने के लिए शेड्यूलिंग सपोर्ट करते हैं:

```json
{
  "crepa_scheduler": "cosine",
  "crepa_warmup_steps": 100,
  "crepa_decay_steps": 5000,
  "crepa_lambda_end": 0.0
}
```

U-REPA के लिए, `urepa_` प्रीफिक्स का उपयोग करें:

```json
{
  "urepa_scheduler": "cosine",
  "urepa_warmup_steps": 100,
  "urepa_cutoff_step": 5000
}
```

<details>
<summary>यह कैसे काम करता है (प्रैक्टिशनर)</summary>

### REPA (DiT)
- चुने गए transformer ब्लॉक से हिडन स्टेट्स कैप्चर करता है
- LayerNorm + Linear के माध्यम से एनकोडर डाइमेंशन में प्रोजेक्ट करता है
- फ्रोज़न DINOv2 फीचर्स के साथ कोसाइन सिमिलैरिटी कैलकुलेट करता है
- अगर काउंट्स अलग हैं तो स्पेशियल टोकन्स को इंटरपोलेट करता है

### U-REPA (UNet)
- UNet mid_block पर फॉरवर्ड हुक रजिस्टर करता है
- कन्वोल्यूशनल फीचर्स `(B, C, H, W)` कैप्चर करता है
- सीक्वेंस `(B, H*W, C)` में रीशेप करता है और एनकोडर डाइमेंशन में प्रोजेक्ट करता है
- कोसाइन अलाइनमेंट और मैनिफोल्ड लॉस दोनों कैलकुलेट करता है
- मैनिफोल्ड लॉस पेयरवाइज़ सिमिलैरिटी स्ट्रक्चर को अलाइन करता है

</details>

<details>
<summary>टेक्निकल (SimpleTuner इंटरनल्स)</summary>

### REPA
- इम्प्लीमेंटेशन: `simpletuner/helpers/training/crepa.py` (`CrepaRegularizer` क्लास)
- मोड डिटेक्शन: इमेज मॉडल्स के लिए `CrepaMode.IMAGE`, `crepa_mode` प्रॉपर्टी द्वारा ऑटोमैटिकली सेट
- हिडन स्टेट्स मॉडल आउटपुट की `crepa_hidden_states` की में स्टोर होते हैं

### U-REPA
- इम्प्लीमेंटेशन: `simpletuner/helpers/training/crepa.py` (`UrepaRegularizer` क्लास)
- मिड-ब्लॉक कैप्चर: `simpletuner/helpers/utils/hidden_state_buffer.py` (`UNetMidBlockCapture`)
- हिडन साइज़ `block_out_channels[-1]` से इन्फर होता है (SDXL/SD1.5/Kolors के लिए 1280)
- केवल `MODEL_TYPE == ModelTypes.UNET` के लिए इनेबल्ड
- हिडन स्टेट्स मॉडल आउटपुट की `urepa_hidden_states` की में स्टोर होते हैं

</details>

## आम समस्याएं

- **गलत मॉडल टाइप**: REPA (`crepa_*`) DiT मॉडल्स के लिए है; U-REPA (`urepa_*`) UNet मॉडल्स के लिए है। गलत का उपयोग करने से कोई प्रभाव नहीं होगा।
- **ब्लॉक इंडेक्स बहुत हाई** (REPA): अगर आपको "hidden states not returned" एरर्स मिलते हैं तो इंडेक्स कम करें।
- **VRAM स्पाइक्स**: छोटा एनकोडर ट्राई करें (`dinov2_vits14` + इमेज साइज़ `224`) या डिकोडिंग के लिए `use_tae` इनेबल करें।
- **मैनिफोल्ड वेट बहुत हाई** (U-REPA): अगर ट्रेनिंग अनस्टेबल हो जाती है, `urepa_manifold_weight` को 3.0 से 1.0 तक कम करें।

## रेफरेंसेस

- [REPA पेपर](https://arxiv.org/abs/2402.17750) - जेनरेशन के लिए रिप्रेज़ेंटेशन अलाइनमेंट
- [U-REPA पेपर](https://arxiv.org/abs/2410.xxxxx) - UNet आर्किटेक्चर के लिए यूनिवर्सल REPA (NeurIPS 2025)
- [DINOv2](https://github.com/facebookresearch/dinov2) - सेल्फ-सुपरवाइज़्ड विज़न एनकोडर
