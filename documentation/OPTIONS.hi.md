# SimpleTuner Training Script рд╡рд┐рдХрд▓реНрдк

## Overview

рдпрд╣ рдЧрд╛рдЗрдб SimpleTuner рдХреЗ `train.py` рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдореЗрдВ рдЙрдкрд▓рдмреНрдз commandтАСline рд╡рд┐рдХрд▓реНрдкреЛрдВ рдХрд╛ userтАСfriendly рд╡рд┐рд╡рд░рдг рджреЗрддреА рд╣реИред рдпреЗ рд╡рд┐рдХрд▓реНрдк рдЙрдЪреНрдЪ рд╕реНрддрд░ рдХрд╛ customization рджреЗрддреЗ рд╣реИрдВ, рдЬрд┐рд╕рд╕реЗ рдЖрдк рдореЙрдбрд▓ рдХреЛ рдЕрдкрдиреА рдЖрд╡рд╢реНрдпрдХрддрд╛рдУрдВ рдХреЗ рдЕрдиреБрд╕рд╛рд░ рдЯреНрд░реЗрди рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред

### JSON Configuration file format

рдЕрдкреЗрдХреНрд╖рд┐рдд JSON рдлрд╝рд╛рдЗрд▓тАСрдирд╛рдо `config.json` рд╣реИ рдФрд░ key рдирд╛рдо рдиреАрдЪреЗ рджрд┐рдП `--arguments` рдЬреИрд╕реЗ рд╣реА рд╣реИрдВред JSON рдлрд╝рд╛рдЗрд▓ рдореЗрдВ рдЕрдЧреНрд░рдгреА `--` рдЖрд╡рд╢реНрдпрдХ рдирд╣реАрдВ рд╣реИ, рд▓реЗрдХрд┐рди рдЪрд╛рд╣реЗрдВ рддреЛ рд░рдЦ рд╕рдХрддреЗ рд╣реИрдВред

ReadyтАСtoтАСrun рдЙрджрд╛рд╣рд░рдг рдвреВрдБрдв рд░рд╣реЗ рд╣реИрдВ? [simpletuner/examples/README.md](/simpletuner/examples/README.md) рдореЗрдВ curated presets рджреЗрдЦреЗрдВред

### Easy configure script (***RECOMMENDED***)

`simpletuner configure` рдХрдорд╛рдВрдб рд╕реЗ `config.json` рдлрд╝рд╛рдЗрд▓ рдХреЛ рдЕрдзрд┐рдХрддрд░ рдЖрджрд░реНрд╢ рдбрд┐рдлрд╝реЙрд▓реНрдЯ рд╕реЗрдЯрд┐рдВрдЧреНрд╕ рдХреЗ рд╕рд╛рде рд╕реЗрдЯ рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИред

#### рдореМрдЬреВрджрд╛ рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди рдмрджрд▓рдирд╛

`configure` рдХрдорд╛рдВрдб рдПрдХ рд╣реА argument рд╕реНрд╡реАрдХрд╛рд░ рдХрд░ рд╕рдХрддрд╛ рд╣реИ, рдПрдХ compatible `config.json`, рдЬрд┐рд╕рд╕реЗ рдЖрдк training setup рдХреЛ рдЗрдВрдЯрд░реИрдХреНрдЯрд┐рд╡ рддрд░реАрдХреЗ рд╕реЗ рдмрджрд▓ рд╕рдХрддреЗ рд╣реИрдВ:

```bash
simpletuner configure config/foo/config.json
```

рдпрд╣рд╛рдБ `foo` рдЖрдкрдХрд╛ config environment рд╣реИ тАФ рдпрд╛ рдпрджрд┐ рдЖрдк config environments рдЙрдкрдпреЛрдЧ рдирд╣реАрдВ рдХрд░ рд░рд╣реЗ рд╣реИрдВ, рддреЛ `config/config.json` рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВред

<img width="1484" height="560" alt="image" src="https://github.com/user-attachments/assets/67dec8d8-3e41-42df-96e6-f95892d2814c" />

> тЪая╕П рдЬрд┐рди рджреЗрд╢реЛрдВ рдореЗрдВ Hugging Face Hub рдЖрд╕рд╛рдиреА рд╕реЗ рдЙрдкрд▓рдмреНрдз рдирд╣реАрдВ рд╣реИ, рд╡рд╣рд╛рдБ рдХреЗ рдЙрдкрдпреЛрдЧрдХрд░реНрддрд╛рдУрдВ рдХреЛ рдЕрдкрдиреЗ рд╕рд┐рд╕реНрдЯрдо рдХреЗ `$SHELL` рдХреЗ рдЕрдиреБрд╕рд╛рд░ `~/.bashrc` рдпрд╛ `~/.zshrc` рдореЗрдВ `HF_ENDPOINT=https://hf-mirror.com` рдЬреЛрдбрд╝рдирд╛ рдЪрд╛рд╣рд┐рдПред

---

## ЁЯМЯ Core Model Configuration

### `--model_type`

- **What**: рдпрд╣ рдЪреБрдирддрд╛ рд╣реИ рдХрд┐ LoRA рдпрд╛ full fineтАСtune рдмрдирд╛рдпрд╛ рдЬрд╛рдПрдЧрд╛ред
- **Choices**: lora, full.
- **Default**: lora
  - рдпрджрд┐ lora рдЙрдкрдпреЛрдЧ рд╣реЛ, рддреЛ `--lora_type` рддрдп рдХрд░рддрд╛ рд╣реИ рдХрд┐ PEFT рдпрд╛ LyCORIS рдЙрдкрдпреЛрдЧ рд╣реЛ рд░рд╣рд╛ рд╣реИред рдХреБрдЫ рдореЙрдбрд▓ (PixArt) рдХреЗрд╡рд▓ LyCORIS adapters рдХреЗ рд╕рд╛рде рдХрд╛рдо рдХрд░рддреЗ рд╣реИрдВред

### `--model_family`

- **What**: рдпрд╣ рдирд┐рд░реНрдзрд╛рд░рд┐рдд рдХрд░рддрд╛ рд╣реИ рдХрд┐ рдХреМрдитАСрд╕рд╛ model architecture train рдХрд┐рдпрд╛ рдЬрд╛ рд░рд╣рд╛ рд╣реИред
- **Choices**: pixart_sigma, flux, sd3, sdxl, kolors, legacy

### `--lora_format`

- **What**: load/save рдХреЗ рд▓рд┐рдП LoRA checkpoint key format рдЪреБрдирддрд╛ рд╣реИред
- **Choices**: `diffusers` (рдбрд┐рдлрд╝реЙрд▓реНрдЯ), `comfyui`
- **Notes**:
  - `diffusers` standard PEFT/Diffusers layout рд╣реИред
  - `comfyui` keys рдХреЛ ComfyUIтАСstyle рдореЗрдВ convert рдХрд░рддрд╛ рд╣реИ (`diffusion_model.*` рдХреЗ рд╕рд╛рде `lora_A/lora_B` рдФрд░ `.alpha` tensors)ред Flux, Flux2, Lumina2, рдФрд░ ZтАСImage ComfyUI inputs рдХреЛ autoтАСdetect рдХрд░реЗрдВрдЧреЗ рднрд▓реЗ рд╣реА рдпрд╣ `diffusers` рдкрд░ рд╣реЛ, рд▓реЗрдХрд┐рди saving рдХреЗ рд▓рд┐рдП ComfyUI output force рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП `comfyui` рд╕реЗрдЯ рдХрд░реЗрдВред

### `--fuse_qkv_projections`

- **What**: рдореЙрдбрд▓ рдХреЗ attention blocks рдореЗрдВ QKV projections рдХреЛ fuse рдХрд░рддрд╛ рд╣реИ рддрд╛рдХрд┐ hardware рдХрд╛ рдЕрдзрд┐рдХ рдХреБрд╢рд▓ рдЙрдкрдпреЛрдЧ рд╣реЛред
- **Note**: рдХреЗрд╡рд▓ NVIDIA H100 рдпрд╛ H200 рдкрд░ рдЙрдкрд▓рдмреНрдз рд╣реИ рдЬрдм Flash Attention 3 рдореИрдиреНрдпреБрдЕрд▓реА install рд╣реЛред

### `--offload_during_startup`

- **What**: VAE caching рдЪрд▓рдиреЗ рдХреЗ рджреМрд░рд╛рди text encoder weights рдХреЛ CPU рдкрд░ offload рдХрд░рддрд╛ рд╣реИред
- **Why**: HiDream рдФрд░ Wan 2.1 рдЬреИрд╕реЗ рдмрдбрд╝реЗ рдореЙрдбрд▓реНрд╕ рдореЗрдВ VAE cache рд▓реЛрдб рдХрд░рддреЗ рд╕рдордп OOM рд╣реЛ рд╕рдХрддрд╛ рд╣реИред рдпрд╣ рд╡рд┐рдХрд▓реНрдк training quality рдХреЛ рдкреНрд░рднрд╛рд╡рд┐рдд рдирд╣реАрдВ рдХрд░рддрд╛, рд▓реЗрдХрд┐рди рдмрд╣реБрдд рдмрдбрд╝реЗ text encoders рдпрд╛ рдзреАрдореЗ CPUs рдХреЗ рд╕рд╛рде, рдХрдИ datasets рдкрд░ startup time рдХрд╛рдлрд╝реА рдмрдврд╝ рд╕рдХрддрд╛ рд╣реИред рдЗрд╕реА рдХрд╛рд░рдг рдпрд╣ рдбрд┐рдлрд╝реЙрд▓реНрдЯ рд░реВрдк рд╕реЗ disabled рд╣реИред
- **Tip**: рд╡рд┐рд╢реЗрд╖ рд░реВрдк рд╕реЗ memoryтАСconstrained systems рдХреЗ рд▓рд┐рдП рдиреАрдЪреЗ рджрд┐рдП group offloading рдлреАрдЪрд░ рдХреЗ рд╕рд╛рде рдкреВрд░рдХ рд╣реИред

### `--offload_during_save`

- **What**: `save_hooks.py` checkpoints рддреИрдпрд╛рд░ рдХрд░рддреЗ рд╕рдордп рдкреВрд░реЗ pipeline рдХреЛ рдЕрд╕реНрдерд╛рдпреА рд░реВрдк рд╕реЗ CPU рдкрд░ рд▓реЗ рдЬрд╛рддрд╛ рд╣реИ рддрд╛рдХрд┐ рд╕рднреА FP8/quantized weights device рд╕реЗ рдмрд╛рд╣рд░ рд▓рд┐рдЦреЗ рдЬрд╛рдПрдБред
- **Why**: fp8тАСquanto weights рд╕реЗрд╡ рдХрд░рдиреЗ рдкрд░ VRAM рдЙрдкрдпреЛрдЧ рдЕрдЪрд╛рдирдХ рдмрдврд╝ рд╕рдХрддрд╛ рд╣реИ (рдЙрджрд╛., `state_dict()` serialization рдХреЗ рджреМрд░рд╛рди)ред рдпрд╣ рд╡рд┐рдХрд▓реНрдк training рдХреЗ рд▓рд┐рдП рдореЙрдбрд▓ рдХреЛ accelerator рдкрд░ рд░рдЦрддрд╛ рд╣реИ, рд▓реЗрдХрд┐рди save trigger рд╣реЛрдиреЗ рдкрд░ рдереЛрдбрд╝реА рджреЗрд░ рдХреЗ рд▓рд┐рдП offload рдХрд░рддрд╛ рд╣реИ рддрд╛рдХрд┐ CUDA OOM рд╕реЗ рдмрдЪрд╛ рдЬрд╛ рд╕рдХреЗред
- **Tip**: рдХреЗрд╡рд▓ рддрдм рд╕рдХреНрд╖рдо рдХрд░реЗрдВ рдЬрдм saving OOM errors рджреЗ рд░рд╣реА рд╣реЛ; loader рдмрд╛рдж рдореЗрдВ рдореЙрдбрд▓ рд╡рд╛рдкрд╕ рд▓реЗ рдЖрддрд╛ рд╣реИ рддрд╛рдХрд┐ training seamless рд░рд╣реЗред

### `--delete_model_after_load`

- **What**: рдореЙрдбрд▓ files рдХреЛ HuggingFace cache рд╕реЗ delete рдХрд░рддрд╛ рд╣реИ рдЬрдм рд╡реЗ memory рдореЗрдВ load рд╣реЛ рдЬрд╛рддреЗ рд╣реИрдВред
- **Why**: рдЙрди рд╕реЗрдЯрдЕрдкреНрд╕ рдореЗрдВ disk usage рдШрдЯрд╛рддрд╛ рд╣реИ рдЬрд╣рд╛рдБ GB рдХреЗ рд╣рд┐рд╕рд╛рдм рд╕реЗ billing рд╣реЛрддреА рд╣реИред рдореЙрдбрд▓ VRAM/RAM рдореЗрдВ рд▓реЛрдб рд╣реЛ рдЬрд╛рдиреЗ рдХреЗ рдмрд╛рдж onтАСdisk cache рдЕрдЧрд▓реА run рддрдХ рдЖрд╡рд╢реНрдпрдХ рдирд╣реАрдВ рд░рд╣рддрд╛ред рдпрд╣ рднрд╛рд░ storage рд╕реЗ network bandwidth рдкрд░ рд╢рд┐рдлреНрдЯ рдХрд░рддрд╛ рд╣реИ рдЕрдЧрд▓реА рд░рди рдореЗрдВред
- **Notes**:
  - рдпрджрд┐ validation рд╕рдХреНрд╖рдо рд╣реИ рддреЛ VAE **delete рдирд╣реАрдВ** рд╣реЛрдЧрд╛, рдХреНрдпреЛрдВрдХрд┐ validation images рдмрдирд╛рдиреЗ рдХреЗ рд▓рд┐рдП рдЗрд╕рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рд╣реИред
  - Text encoders рдХреЛ data backend factory рдХреЗ startup рдкреВрд░рд╛ рд╣реЛрдиреЗ рдХреЗ рдмрд╛рдж delete рдХрд┐рдпрд╛ рдЬрд╛рддрд╛ рд╣реИ (embed caching рдХреЗ рдмрд╛рдж)ред
  - Transformer/UNet рдореЙрдбрд▓реНрд╕ load рд╣реЛрдиреЗ рдХреЗ рддреБрд░рдВрдд рдмрд╛рдж delete рд╣реЛрддреЗ рд╣реИрдВред
  - MultiтАСnode setups рдореЗрдВ, рд╣рд░ node рдкрд░ рдХреЗрд╡рд▓ localтАСrank 0 deletion рдХрд░рддрд╛ рд╣реИред Shared network storage рдкрд░ race conditions рд╕рдВрднрд╛рд▓рдиреЗ рдХреЗ рд▓рд┐рдП deletion failures silently ignore рдХреА рдЬрд╛рддреА рд╣реИрдВред
  - рдпрд╣ saved training checkpoints рдкрд░ **рдкреНрд░рднрд╛рд╡ рдирд╣реАрдВ** рдбрд╛рд▓рддрд╛ тАФ рдХреЗрд╡рд▓ preтАСtrained base model cache рдкрд░ рд▓рд╛рдЧреВ рд╣реЛрддрд╛ рд╣реИред

### `--enable_group_offload`

- **What**: diffusers рдХреА grouped module offloading рд╕рдХреНрд╖рдо рдХрд░рддрд╛ рд╣реИ рддрд╛рдХрд┐ forward passes рдХреЗ рдмреАрдЪ model blocks рдХреЛ CPU (рдпрд╛ disk) рдкрд░ stage рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХреЗред
- **Why**: рдмрдбрд╝реЗ transformers (Flux, Wan, Auraflow, LTXVideo, Cosmos2Image) рдкрд░ peak VRAM usage рдХреЛ рдмрд╣реБрдд рдХрдо рдХрд░рддрд╛ рд╣реИ, рдЦрд╛рд╕рдХрд░ CUDA streams рдХреЗ рд╕рд╛рде, рдФрд░ performance рдкрд░ рдиреНрдпреВрдирддрдо рдкреНрд░рднрд╛рд╡ рдкрдбрд╝рддрд╛ рд╣реИред
- **Notes**:
  - `--enable_model_cpu_offload` рдХреЗ рд╕рд╛рде mutually exclusive тАФ рдкреНрд░рддрд┐ run рдПрдХ рд╣реА strategy рдЪреБрдиреЗрдВред
  - diffusers **v0.33.0** рдпрд╛ рдирдпрд╛ required рд╣реИред

### `--group_offload_type`

- **Choices**: `block_level` (рдбрд┐рдлрд╝реЙрд▓реНрдЯ), `leaf_level`
- **What**: layers рдХреЛ рдХреИрд╕реЗ group рдХрд┐рдпрд╛ рдЬрд╛рдП рдирд┐рдпрдВрддреНрд░рд┐рдд рдХрд░рддрд╛ рд╣реИред `block_level` VRAM рдмрдЪрдд рдФрд░ throughput рдХреЗ рдмреАрдЪ рд╕рдВрддреБрд▓рди рд░рдЦрддрд╛ рд╣реИ, рдЬрдмрдХрд┐ `leaf_level` рдЕрдзрд┐рдХ CPU transfers рдХреА рдХреАрдордд рдкрд░ рдЕрдзрд┐рдХ рдмрдЪрдд рджреЗрддрд╛ рд╣реИред

### `--group_offload_blocks_per_group`

- **What**: `block_level` рдЙрдкрдпреЛрдЧ рдХрд░рддреЗ рд╕рдордп, рдПрдХ offload group рдореЗрдВ рдХрд┐рддрдиреЗ transformer blocks bundle рдХрд┐рдП рдЬрд╛рдПрдБред
- **Default**: `1`
- **Why**: рдЗрд╕ рд╕рдВрдЦреНрдпрд╛ рдХреЛ рдмрдврд╝рд╛рдиреЗ рд╕реЗ transfer frequency рдХрдо рд╣реЛрддреА рд╣реИ (рддреЗрдЬрд╝), рд▓реЗрдХрд┐рди рдЕрдзрд┐рдХ parameters accelerator рдкрд░ resident рд░рд╣рддреЗ рд╣реИрдВ (рдЕрдзрд┐рдХ VRAM)ред

### `--group_offload_use_stream`

- **What**: host/device transfers рдХреЛ compute рдХреЗ рд╕рд╛рде overlap рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП dedicated CUDA stream рдЙрдкрдпреЛрдЧ рдХрд░рддрд╛ рд╣реИред
- **Default**: `False`
- **Notes**:
  - nonтАСCUDA backends (Apple MPS, ROCm, CPU) рдкрд░ рд╕реНрд╡рддрдГ CPUтАСstyle transfers рдкрд░ fallback рдХрд░рддрд╛ рд╣реИред
  - NVIDIA GPUs рдкрд░ training рдХрд░рддреЗ рд╕рдордп, рдФрд░ copy engine capacity spare рд╣реЛ, рддреЛ рдЕрдиреБрд╢рдВрд╕рд┐рддред

### `--group_offload_to_disk_path`

- **What**: directory path рдЬрд╣рд╛рдБ grouped parameters рдХреЛ RAM рдХреА рдмрдЬрд╛рдп disk рдкрд░ spill рдХрд┐рдпрд╛ рдЬрд╛рдПрдЧрд╛ред
- **Why**: рдЕрддреНрдпрдВрдд tight CPU RAM рдмрдЬрдЯ рдХреЗ рд▓рд┐рдП рдЙрдкрдпреЛрдЧреА (рдЬреИрд╕реЗ рдмрдбрд╝реЗ NVMe drive рд╡рд╛рд▓рд╛ workstation)ред
- **Tip**: рддреЗрдЬрд╝ local SSD рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВ; network filesystems training рдХреЛ рдХрд╛рдлреА рдзреАрдорд╛ рдХрд░ рджреЗрдВрдЧреЗред

### `--musubi_blocks_to_swap`

- **What**: LongCatтАСVideo, Wan, LTXVideo, Kandinsky5тАСVideo, QwenтАСImage, Flux, Flux.2, Cosmos2Image, рдФрд░ HunyuanVideo рдХреЗ рд▓рд┐рдП Musubi block swap тАФ рдЖрдЦрд╝рд┐рд░реА N transformer blocks рдХреЛ CPU рдкрд░ рд░рдЦреЗрдВ рдФрд░ forward рдХреЗ рджреМрд░рд╛рди рдкреНрд░рддрд┐ block weights stream рдХрд░реЗрдВред
- **Default**: `0` (disabled)
- **Notes**: MusubiтАСstyle weight offload; throughput рд▓рд╛рдЧрдд рдкрд░ VRAM рдХрдо рдХрд░рддрд╛ рд╣реИ рдФрд░ gradients рд╕рдХреНрд╖рдо рд╣реЛрдиреЗ рдкрд░ skip рд╣реЛ рдЬрд╛рддрд╛ рд╣реИред

### `--musubi_block_swap_device`

- **What**: swapped transformer blocks рдХреЛ рд╕реНрдЯреЛрд░ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП device string (рдЙрджрд╛. `cpu`, `cuda:0`)ред
- **Default**: `cpu`
- **Notes**: рдХреЗрд╡рд▓ рддрдм рдЙрдкрдпреЛрдЧ рд╣реЛрддрд╛ рд╣реИ рдЬрдм `--musubi_blocks_to_swap` > 0 рд╣реЛред

### `--ramtorch`

- **What**: `nn.Linear` layers рдХреЛ RamTorch CPUтАСstreamed implementations рд╕реЗ replace рдХрд░рддрд╛ рд╣реИред
- **Why**: Linear weights рдХреЛ CPU memory рдореЗрдВ рд╕рд╛рдЭрд╛ рдХрд░рддрд╛ рд╣реИ рдФрд░ рдЙрдиреНрд╣реЗрдВ accelerator рдкрд░ stream рдХрд░рддрд╛ рд╣реИ рддрд╛рдХрд┐ VRAM pressure рдХрдо рд╣реЛред
- **Notes**:
  - CUDA рдпрд╛ ROCm рдЖрд╡рд╢реНрдпрдХ рд╣реИ (Apple/MPS рдкрд░ рд╕рдорд░реНрдерд┐рдд рдирд╣реАрдВ)ред
  - `--enable_group_offload` рдХреЗ рд╕рд╛рде mutually exclusiveред
  - `--set_grads_to_none` рд╕реНрд╡рддрдГ рд╕рдХреНрд╖рдо рдХрд░рддрд╛ рд╣реИред

### `--ramtorch_target_modules`

- **What**: CommaтАСseparated glob patterns рдЬреЛ рдпрд╣ рд╕реАрдорд┐рдд рдХрд░рддреЗ рд╣реИрдВ рдХрд┐ рдХреМрдитАСрд╕реЗ Linear modules рдХреЛ RamTorch рдореЗрдВ рдмрджрд▓рд╛ рдЬрд╛рдПред
- **Default**: рдпрджрд┐ рдХреЛрдИ pattern рдирд╣реАрдВ рджрд┐рдпрд╛ рдЧрдпрд╛, рддреЛ рд╕рднреА Linear layers convert рд╣реЛрддреА рд╣реИрдВред
- **Notes**: fully qualified module names рдпрд╛ class names рдХреЛ match рдХрд░рддрд╛ рд╣реИ (wildcards allowed)ред

### `--ramtorch_text_encoder`

- **What**: рд╕рднреА text encoder Linear layers рдкрд░ RamTorch replacements рд▓рд╛рдЧреВ рдХрд░рддрд╛ рд╣реИред
- **Default**: `False`

### `--ramtorch_vae`

- **What**: VAE midтАСblock Linear layers рдХреЗ рд▓рд┐рдП experimental RamTorch conversionред
- **Default**: `False`
- **Notes**: VAE up/down convolutional blocks unchanged рд░рд╣рддреЗ рд╣реИрдВред

### `--ramtorch_controlnet`

- **What**: ControlNet training рдХреЗ рджреМрд░рд╛рди ControlNet Linear layers рдкрд░ RamTorch replacements рд▓рд╛рдЧреВ рдХрд░рддрд╛ рд╣реИред
- **Default**: `False`

### `--ramtorch_transformer_percent`

- **What**: RamTorch рдХреЗ рд╕рд╛рде offload рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП transformer Linear layers рдХрд╛ рдкреНрд░рддрд┐рд╢рдд (0-100)ред
- **Default**: `100` (рд╕рднреА eligible layers)
- **Why**: VRAM рдмрдЪрдд рдФрд░ performance рдХреЗ рдмреАрдЪ рд╕рдВрддреБрд▓рди рдХреЗ рд▓рд┐рдП partial offloading рдХреА рдЕрдиреБрдорддрд┐ рджреЗрддрд╛ рд╣реИред рдХрдо values GPU рдкрд░ рдЕрдзрд┐рдХ layers рд░рдЦрддреА рд╣реИрдВ рдЬрд┐рд╕рд╕реЗ training рддреЗрдЬ рд╣реЛрддреА рд╣реИ рдЬрдмрдХрд┐ memory usage рднреА рдХрдо рд╣реЛрддреА рд╣реИред
- **Notes**: Layers module traversal order рдХреА рд╢реБрд░реБрдЖрдд рд╕реЗ select рдХреА рдЬрд╛рддреА рд╣реИрдВред `--ramtorch_target_modules` рдХреЗ рд╕рд╛рде combine рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИред

### `--ramtorch_text_encoder_percent`

- **What**: RamTorch рдХреЗ рд╕рд╛рде offload рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП text encoder Linear layers рдХрд╛ рдкреНрд░рддрд┐рд╢рдд (0-100)ред
- **Default**: `100` (рд╕рднреА eligible layers)
- **Why**: рдЬрдм `--ramtorch_text_encoder` enabled рд╣реЛ рддрдм text encoders рдХреА partial offloading рдХреА рдЕрдиреБрдорддрд┐ рджреЗрддрд╛ рд╣реИред
- **Notes**: рдХреЗрд╡рд▓ рддрдм рд▓рд╛рдЧреВ рд╣реЛрддрд╛ рд╣реИ рдЬрдм `--ramtorch_text_encoder` enabled рд╣реЛред

### `--ramtorch_disable_sync_hooks`

- **What**: RamTorch layers рдХреЗ рдмрд╛рдж add рдХрд┐рдП рдЧрдП CUDA synchronization hooks рдХреЛ disable рдХрд░рддрд╛ рд╣реИред
- **Default**: `False` (sync hooks enabled)
- **Why**: Sync hooks RamTorch рдХреЗ ping-pong buffering system рдореЗрдВ race conditions рдХреЛ fix рдХрд░рддреЗ рд╣реИрдВ рдЬреЛ non-deterministic outputs рдХрд╛ рдХрд╛рд░рдг рдмрди рд╕рдХрддреЗ рд╣реИрдВред Disable рдХрд░рдиреЗ рд╕реЗ performance рдмреЗрд╣рддрд░ рд╣реЛ рд╕рдХрддрд╛ рд╣реИ рд▓реЗрдХрд┐рди incorrect results рдХрд╛ risk рд╣реИред
- **Notes**: рдХреЗрд╡рд▓ рддрдм disable рдХрд░реЗрдВ рдЬрдм sync hooks рдореЗрдВ рд╕рдорд╕реНрдпрд╛ рд╣реЛ рдпрд╛ рдЙрдирдХреЗ рдмрд┐рдирд╛ test рдХрд░рдирд╛ рд╣реЛред

### `--ramtorch_disable_extensions`

- **What**: рдХреЗрд╡рд▓ Linear layers рдкрд░ RamTorch apply рдХрд░рддрд╛ рд╣реИ, Embedding/RMSNorm/LayerNorm/Conv рдХреЛ skip рдХрд░рддрд╛ рд╣реИред
- **Default**: `True` (extensions disabled)
- **Why**: SimpleTuner RamTorch рдХреЛ Linear layers рд╕реЗ рдЖрдЧреЗ рдмрдврд╝рд╛рдХрд░ Embedding, RMSNorm, LayerNorm, рдФрд░ Conv layers рдХреЛ include рдХрд░рддрд╛ рд╣реИред рдЗрди extensions рдХреЛ disable рдХрд░рдХреЗ рдХреЗрд╡рд▓ Linear layers offload рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдЗрд╕рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВред
- **Notes**: VRAM savings рдХрдо рд╣реЛ рд╕рдХрддреА рд╣реИ рд▓реЗрдХрд┐рди extended layer types рдХреА рд╕рдорд╕реНрдпрд╛рдУрдВ рдХреЛ debug рдХрд░рдиреЗ рдореЗрдВ рдорджрдж рдХрд░ рд╕рдХрддрд╛ рд╣реИред

### `--pretrained_model_name_or_path`

- **What**: pretrained model рдХрд╛ path рдпрд╛ <https://huggingface.co/models> рд╕реЗ рдЙрд╕рдХрд╛ identifier.
- **Why**: рдЙрд╕ base model рдХреЛ рдирд┐рд░реНрджрд┐рд╖реНрдЯ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдЬрд┐рд╕рд╕реЗ training рд╢реБрд░реВ рд╣реЛрдЧреАред Repository рд╕реЗ specific versions рдЪреБрдирдиреЗ рдХреЗ рд▓рд┐рдП `--revision` рдФрд░ `--variant` рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВред рдпрд╣ SDXL, Flux, рдФрд░ SD3.x рдХреЗ рд▓рд┐рдП singleтАСfile `.safetensors` paths рднреА рд╕рдкреЛрд░реНрдЯ рдХрд░рддрд╛ рд╣реИред

### `--pretrained_t5_model_name_or_path`

- **What**: pretrained T5 model рдХрд╛ path рдпрд╛ <https://huggingface.co/models> рд╕реЗ рдЙрд╕рдХрд╛ identifier.
- **Why**: PixArt рдЯреНрд░реЗрди рдХрд░рддреЗ рд╕рдордп рдЖрдк рдЕрдкрдиреЗ T5 weights рдХреЗ рд▓рд┐рдП рдХреЛрдИ specific source рдЪреБрдирдирд╛ рдЪрд╛рд╣ рд╕рдХрддреЗ рд╣реИрдВ рддрд╛рдХрд┐ base model switch рдХрд░рдиреЗ рдкрд░ рдмрд╛рд░тАСрдмрд╛рд░ download рди рдХрд░рдирд╛ рдкрдбрд╝реЗред

### `--pretrained_gemma_model_name_or_path`

- **What**: pretrained Gemma model рдХрд╛ path рдпрд╛ <https://huggingface.co/models> рд╕реЗ рдЙрд╕рдХрд╛ identifier.
- **Why**: GemmaтАСbased models (рдЬреИрд╕реЗ LTX-2, Sana, Lumina2) рдЯреНрд░реЗрди рдХрд░рддреЗ рд╕рдордп рдЖрдк base diffusion model path рдмрджрд▓реЗ рдмрд┐рдирд╛ Gemma weights рдХрд╛ source specify рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред

### `--custom_text_encoder_intermediary_layers`

- **What**: FLUX.2 models рдХреЗ рд▓рд┐рдП text encoder рд╕реЗ extract рд╣реЛрдиреЗ рд╡рд╛рд▓реА hidden state layers рдХреЛ override рдХрд░реЗрдВред
- **Format**: Layer indices рдХрд╛ JSON array, рдЬреИрд╕реЗ `[10, 20, 30]`
- **Default**: рд╕реЗрдЯ рди рд╣реЛрдиреЗ рдкрд░ model-specific defaults рдЙрдкрдпреЛрдЧ рд╣реЛрддреЗ рд╣реИрдВ:
  - FLUX.2-dev (Mistral-3): `[10, 20, 30]`
  - FLUX.2-klein (Qwen3): `[9, 18, 27]`
- **Why**: Custom alignment рдпрд╛ research рдХреЗ рд▓рд┐рдП рд╡рд┐рднрд┐рдиреНрди text encoder hidden state combinations рдХреЗ рд╕рд╛рде experiment рдХрд░рдиреЗ рдХреА рд╕реБрд╡рд┐рдзрд╛ рджреЗрддрд╛ рд╣реИред
- **Note**: рдпрд╣ option experimental рд╣реИ рдФрд░ рдХреЗрд╡рд▓ FLUX.2 models рдкрд░ рд▓рд╛рдЧреВ рд╣реЛрддрд╛ рд╣реИред Layer indices рдмрджрд▓рдиреЗ рд╕реЗ cached text embeddings invalid рд╣реЛ рдЬрд╛рдПрдВрдЧреЗ рдФрд░ regenerate рдХрд░рдиреЗ рд╣реЛрдВрдЧреЗред Layers рдХреА рд╕рдВрдЦреНрдпрд╛ model рдХреА expected input (3 layers) рд╕реЗ match рд╣реЛрдиреА рдЪрд╛рд╣рд┐рдПред

### `--gradient_checkpointing`

- **What**: Training рдХреЗ рджреМрд░рд╛рди gradients layerwise compute рд╣реЛрдХрд░ accumulate рд╣реЛрддреЗ рд╣реИрдВ рддрд╛рдХрд┐ peak VRAM рдХрдо рд╣реЛ, рд▓реЗрдХрд┐рди training рдзреАрдореА рд╣реЛрддреА рд╣реИред

### `--gradient_checkpointing_interval`

- **What**: рд╣рд░ *n* blocks рдкрд░ checkpoint рдХрд░реЗрдВ, рдЬрд╣рд╛рдБ *n* рд╢реВрдиреНрдп рд╕реЗ рдмрдбрд╝рд╛ рдорд╛рди рд╣реИред 1 рдХрд╛ рдорд╛рди `--gradient_checkpointing` enabled рдЬреИрд╕рд╛ рд╣реИ, рдФрд░ 2 рд╣рд░ рджреВрд╕рд░реЗ block рдкрд░ checkpoint рдХрд░реЗрдЧрд╛ред
- **Note**: рдпрд╣ рд╡рд┐рдХрд▓реНрдк рдлрд┐рд▓рд╣рд╛рд▓ рдХреЗрд╡рд▓ SDXL рдФрд░ Flux рдореЗрдВ рд╕рдорд░реНрдерд┐рдд рд╣реИред SDXL рдЗрд╕рдореЗрдВ hackish implementation рдЙрдкрдпреЛрдЧ рдХрд░рддрд╛ рд╣реИред

### `--gradient_checkpointing_backend`

- **Choices**: `torch`, `unsloth`
- **What**: Gradient checkpointing рдХреЗ рд▓рд┐рдП implementation рдЪреБрдиреЗрдВред
  - `torch` (default): Standard PyTorch checkpointing рдЬреЛ backward pass рдХреЗ рджреМрд░рд╛рди activations рдХреЛ recalculate рдХрд░рддрд╛ рд╣реИред ~20% time overheadред
  - `unsloth`: Recalculate рдХрд░рдиреЗ рдХреЗ рдмрдЬрд╛рдп activations рдХреЛ asynchronously CPU рдкрд░ offload рдХрд░рддрд╛ рд╣реИред ~30% рдЕрдзрд┐рдХ memory рдмрдЪрдд рдХреЗрд╡рд▓ ~2% overhead рдХреЗ рд╕рд╛рдеред Fast PCIe bandwidth рдЖрд╡рд╢реНрдпрдХ рд╣реИред
- **Note**: рдХреЗрд╡рд▓ `--gradient_checkpointing` enabled рд╣реЛрдиреЗ рдкрд░ рдкреНрд░рднрд╛рд╡реАред `unsloth` backend рдХреЗ рд▓рд┐рдП CUDA рдЖрд╡рд╢реНрдпрдХ рд╣реИред

### `--refiner_training`

- **What**: custom mixtureтАСofтАСexperts рдореЙрдбрд▓ рд╢реНрд░реГрдВрдЦрд▓рд╛ training рд╕рдХреНрд╖рдо рдХрд░рддрд╛ рд╣реИред рдЗрди рд╡рд┐рдХрд▓реНрдкреЛрдВ рдкрд░ рдЕрдзрд┐рдХ рдЬрд╛рдирдХрд╛рд░реА рдХреЗ рд▓рд┐рдП [Mixture-of-Experts](MIXTURE_OF_EXPERTS.md) рджреЗрдЦреЗрдВред

## Precision

### `--quantize_via`

- **Choices**: `cpu`, `accelerator`, `pipeline`
  - `accelerator` рдкрд░ рдпрд╣ рдордзреНрдпрдо рд░реВрдк рд╕реЗ рддреЗрдЬрд╝ рд╣реЛ рд╕рдХрддрд╛ рд╣реИ рд▓реЗрдХрд┐рди Flux рдЬреИрд╕реЗ рдмрдбрд╝реЗ рдореЙрдбрд▓ рдХреЗ рд▓рд┐рдП 24G cards рдкрд░ OOM рдХрд╛ рдЬреЛрдЦрд┐рдо рд░рд╣рддрд╛ рд╣реИред
  - `cpu` рдкрд░ quantisation рдореЗрдВ рд▓рдЧрднрдЧ 30 seconds рд▓рдЧрддреЗ рд╣реИрдВред (**Default**)
  - `pipeline` Diffusers рдХреЛ `--quantization_config` рдпрд╛ pipelineтАСcapable presets (рдЙрджрд╛. `nf4-bnb`, `int8-torchao`, `fp8-torchao`, `int8-quanto`, рдпрд╛ `.gguf` checkpoints) рдХреЗ рд╕рд╛рде quantization delegate рдХрд░рддрд╛ рд╣реИред

### `--base_model_precision`

- **What**: model precision рдШрдЯрд╛рдПрдБ рдФрд░ рдХрдо memory рдореЗрдВ training рдХрд░реЗрдВред рддреАрди рд╕рдорд░реНрдерд┐рдд quantisation backends рд╣реИрдВ: BitsAndBytes (pipeline), TorchAO (pipeline рдпрд╛ manual), рдФрд░ Optimum Quanto (pipeline рдпрд╛ manual)ред

#### Diffusers pipeline presets

- `nf4-bnb` Diffusers рдХреЗ рдорд╛рдзреНрдпрдо рд╕реЗ 4тАСbit NF4 BitsAndBytes config рдХреЗ рд╕рд╛рде рд▓реЛрдб рд╣реЛрддрд╛ рд╣реИ (CUDA only)ред `bitsandbytes` рдФрд░ BnB support рд╡рд╛рд▓реА diffusers build рдЖрд╡рд╢реНрдпрдХ рд╣реИред
- `int4-torchao`, `int8-torchao`, рдФрд░ `fp8-torchao` Diffusers рдХреЗ рдорд╛рдзреНрдпрдо рд╕реЗ TorchAoConfig рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рддреЗ рд╣реИрдВ (CUDA)ред `torchao` рдФрд░ recent diffusers/transformers рдЖрд╡рд╢реНрдпрдХ рд╣реИред
- `int8-quanto`, `int4-quanto`, `int2-quanto`, `fp8-quanto`, рдФрд░ `fp8uz-quanto` Diffusers рдХреЗ рдорд╛рдзреНрдпрдо рд╕реЗ QuantoConfig рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рддреЗ рд╣реИрдВред Diffusers FP8-NUZ рдХреЛ float8 weights рдкрд░ map рдХрд░рддрд╛ рд╣реИ; NUZ variant рдХреЗ рд▓рд┐рдП manual quanto quantization рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВред
- `.gguf` checkpoints autoтАСdetect рд╣реЛрдХрд░ рдЙрдкрд▓рдмреНрдз рд╣реЛрдиреЗ рдкрд░ `GGUFQuantizationConfig` рдХреЗ рд╕рд╛рде рд▓реЛрдб рд╣реЛрддреЗ рд╣реИрдВред GGUF support рдХреЗ рд▓рд┐рдП recent diffusers/transformers install рдХрд░реЗрдВред

#### Optimum Quanto

Hugging Face рджреНрд╡рд╛рд░рд╛ рдкреНрд░рджрд╛рди рдХреА рдЧрдИ optimumтАСquanto рд▓рд╛рдЗрдмреНрд░реЗрд░реА рд╕рднреА рд╕рдорд░реНрдерд┐рдд рдкреНрд▓реЗрдЯрдлрд╝реЙрд░реНрдореНрд╕ рдкрд░ рдордЬрдмреВрдд рд╕рдорд░реНрдерди рджреЗрддреА рд╣реИред

- `int8-quanto` рд╕рдмрд╕реЗ рд╡реНрдпрд╛рдкрдХ рд░реВрдк рд╕реЗ compatible рд╣реИ рдФрд░ рд╕рдВрднрд╡рддрдГ рд╕рд░реНрд╡реЛрддреНрддрдо рдкрд░рд┐рдгрд╛рдо рджреЗрддрд╛ рд╣реИ
  - RTX4090 рдФрд░ рд╕рдВрднрд╡рддрдГ рдЕрдиреНрдп GPUs рдкрд░ рд╕рдмрд╕реЗ рддреЗрдЬрд╝ training
  - CUDA devices рдкрд░ int8, int4 рдХреЗ рд▓рд┐рдП hardwareтАСaccelerated matmul рдЙрдкрдпреЛрдЧ рдХрд░рддрд╛ рд╣реИ
    - int4 рдЕрднреА рднреА рдмрд╣реБрдд рдзреАрдорд╛ рд╣реИ
  - `TRAINING_DYNAMO_BACKEND=inductor` (`torch.compile()`) рдХреЗ рд╕рд╛рде рдХрд╛рдо рдХрд░рддрд╛ рд╣реИ
- `fp8uz-quanto` CUDA рдФрд░ ROCm devices рдХреЗ рд▓рд┐рдП experimental fp8 variant рд╣реИред
  - Instinct рдпрд╛ рдирдИ architecture рд╡рд╛рд▓реЗ AMD silicon рдкрд░ рдмреЗрд╣рддрд░ supported
  - 4090 рдкрд░ training рдореЗрдВ `int8-quanto` рд╕реЗ рдереЛрдбрд╝рд╛ рддреЗрдЬрд╝ рд╣реЛ рд╕рдХрддрд╛ рд╣реИ, рд▓реЗрдХрд┐рди inference рдореЗрдВ рдирд╣реАрдВ (1 second рдзреАрдорд╛)
  - `TRAINING_DYNAMO_BACKEND=inductor` (`torch.compile()`) рдХреЗ рд╕рд╛рде рдХрд╛рдо рдХрд░рддрд╛ рд╣реИ
- `fp8-quanto` рдлрд┐рд▓рд╣рд╛рд▓ fp8 matmul рдЙрдкрдпреЛрдЧ рдирд╣реАрдВ рдХрд░реЗрдЧрд╛, Apple systems рдкрд░ рдХрд╛рдо рдирд╣реАрдВ рдХрд░рддрд╛ред
  - CUDA рдпрд╛ ROCm рдкрд░ hardware fp8 matmul рдЕрднреА рдирд╣реАрдВ рд╣реИ, рдЗрд╕рд▓рд┐рдП рд╕рдВрднрд╡рддрдГ int8 рд╕реЗ рдХрд╛рдлреА рдзреАрдорд╛ рд╣реЛрдЧрд╛
    - fp8 GEMM рдХреЗ рд▓рд┐рдП MARLIN kernel рдЙрдкрдпреЛрдЧ рдХрд░рддрд╛ рд╣реИ
  - dynamo рдХреЗ рд╕рд╛рде рдЕрд╕рдВрдЧрдд, рдЗрд╕ рд╕рдВрдпреЛрдЬрди рдХреА рдХреЛрд╢рд┐рд╢ рд╣реЛрдиреЗ рдкрд░ dynamo рд╕реНрд╡рддрдГ disabled рд╣реЛ рдЬрд╛рдПрдЧрд╛ред

#### TorchAO

PyTorch рдХреА рдПрдХ рдирдИ рд▓рд╛рдЗрдмреНрд░реЗрд░реА, AO рд╣рдореЗрдВ linears рдФрд░ 2D convolutions (рдЙрджрд╛. unet style models) рдХреЛ quantised counterparts рд╕реЗ рдмрджрд▓рдиреЗ рджреЗрддреА рд╣реИред
<!-- Additionally, it provides an experimental CPU offload optimiser that essentially provides a simpler reimplementation of DeepSpeed. -->

- `int8-torchao` memory consumption рдХреЛ Quanto рдХреЗ precision levels рдЬреИрд╕рд╛ рдХрдо рдХрд░ рджреЗрддрд╛ рд╣реИ
  - рд▓рд┐рдЦрддреЗ рд╕рдордп, Apple MPS рдкрд░ Quanto (9s/iter) рдХреА рддреБрд▓рдирд╛ рдореЗрдВ рдереЛрдбрд╝рд╛ рдзреАрдорд╛ (11s/iter)
  - `torch.compile` рдЙрдкрдпреЛрдЧ рди рдХрд░рдиреЗ рдкрд░ CUDA devices рдкрд░ `int8-quanto` рдЬреИрд╕реА speed рдФрд░ memory, ROCm рдкрд░ speed profile рдЕрдЬреНрдЮрд╛рдд
  - `torch.compile` рдЙрдкрдпреЛрдЧ рдХрд░рдиреЗ рдкрд░ `int8-quanto` рд╕реЗ рдзреАрдорд╛
- `fp8-torchao` рдХреЗрд╡рд▓ Hopper (H100, H200) рдпрд╛ рдирдП (Blackwell B200) accelerators рдХреЗ рд▓рд┐рдП рдЙрдкрд▓рдмреНрдз рд╣реИ

##### Optimisers

TorchAO рдореЗрдВ рд╕рд╛рдорд╛рдиреНрдп 4bit рдФрд░ 8bit optimisers рд╣реИрдВ: `ao-adamw8bit`, `ao-adamw4bit`

рдпрд╣ Hopper (H100 рдпрд╛ рдмреЗрд╣рддрд░) users рдХреЗ рд▓рд┐рдП рджреЛ optimisers рднреА рджреЗрддрд╛ рд╣реИ: `ao-adamfp8`, рдФрд░ `ao-adamwfp8`

#### SDNQ (SD.Next Quantization Engine)

[SDNQ](https://github.com/disty0/sdnq) рдПрдХ trainingтАСoptimized quantization рд▓рд╛рдЗрдмреНрд░реЗрд░реА рд╣реИ рдЬреЛ рд╕рднреА рдкреНрд▓реЗрдЯрдлрд╝реЙрд░реНрдореНрд╕ рдкрд░ рдХрд╛рдо рдХрд░рддреА рд╣реИ: AMD (ROCm), Apple (MPS), рдФрд░ NVIDIA (CUDA)ред рдпрд╣ stochastic rounding рдФрд░ quantized optimizer states рдХреЗ рд╕рд╛рде memoryтАСefficient quantized training рдкреНрд░рджрд╛рди рдХрд░рддреА рд╣реИред

##### Recommended Precision Levels

**Full finetuning рдХреЗ рд▓рд┐рдП** (model weights update рд╣реЛрддреА рд╣реИрдВ):
- `uint8-sdnq` - memory рдмрдЪрдд рдФрд░ training quality рдХрд╛ рд╕рдмрд╕реЗ рдЕрдЪреНрдЫрд╛ рд╕рдВрддреБрд▓рди
- `uint16-sdnq` - рдЕрдзрд┐рдХрддрдо quality рдХреЗ рд▓рд┐рдП рдЙрдЪреНрдЪ precision (рдЙрджрд╛. Stable Cascade)
- `int16-sdnq` - signed 16тАСbit рд╡рд┐рдХрд▓реНрдк
- `fp16-sdnq` - quantized FP16, SDNQ рд▓рд╛рднреЛрдВ рдХреЗ рд╕рд╛рде рдЕрдзрд┐рдХрддрдо precision

**LoRA training рдХреЗ рд▓рд┐рдП** (base model weights frozen):
- `int8-sdnq` - signed 8тАСbit, рдЕрдЪреНрдЫрд╛ general purpose рд╡рд┐рдХрд▓реНрдк
- `int6-sdnq`, `int5-sdnq` - lower precision, рдЫреЛрдЯрд╛ memory footprint
- `uint5-sdnq`, `uint4-sdnq`, `uint3-sdnq`, `uint2-sdnq` - aggressive compression

**Note:** `int7-sdnq` рдЙрдкрд▓рдмреНрдз рд╣реИ рд▓реЗрдХрд┐рди рдЕрдиреБрд╢рдВрд╕рд┐рдд рдирд╣реАрдВ (рдзреАрдорд╛ рдФрд░ int8 рд╕реЗ рдмрд╣реБрдд рдЫреЛрдЯрд╛ рдирд╣реАрдВ)ред

**Important:** 5тАСbit рд╕реЗ рдиреАрдЪреЗ SDNQ рдЧреБрдгрд╡рддреНрддрд╛ рдмрдирд╛рдП рд░рдЦрдиреЗ рдХреЗ рд▓рд┐рдП рд╕реНрд╡рддрдГ SVD (Singular Value Decomposition) рдХреЛ 8 steps рдХреЗ рд╕рд╛рде рд╕рдХреНрд╖рдо рдХрд░рддрд╛ рд╣реИред SVD quantize рдХрд░рдиреЗ рдореЗрдВ рдЕрдзрд┐рдХ рд╕рдордп рд▓реЗрддрд╛ рд╣реИ рдФрд░ nonтАСdeterministic рд╣реИ, рдЗрд╕рд▓рд┐рдП Disty0 HuggingFace рдкрд░ preтАСquantized SVD рдореЙрдбрд▓ рджреЗрддрд╛ рд╣реИред SVD training рдХреЗ рджреМрд░рд╛рди compute overhead рдЬреЛрдбрд╝рддрд╛ рд╣реИ, рдЗрд╕рд▓рд┐рдП full finetuning рдореЗрдВ (рдЬрд╣рд╛рдБ weights рд╕рдХреНрд░рд┐рдп рд░реВрдк рд╕реЗ update рд╣реЛрддреА рд╣реИрдВ) рдЗрд╕рд╕реЗ рдмрдЪреЗрдВред

**Key features:**
- CrossтАСplatform: AMD, Apple, рдФрд░ NVIDIA рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдкрд░ рд╕рдорд╛рди рд░реВрдк рд╕реЗ рдХрд╛рдо рдХрд░рддрд╛ рд╣реИ
- TrainingтАСoptimized: stochastic rounding рд╕реЗ quantization error accumulation рдХрдо рд╣реЛрддрд╛ рд╣реИ
- Memory efficient: quantized optimizer state buffers рд╕рдкреЛрд░реНрдЯ рдХрд░рддрд╛ рд╣реИ
- Decoupled matmul: weight precision рдФрд░ matmul precision рд╕реНрд╡рддрдВрддреНрд░ рд╣реИрдВ (INT8/FP8/FP16 matmul рдЙрдкрд▓рдмреНрдз)

##### SDNQ Optimisers

SDNQ рдореЗрдВ рдЕрддрд┐рд░рд┐рдХреНрдд memory рдмрдЪрдд рдХреЗ рд▓рд┐рдП optional quantized state buffers рд╡рд╛рд▓реЗ optimizers рд╢рд╛рдорд┐рд▓ рд╣реИрдВ:

- `sdnq-adamw` - AdamW with quantized state buffers (uint8, group_size=32)
- `sdnq-adamw+no_quant` - рдмрд┐рдирд╛ quantized states рдХреЗ AdamW (comparison рдХреЗ рд▓рд┐рдП)
- `sdnq-adafactor` - quantized state buffers рдХреЗ рд╕рд╛рде Adafactor
- `sdnq-came` - quantized state buffers рдХреЗ рд╕рд╛рде CAME optimizer
- `sdnq-lion` - quantized state buffers рдХреЗ рд╕рд╛рде Lion optimizer
- `sdnq-muon` - quantized state buffers рдХреЗ рд╕рд╛рде Muon optimizer
- `sdnq-muon+quantized_matmul` - zeropower computation рдореЗрдВ INT8 matmul рдХреЗ рд╕рд╛рде Muon

рд╕рднреА SDNQ optimizers рдбрд┐рдлрд╝реЙрд▓реНрдЯ рд░реВрдк рд╕реЗ stochastic rounding рдЙрдкрдпреЛрдЧ рдХрд░рддреЗ рд╣реИрдВ рдФрд░ custom settings рдХреЗ рд▓рд┐рдП `--optimizer_config` рдХреЗ рд╕рд╛рде рдХреЙрдиреНрдлрд╝рд┐рдЧрд░ рдХрд┐рдП рдЬрд╛ рд╕рдХрддреЗ рд╣реИрдВ, рдЬреИрд╕реЗ `use_quantized_buffers=false` рдЬрд┐рд╕рд╕реЗ state quantization рдмрдВрдж рд╣реЛ рдЬрд╛рддреА рд╣реИред

**MuonтАСspecific options:**
- `use_quantized_matmul` - zeropower_via_newtonschulz5 рдореЗрдВ INT8/FP8/FP16 matmul рд╕рдХреНрд╖рдо рдХрд░реЗрдВ
- `quantized_matmul_dtype` - matmul precision: `int8` (consumer GPUs), `fp8` (datacenter), `fp16`
- `zeropower_dtype` - zeropower computation рдХреЗ рд▓рд┐рдП precision (рдЬрдм `use_quantized_matmul=True` рд╣реЛ рддрдм ignore)
- Muon рдмрдирд╛рдо AdamW fallback рдХреЗ рд▓рд┐рдП рдЕрд▓рдЧ values рд╕реЗрдЯ рдХрд░рдиреЗ рд╣реЗрддреБ args рдХреЛ `muon_` рдпрд╛ `adamw_` prefix рдХрд░реЗрдВ

**PreтАСquantized models:** Disty0 preтАСquantized uint4 SVD models [huggingface.co/collections/Disty0/sdnq](https://huggingface.co/collections/Disty0/sdnq) рдкрд░ рджреЗрддрд╛ рд╣реИред рдЗрдиреНрд╣реЗрдВ рд╕рд╛рдорд╛рдиреНрдп рд░реВрдк рд╕реЗ рд▓реЛрдб рдХрд░реЗрдВ, рдлрд┐рд░ SDNQ import рдХрд░рдиреЗ рдХреЗ рдмрд╛рдж `convert_sdnq_model_to_training()` рд╕реЗ convert рдХрд░реЗрдВ (register рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП loading рд╕реЗ рдкрд╣рд▓реЗ SDNQ import рд╣реЛрдирд╛ рдЪрд╛рд╣рд┐рдП)ред

**Note on checkpointing:** SDNQ training models рдХреЛ training resumption рдХреЗ рд▓рд┐рдП native PyTorch format (`.pt`) рдФрд░ inference рдХреЗ рд▓рд┐рдП safetensors format рджреЛрдиреЛрдВ рдореЗрдВ рд╕реЗрд╡ рдХрд┐рдпрд╛ рдЬрд╛рддрд╛ рд╣реИред Proper training resumption рдХреЗ рд▓рд┐рдП native format рдЖрд╡рд╢реНрдпрдХ рд╣реИ рдХреНрдпреЛрдВрдХрд┐ SDNQ рдХреА `SDNQTensor` class custom serialization рдЙрдкрдпреЛрдЧ рдХрд░рддреА рд╣реИред

**Disk space tip:** disk space рдмрдЪрд╛рдиреЗ рдХреЗ рд▓рд┐рдП рдЖрдк рдХреЗрд╡рд▓ quantized weights рд░рдЦ рд╕рдХрддреЗ рд╣реИрдВ рдФрд░ inference рдХреЗ рд▓рд┐рдП рдЬрд╝рд░реВрд░рдд рдкрдбрд╝рдиреЗ рдкрд░ SDNQ рдХреА [dequantize_sdnq_training.py](https://github.com/Disty0/sdnq/blob/main/scripts/dequantize_sdnq_training.py) script рд╕реЗ dequantize рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред

### `--quantization_config`

- **What**: `--quantize_via=pipeline` рдЙрдкрдпреЛрдЧ рдХрд░рддреЗ рд╕рдордп Diffusers `quantization_config` overrides рдХрд╛ JSON object рдпрд╛ file path.
- **How**: inline JSON (рдпрд╛ file) рд╕реНрд╡реАрдХрд╛рд░ рдХрд░рддрд╛ рд╣реИ рдЬрд┐рд╕рдореЗрдВ perтАСcomponent entries рд╣реЛрдВред Keys рдореЗрдВ `unet`, `transformer`, `text_encoder`, рдпрд╛ `default` рд╢рд╛рдорд┐рд▓ рд╣реЛ рд╕рдХрддреЗ рд╣реИрдВред
- **Examples**:

```json
{
  "unet": {"load_in_4bit": true, "bnb_4bit_quant_type": "nf4", "bnb_4bit_compute_dtype": "bfloat16"},
  "text_encoder": {"quant_type": {"group_size": 128}}
}
```

рдпрд╣ рдЙрджрд╛рд╣рд░рдг UNet рдкрд░ 4тАСbit NF4 BnB рдФрд░ text encoder рдкрд░ TorchAO int4 рд╕рдХреНрд╖рдо рдХрд░рддрд╛ рд╣реИред

#### Torch Dynamo

WebUI рд╕реЗ `torch.compile()` рд╕рдХреНрд╖рдо рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП **Hardware тЖТ Accelerate (advanced)** рдкрд░ рдЬрд╛рдПрдБ рдФрд░ **Torch Dynamo Backend** рдХреЛ рдЕрдкрдиреЗ рдкрд╕рдВрджреАрджрд╛ compiler (рдЙрджрд╛. *inductor*) рдкрд░ рд╕реЗрдЯ рдХрд░реЗрдВред рдЕрддрд┐рд░рд┐рдХреНрдд toggles рдЖрдкрдХреЛ optimisation **mode** рдЪреБрдирдиреЗ, **dynamic shape** guards рд╕рдХреНрд╖рдо рдХрд░рдиреЗ, рдпрд╛ **regional compilation** optтАСin рдХрд░рдиреЗ рджреЗрддреЗ рд╣реИрдВ рддрд╛рдХрд┐ рдмрд╣реБрдд рдЧрд╣рд░реЗ transformer models рдкрд░ cold starts рддреЗрдЬрд╝ рд╣реЛ рд╕рдХреЗрдВред

рд╡рд╣реА рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди `config/config.env` рдореЗрдВ рдЗрд╕ рддрд░рд╣ рд╡реНрдпрдХреНрдд рдХреА рдЬрд╛ рд╕рдХрддреА рд╣реИ:

```bash
TRAINING_DYNAMO_BACKEND=inductor
```

рдЖрдк рдЗрд╕реЗ рд╡реИрдХрд▓реНрдкрд┐рдХ рд░реВрдк рд╕реЗ `--dynamo_mode=max-autotune` рдпрд╛ UI рдореЗрдВ рдЙрдкрд▓рдмреНрдз рдЕрдиреНрдп Dynamo flags рдХреЗ рд╕рд╛рде pair рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ рддрд╛рдХрд┐ finer control рдорд┐рд▓реЗред

рдзреНрдпрд╛рди рджреЗрдВ рдХрд┐ training рдХреЗ рдкрд╣рд▓реЗ рдХрдИ steps рд╕рд╛рдорд╛рдиреНрдп рд╕реЗ рдзреАрдореЗ рд╣реЛрдВрдЧреЗ рдХреНрдпреЛрдВрдХрд┐ compilation background рдореЗрдВ рд╣реЛ рд░рд╣реА рд╣реЛрддреА рд╣реИред

Settings рдХреЛ `config.json` рдореЗрдВ persist рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рд╕рдорд╛рди keys рдЬреЛрдбрд╝реЗрдВ:

```json
{
  "dynamo_backend": "inductor",
  "dynamo_mode": "max-autotune",
  "dynamo_fullgraph": false,
  "dynamo_dynamic": false,
  "dynamo_use_regional_compilation": true
}
```

рдпрджрд┐ рдЖрдк Accelerate defaults inherit рдХрд░рдирд╛ рдЪрд╛рд╣рддреЗ рд╣реИрдВ рддреЛ рд╕рдВрдмрдВрдзрд┐рдд entries рдЫреЛрдбрд╝ рджреЗрдВ (рдЙрджрд╛., `dynamo_mode` рди рджреЗрдВ рддрд╛рдХрд┐ automatic selection рдЙрдкрдпреЛрдЧ рд╣реЛ)ред

### `--attention_mechanism`

Alternative attention mechanisms рд╕рдорд░реНрдерд┐рдд рд╣реИрдВ, рдЬрд┐рдирдХреЗ compatibility рд╕реНрддрд░ рдпрд╛ tradeтАСoffs рдЕрд▓рдЧ рд╣реЛрддреЗ рд╣реИрдВ:

- `diffusers` PyTorch рдХреЗ native SDPA kernels рдЙрдкрдпреЛрдЧ рдХрд░рддрд╛ рд╣реИ рдФрд░ рдбрд┐рдлрд╝реЙрд▓реНрдЯ рд╣реИред
- `xformers` Meta рдХреЗ [xformers](https://github.com/facebookresearch/xformers) attention kernel (training + inference) рд╕рдХреНрд╖рдо рдХрд░рддрд╛ рд╣реИ, рдЬрдм underlying рдореЙрдбрд▓ `enable_xformers_memory_efficient_attention` expose рдХрд░рддрд╛ рд╣реИред
- `flash-attn`, `flash-attn-2`, `flash-attn-3`, рдФрд░ `flash-attn-3-varlen` Diffusers рдХреЗ рдирдП `attention_backend` helper рдХреЗ рдЬрд░рд┐рдП FlashAttention v1/2/3 kernels рдореЗрдВ route рдХрд░рддреЗ рд╣реИрдВред рд╕рдВрдмрдВрдзрд┐рдд `flash-attn` / `flash-attn-interface` wheels install рдХрд░реЗрдВ рдФрд░ рдзреНрдпрд╛рди рджреЗрдВ рдХрд┐ FA3 рдлрд┐рд▓рд╣рд╛рд▓ Hopper GPUs рдХреА рдорд╛рдВрдЧ рдХрд░рддрд╛ рд╣реИред
- `flex` PyTorch 2.5 рдХрд╛ FlexAttention backend рдЪреБрдирддрд╛ рд╣реИ (CUDA рдкрд░ FP16/BF16)ред рдЖрдкрдХреЛ Flex kernels рдЕрд▓рдЧ рд╕реЗ compile/install рдХрд░рдиреЗ рд╣реЛрдВрдЧреЗ тАФ рджреЗрдЦреЗрдВ [documentation/attention/FLEX.md](attention/FLEX.md)ред
- `cudnn`, `native-efficient`, `native-flash`, `native-math`, `native-npu`, рдФрд░ `native-xla` `torch.nn.attention.sdpa_kernel` рджреНрд╡рд╛рд░рд╛ expose рдХрд┐рдП рдЧрдП matching SDPA backend рдЪреБрдирддреЗ рд╣реИрдВред рдпреЗ рддрдм рдЙрдкрдпреЛрдЧреА рд╣реИрдВ рдЬрдм рдЖрдкрдХреЛ determinism (`native-math`), CuDNN SDPA kernel, рдпрд╛ vendorтАСnative accelerators (NPU/XLA) рдЪрд╛рд╣рд┐рдПред
- `sla` [SparseтАУLinear Attention (SLA)](https://github.com/thu-ml/SLA) рд╕рдХреНрд╖рдо рдХрд░рддрд╛ рд╣реИ, рдЬреЛ fineтАСtunable sparse/linear hybrid kernel рджреЗрддрд╛ рд╣реИ рдФрд░ training рддрдерд╛ validation рджреЛрдиреЛрдВ рдореЗрдВ рдмрд┐рдирд╛ рдЕрддрд┐рд░рд┐рдХреНрдд gating рдХреЗ рдЙрдкрдпреЛрдЧ рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИред
  - SLA package install рдХрд░реЗрдВ (рдЙрджрд╛. `pip install -e ~/src/SLA`) рдЗрд╕ backend рдХреЛ рдЪреБрдирдиреЗ рд╕реЗ рдкрд╣рд▓реЗред
  - SimpleTuner SLA рдХреЗ learned projection weights рд╣рд░ checkpoint рдореЗрдВ `sla_attention.pt` рдореЗрдВ рд╕реЗрд╡ рдХрд░рддрд╛ рд╣реИ; resume рдФрд░ inference рдХреЗ рд▓рд┐рдП рдЗрд╕ рдлрд╝рд╛рдЗрд▓ рдХреЛ рдмрд╛рдХреА checkpoint рдХреЗ рд╕рд╛рде рд░рдЦреЗрдВред
  - рдХреНрдпреЛрдВрдХрд┐ backbone рдХреЛ SLA рдХреЗ mixed sparse/linear behavior рдХреЗ рдЕрдиреБрд╕рд╛рд░ рдЯреНрдпреВрди рдХрд┐рдпрд╛ рдЧрдпрд╛ рд╣реИ, inference рд╕рдордп рдкрд░ рднреА SLA рдЖрд╡рд╢реНрдпрдХ рд╣реЛрдЧрд╛ред focused рдЧрд╛рдЗрдб рдХреЗ рд▓рд┐рдП `documentation/attention/SLA.md` рджреЗрдЦреЗрдВред
  - рдпрджрд┐ рдЬрд░реВрд░рдд рд╣реЛ рддреЛ SLA runtime defaults override рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП `--sla_config '{"topk":0.15,"blkq":32,"tie_feature_map_qk":false}'` (JSON рдпрд╛ Python dict syntax) рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВред
- `sageattention`, `sageattention-int8-fp16-triton`, `sageattention-int8-fp16-cuda`, рдФрд░ `sageattention-int8-fp8-cuda` рд╕рдВрдмрдВрдзрд┐рдд [SageAttention](https://github.com/thu-ml/SageAttention) kernels рдХреЛ wrap рдХрд░рддреЗ рд╣реИрдВред рдпреЗ inferenceтАСoriented рд╣реИрдВ рдФрд░ accidental training рд╕реЗ рдмрдЪрдиреЗ рдХреЗ рд▓рд┐рдП `--sageattention_usage` рдХреЗ рд╕рд╛рде рдЙрдкрдпреЛрдЧ рд╣реЛрдиреЗ рдЪрд╛рд╣рд┐рдПред
  - рд╕рд░рд▓ рд╢рдмреНрджреЛрдВ рдореЗрдВ, SageAttention inference рдХреЗ compute requirement рдХреЛ рдХрдо рдХрд░рддрд╛ рд╣реИ

> тД╣я╕П Flash/Flex/PyTorch backend selectors Diffusers рдХреЗ `attention_backend` dispatcher рдкрд░ рдирд┐рд░реНрднрд░ рд╣реИрдВ, рдЗрд╕рд▓рд┐рдП рд╡реЗ рд╡рд░реНрддрдорд╛рди рдореЗрдВ transformerтАСstyle models рдореЗрдВ рдЕрдзрд┐рдХ рд▓рд╛рдн рджреЗрддреЗ рд╣реИрдВ рдЬреЛ рдкрд╣рд▓реЗ рд╕реЗ рдЗрд╕ code path рдХреЛ рдЙрдкрдпреЛрдЧ рдХрд░рддреЗ рд╣реИрдВ (Flux, Wan 2.x, LTXVideo, QwenImage, рдЖрджрд┐)ред Classic SD/SDXL UNets рдЕрднреА рд╕реАрдзреЗ PyTorch SDPA рдЙрдкрдпреЛрдЧ рдХрд░рддреЗ рд╣реИрдВред

`--sageattention_usage` рдХреЗ рдЬрд░рд┐рдП SageAttention рдХреЗ рд╕рд╛рде training рд╕рдХреНрд╖рдо рдХрд░рдирд╛ рд╕рд╛рд╡рдзрд╛рдиреА рд╕реЗ рдХрд░рдирд╛ рдЪрд╛рд╣рд┐рдП, рдХреНрдпреЛрдВрдХрд┐ рдпрд╣ QKV linears рдХреЗ рд▓рд┐рдП рдЕрдкрдиреА custom CUDA implementations рд╕реЗ gradients track рдпрд╛ propagate рдирд╣реАрдВ рдХрд░рддрд╛ред

- рдЗрд╕рд╕реЗ рдпреЗ layers рдкреВрд░реА рддрд░рд╣ untrained рд░рд╣ рдЬрд╛рддреЗ рд╣реИрдВ, рдЬреЛ model collapse рдпрд╛ рдЫреЛрдЯреЗ training runs рдореЗрдВ рд╣рд▓реНрдХрд╛ рд╕реБрдзрд╛рд░ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред

---

## ЁЯУ░ Publishing

### `--push_to_hub`

- **What**: рдпрджрд┐ рджрд┐рдпрд╛ рдЧрдпрд╛, рддреЛ training рдкреВрд░реА рд╣реЛрдиреЗ рдкрд░ рдЖрдкрдХрд╛ рдореЙрдбрд▓ [Huggingface Hub](https://huggingface.co) рдкрд░ upload рд╣реЛрдЧрд╛ред `--push_checkpoints_to_hub` рдЙрдкрдпреЛрдЧ рдХрд░рдиреЗ рдкрд░ рд╣рд░ intermediary checkpoint рднреА push рд╣реЛрдЧрд╛ред

### `--push_to_hub_background`

- **What**: Hugging Face Hub рдкрд░ background worker рд╕реЗ uploads рдХрд░рддрд╛ рд╣реИ рддрд╛рдХрд┐ checkpoint pushes training loop рдХреЛ pause рди рдХрд░реЗрдВред
- **Why**: Hub uploads asynchronous рд░рд╣рддреЗ рд╣реБрдП training рдФрд░ validation рдЪрд▓рддреА рд░рд╣рддреА рд╣реИред Run рд╕рдорд╛рдкреНрдд рд╣реЛрдиреЗ рд╕реЗ рдкрд╣рд▓реЗ final uploads рдХреА рдкреНрд░рддреАрдХреНрд╖рд╛ рдХреА рдЬрд╛рддреА рд╣реИ рддрд╛рдХрд┐ failures surface рд╣реЛрдВред

### `--webhook_config`

- **What**: webhook targets (рдЙрджрд╛. Discord, custom endpoints) рдХреЗ рд▓рд┐рдП рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди рддрд╛рдХрд┐ realтАСtime training events рдорд┐рд▓ рд╕рдХреЗрдВред
- **Why**: рдмрд╛рд╣рд░реА tools рдФрд░ dashboards рдХреЗ рд╕рд╛рде training runs рдореЙрдирд┐рдЯрд░ рдХрд░рдиреЗ рджреЗрддрд╛ рд╣реИ рдФрд░ рдореБрдЦреНрдп training рдЪрд░рдгреЛрдВ рдкрд░ notifications рднреЗрдЬрддрд╛ рд╣реИред
- **Notes**: webhook payloads рдореЗрдВ `job_id` рдлрд╝реАрд▓реНрдб `SIMPLETUNER_JOB_ID` environment variable рд╕реЗрдЯ рдХрд░рдХреЗ рднрд░реА рдЬрд╛ рд╕рдХрддреА рд╣реИ:
  ```bash
  export SIMPLETUNER_JOB_ID="my-training-run-name"
  python train.py
  ```
рдпрд╣ рдЙрди monitoring tools рдХреЗ рд▓рд┐рдП рдЙрдкрдпреЛрдЧреА рд╣реИ рдЬреЛ рдХрдИ training runs рд╕реЗ webhooks рдкреНрд░рд╛рдкреНрдд рдХрд░рддреЗ рд╣реИрдВ рддрд╛рдХрд┐ рдпрд╣ рдкрддрд╛ рдЪрд▓реЗ рдХрд┐ рдХрд┐рд╕ config рдиреЗ event рднреЗрдЬрд╛ред рдпрджрд┐ SIMPLETUNER_JOB_ID рд╕реЗрдЯ рдирд╣реАрдВ рд╣реИ, рддреЛ webhook payloads рдореЗрдВ job_id null рд╣реЛрдЧрд╛ред

### `--publishing_config`

- **What**: nonтАСHugging Face publishing targets (S3тАСcompatible storage, Backblaze B2, Azure Blob Storage, Dropbox) рдХреЛ рд╡рд░реНрдгрд┐рдд рдХрд░рдиреЗ рд╡рд╛рд▓рд╛ optional JSON/dict/file path.
- **Why**: `--webhook_config` parsing рдХреЛ mirror рдХрд░рддрд╛ рд╣реИ рддрд╛рдХрд┐ artifacts рдХреЛ Hub рдХреЗ рдмрд╛рд╣рд░ рднреА fan out рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХреЗред Publishing validation рдХреЗ рдмрд╛рдж main process рдкрд░ current `output_dir` рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдЪрд▓рддрд╛ рд╣реИред
- **Notes**: Providers `--push_to_hub` рдХреЗ additive рд╣реИрдВред provider SDKs (рдЬреИрд╕реЗ `boto3`, `azure-storage-blob`, `dropbox`) рдХреЛ `.venv` рдореЗрдВ install рдХрд░реЗрдВ рдЬрдм рдЖрдк рдЗрдиреНрд╣реЗрдВ enable рдХрд░реЗрдВред рдкреВрд░реНрдг рдЙрджрд╛рд╣рд░рдгреЛрдВ рдХреЗ рд▓рд┐рдП `documentation/publishing/README.md` рджреЗрдЦреЗрдВред

### `--hub_model_id`

- **What**: Huggingface Hub рдореЙрдбрд▓ рдФрд░ local results directory рдХрд╛ рдирд╛рдоред
- **Why**: рдпрд╣ рдорд╛рди `--output_dir` рджреНрд╡рд╛рд░рд╛ рдирд┐рд░реНрджрд┐рд╖реНрдЯ рд╕реНрдерд╛рди рдХреЗ рдЕрдВрддрд░реНрдЧрдд directory рдирд╛рдо рдХреЗ рд░реВрдк рдореЗрдВ рдЙрдкрдпреЛрдЧ рд╣реЛрддрд╛ рд╣реИред рдпрджрд┐ `--push_to_hub` рджрд┐рдпрд╛ рдЧрдпрд╛ рд╣реИ, рддреЛ рдпрд╣реА Huggingface Hub рдкрд░ рдореЙрдбрд▓ рдХрд╛ рдирд╛рдо рд╣реЛрдЧрд╛ред

### `--modelspec_comment`

- **What**: safetensors рдлрд╝рд╛рдЗрд▓ metadata рдореЗрдВ `modelspec.comment` рдХреЗ рд░реВрдк рдореЗрдВ embedded text
- **Default**: None (disabled)
- **Notes**:
  - рдмрд╛рд╣рд░реА model viewers (ComfyUI, model info tools) рдореЗрдВ рджрд┐рдЦрд╛рдИ рджреЗрддрд╛ рд╣реИ
  - string рдпрд╛ strings рдХреА array (newlines рд╕реЗ рдЬреБрдбрд╝реА) рд╕реНрд╡реАрдХрд╛рд░ рдХрд░рддрд╛ рд╣реИ
  - environment variable substitution рдХреЗ рд▓рд┐рдП `{env:VAR_NAME}` placeholders support рдХрд░рддрд╛ рд╣реИ
  - рдкреНрд░рддреНрдпреЗрдХ checkpoint save рдХреЗ рд╕рдордп current config value рдЙрдкрдпреЛрдЧ рдХрд░рддрд╛ рд╣реИ

**Example (string)**:
```json
"modelspec_comment": "рдореЗрд░реЗ custom dataset v2.1 рдкрд░ trained"
```

**Example (array multi-line рдХреЗ рд▓рд┐рдП)**:
```json
"modelspec_comment": [
  "Training run: experiment-42",
  "Dataset: custom-portraits-v2",
  "Notes: {env:TRAINING_NOTES}"
]
```

### `--disable_benchmark`

- **What**: step 0 рдкрд░ base model рдХреЗ рд▓рд┐рдП рд╣реЛрдиреЗ рд╡рд╛рд▓реА startup validation/benchmark рдХреЛ disable рдХрд░рддрд╛ рд╣реИред рдпреЗ outputs рдЖрдкрдХреА trained model validation images рдХреЗ рдмрд╛рдПрдБ рд╣рд┐рд╕реНрд╕реЗ рдореЗрдВ stitched рд╣реЛрддреЗ рд╣реИрдВред

## ЁЯУВ Data Storage and Management

### `--data_backend_config`

- **What**: рдЖрдкрдХреЗ SimpleTuner dataset рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди рдХрд╛ path.
- **Why**: рдЕрд▓рдЧтАСрдЕрд▓рдЧ storage рдорд╛рдзреНрдпрдореЛрдВ рдкрд░ рдХрдИ datasets рдХреЛ рдПрдХ training session рдореЗрдВ рдЬреЛрдбрд╝рд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИред
- **Example**: рдЙрджрд╛рд╣рд░рдг рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди рдХреЗ рд▓рд┐рдП [multidatabackend.json.example](/multidatabackend.json.example) рджреЗрдЦреЗрдВ, рдФрд░ data loader рдХреЙрдиреНрдлрд╝рд┐рдЧрд░ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП [рдпрд╣ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝](DATALOADER.md) рджреЗрдЦреЗрдВред

### `--override_dataset_config`

- **What**: рджрд┐рдпрд╛ рдЬрд╛рдиреЗ рдкрд░, SimpleTuner cached config рдФрд░ current values рдХреЗ рдмреАрдЪ рдЕрдВрддрд░ рдХреЛ ignore рдХрд░реЗрдЧрд╛ред
- **Why**: рдХрд┐рд╕реА dataset рдкрд░ SimpleTuner рдкрд╣рд▓реА рдмрд╛рд░ рдЪрд▓рдиреЗ рдкрд░ рдпрд╣ dataset рдХреА рд╣рд░ рдЪреАрдЬрд╝ рдХреА рдЬрд╛рдирдХрд╛рд░реА рд╡рд╛рд▓рд╛ cache document рдмрдирд╛рддрд╛ рд╣реИ, рдЬрд┐рд╕рдореЗрдВ dataset config рднреА рд╢рд╛рдорд┐рд▓ рд╣реЛрддрд╛ рд╣реИ, рдЬреИрд╕реЗ рдЗрд╕рдХреЗ "crop" рдФрд░ "resolution" рд╕рдВрдмрдВрдзрд┐рдд рдорд╛рдиред рдЗрдиреНрд╣реЗрдВ рдордирдорд╛рдиреЗ рд░реВрдк рд╕реЗ рдпрд╛ рдЧрд▓рддреА рд╕реЗ рдмрджрд▓рдиреЗ рдкрд░ training jobs рдмреЗрддрд░рддреАрдм рд░реВрдк рд╕реЗ crash рд╣реЛ рд╕рдХрддреЗ рд╣реИрдВ, рдЗрд╕рд▓рд┐рдП рдЗрд╕ parameter рдХрд╛ рдЙрдкрдпреЛрдЧ рди рдХрд░рдиреЗ рдФрд░ рдмрджрд▓рд╛рд╡ рдХрд┐рд╕реА рдЕрдиреНрдп рддрд░реАрдХреЗ рд╕реЗ рдХрд░рдиреЗ рдХреА рд╕рд┐рдлрд╝рд╛рд░рд┐рд╢ рд╣реИред

### `--data_backend_sampling`

- **What**: рдХрдИ data backends рдХреЗ рд╕рд╛рде sampling рдЕрд▓рдЧ strategies рд╕реЗ рдХреА рдЬрд╛ рд╕рдХрддреА рд╣реИред
- **Options**:
  - `uniform` - v0.9.8.1 рдФрд░ рдкрд╣рд▓реЗ рдХрд╛ behavior рдЬрд╣рд╛рдБ dataset length consider рдирд╣реАрдВ рд╣реЛрддреА, рдХреЗрд╡рд▓ manual probability weightings рд▓реА рдЬрд╛рддреА рдереАрдВред
  - `auto-weighting` - рдбрд┐рдлрд╝реЙрд▓реНрдЯ behavior рдЬрд╣рд╛рдБ dataset length рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рд╕рднреА datasets рдХреЛ рд╕рдорд╛рди рд░реВрдк рд╕реЗ sample рдХрд┐рдпрд╛ рдЬрд╛рддрд╛ рд╣реИ, рддрд╛рдХрд┐ рдкреВрд░реЗ data distribution рдкрд░ uniform sampling рдмрдиреА рд░рд╣реЗред
    - рдпрд╣ рддрдм рдЖрд╡рд╢реНрдпрдХ рд╣реИ рдЬрдм рдЖрдкрдХреЗ datasets рдЕрд▓рдЧтАСрдЕрд▓рдЧ sizes рдХреЗ рд╣реЛрдВ рдФрд░ рдЖрдк рдЪрд╛рд╣рддреЗ рд╣реЛрдВ рдХрд┐ рдореЙрдбрд▓ рдЙрдиреНрд╣реЗрдВ рд╕рдорд╛рди рд░реВрдк рд╕реЗ рд╕реАрдЦреЗред
    - рд▓реЗрдХрд┐рди Dreambooth images рдХреЛ regularisation set рдХреЗ рд╡рд┐рд░реБрджреНрдз рд╕рд╣реА рддрд░рд╣ sample рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП `repeats` рдХреЛ manually adjust рдХрд░рдирд╛ **рдЖрд╡рд╢реНрдпрдХ** рд╣реИ

### `--vae_cache_scan_behaviour`

- **What**: integrity scan check рдХрд╛ рд╡реНрдпрд╡рд╣рд╛рд░ рдХреЙрдиреНрдлрд╝рд┐рдЧрд░ рдХрд░рддрд╛ рд╣реИред
- **Why**: dataset рдХреЗ рд▓рд┐рдП рдЧрд▓рдд settings training рдХреЗ рдХрдИ рдЪрд░рдгреЛрдВ рдкрд░ рд▓рд╛рдЧреВ рд╣реЛ рд╕рдХрддреЗ рд╣реИрдВ, рдЬреИрд╕реЗ рдпрджрд┐ рдЖрдк рдЧрд▓рддреА рд╕реЗ dataset рд╕реЗ `.json` cache files delete рдХрд░ рджреЗрдВ рдФрд░ data backend config рдХреЛ aspectтАСcrops рдХреА рдЬрдЧрд╣ square images рдХреЗ рд▓рд┐рдП switch рдХрд░ рджреЗрдВред рдЗрд╕рд╕реЗ data cache inconsistent рд╣реЛ рдЬрд╛рддрд╛ рд╣реИ, рдЬрд┐рд╕реЗ `multidatabackend.json` рдореЗрдВ `scan_for_errors` рдХреЛ `true` рд╕реЗрдЯ рдХрд░рдХреЗ рдареАрдХ рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИред рдЬрдм рдпрд╣ scan рдЪрд▓рддрд╛ рд╣реИ, рддреЛ рдпрд╣ `--vae_cache_scan_behaviour` рдХреЗ рдорд╛рди рдХреЗ рдЕрдиреБрд╕рд╛рд░ inconsistency рдХреЛ resolve рдХрд░рддрд╛ рд╣реИ: `recreate` (рдбрд┐рдлрд╝реЙрд▓реНрдЯ) offending cache entry рдХреЛ рд╣рдЯрд╛рддрд╛ рд╣реИ рддрд╛рдХрд┐ рд╡рд╣ рдлрд┐рд░ рд╕реЗ рдмрдирд╛рдИ рдЬрд╛ рд╕рдХреЗ, рдФрд░ `sync` bucket metadata рдХреЛ рд╡рд╛рд╕реНрддрд╡рд┐рдХ training sample рдХреЗ рдЕрдиреБрд░реВрдк рдЕрдкрдбреЗрдЯ рдХрд░рддрд╛ рд╣реИред рдЕрдиреБрд╢рдВрд╕рд┐рдд рдорд╛рди: `recreate`.

### `--dataloader_prefetch`

- **What**: batches рдХреЛ aheadтАСofтАСtime retrieve рдХрд░рддрд╛ рд╣реИред
- **Why**: рд╡рд┐рд╢реЗрд╖ рд░реВрдк рд╕реЗ рдмрдбрд╝реЗ batch sizes рдХреЗ рд╕рд╛рде, samples disk (рдпрд╣рд╛рдБ рддрдХ рдХрд┐ NVMe) рд╕реЗ рд▓реЛрдб рд╣реЛрдиреЗ рдкрд░ training "pause" рд╣реЛрддреА рд╣реИ, рдЬрд┐рд╕рд╕реЗ GPU utilisation metrics рдкреНрд░рднрд╛рд╡рд┐рдд рд╣реЛрддреЗ рд╣реИрдВред Dataloader prefetch рд╕рдХреНрд╖рдо рдХрд░рдиреЗ рдкрд░ рдкреВрд░реЗ batches рдХрд╛ buffer рднрд░рдХрд░ рд░рдЦрд╛ рдЬрд╛рддрд╛ рд╣реИ рддрд╛рдХрд┐ рд╡реЗ рддреБрд░рдВрдд load рд╣реЛ рд╕рдХреЗрдВред

> тЪая╕П рдпрд╣ рд╡рд╛рд╕реНрддрд╡ рдореЗрдВ рдХреЗрд╡рд▓ H100 рдпрд╛ рдмреЗрд╣рддрд░ GPU рдкрд░ рдХрдо resolution рдореЗрдВ рдЙрдкрдпреЛрдЧреА рд╣реИ рдЬрд╣рд╛рдБ I/O bottleneck рдмрдирддрд╛ рд╣реИред рдЕрдзрд┐рдХрд╛рдВрд╢ рдЕрдиреНрдп рдЙрдкрдпреЛрдЧ рдорд╛рдорд▓реЛрдВ рдореЗрдВ рдпрд╣ рдЕрдирд╛рд╡рд╢реНрдпрдХ рдЬрдЯрд┐рд▓рддрд╛ рд╣реИред

### `--dataloader_prefetch_qlen`

- **What**: memory рдореЗрдВ рд░рдЦреЗ рдЧрдП batches рдХреА рд╕рдВрдЦреНрдпрд╛ рдмрдврд╝рд╛рддрд╛ рдпрд╛ рдШрдЯрд╛рддрд╛ рд╣реИред
- **Why**: dataloader prefetch рдХреЗ рд╕рд╛рде, рдбрд┐рдлрд╝реЙрд▓реНрдЯ рд░реВрдк рд╕реЗ рдкреНрд░рддрд┐ GPU/process 10 entries memory рдореЗрдВ рд░рдЦреА рдЬрд╛рддреА рд╣реИрдВред рдпрд╣ рдмрд╣реБрдд рдЕрдзрд┐рдХ рдпрд╛ рдмрд╣реБрдд рдХрдо рд╣реЛ рд╕рдХрддрд╛ рд╣реИред рдЗрд╕ рдорд╛рди рдХреЛ рдмрджрд▓рдХрд░ batches рдХреА рд╕рдВрдЦреНрдпрд╛ рд╕рдорд╛рдпреЛрдЬрд┐рдд рдХреА рдЬрд╛ рд╕рдХрддреА рд╣реИред

### `--compress_disk_cache`

- **What**: VAE рдФрд░ text embed caches рдХреЛ disk рдкрд░ compress рдХрд░рддрд╛ рд╣реИред
- **Why**: DeepFloyd, SD3, рдФрд░ PixArt рдореЗрдВ рдЙрдкрдпреЛрдЧ рд╣реЛрдиреЗ рд╡рд╛рд▓рд╛ T5 encoder рдмрд╣реБрдд рдмрдбрд╝реЗ text embeds рдмрдирд╛рддрд╛ рд╣реИ рдЬреЛ рдЫреЛрдЯреЗ рдпрд╛ redundant captions рдХреЗ рд▓рд┐рдП mostly empty space рд╣реЛрддреЗ рд╣реИрдВред `--compress_disk_cache` рд╕рдХреНрд╖рдо рдХрд░рдиреЗ рд╕реЗ space рдЙрдкрдпреЛрдЧ 75% рддрдХ рдШрдЯ рд╕рдХрддрд╛ рд╣реИ, рдФрд╕рддрди 40% рдмрдЪрдд рдХреЗ рд╕рд╛рдеред

> тЪая╕П рдЖрдкрдХреЛ рдореМрдЬреВрджрд╛ cache directories рдореИрдиреНрдпреБрдЕрд▓ рд░реВрдк рд╕реЗ рд╣рдЯрд╛рдиреЗ рд╣реЛрдВрдЧреЗ рддрд╛рдХрд┐ trainer рдЙрдиреНрд╣реЗрдВ compression рдХреЗ рд╕рд╛рде рдлрд┐рд░ рд╕реЗ рдмрдирд╛ рд╕рдХреЗред

---

## ЁЯМИ Image рдФрд░ Text Processing

рдХрдИ рд╕реЗрдЯрд┐рдВрдЧреНрд╕ [dataloader config](DATALOADER.md) рдореЗрдВ рд╕реЗрдЯ рд╣реЛрддреА рд╣реИрдВ, рд▓реЗрдХрд┐рди рдпреЗ global рд░реВрдк рд╕реЗ рд▓рд╛рдЧреВ рд╣реЛрдВрдЧреАред

### `--resolution_type`

- **What**: рдпрд╣ SimpleTuner рдХреЛ рдмрддрд╛рддрд╛ рд╣реИ рдХрд┐ `area` size calculations рдЙрдкрдпреЛрдЧ рдХрд░рдиреА рд╣реИрдВ рдпрд╛ `pixel` edge calculationsред `pixel_area` рдХрд╛ hybrid approach рднреА рд╕рдорд░реНрдерд┐рдд рд╣реИ, рдЬреЛ `area` measurements рдХреЗ рд▓рд┐рдП megapixel рдХреА рдмрдЬрд╛рдп pixel рдЙрдкрдпреЛрдЧ рдХрд░рдиреЗ рджреЗрддрд╛ рд╣реИред
- **Options**:
  - `resolution_type=pixel_area`
    - `resolution` рдХрд╛ рдорд╛рди 1024 рд╣реЛрдиреЗ рдкрд░ рдпрд╣ internally efficient aspect bucketing рдХреЗ рд▓рд┐рдП рд╕рдЯреАрдХ area measurement рдореЗрдВ рдореИрдк рд╣реЛрдЧрд╛ред
    - `1024` рдХреЗ рд▓рд┐рдП рдЙрджрд╛рд╣рд░рдг рдЖрдХрд╛рд░: 1024x1024, 1216x832, 832x1216
  - `resolution_type=pixel`
    - dataset рдХреА рд╕рднреА images рдХрд╛ рдЫреЛрдЯрд╛ edge рдЗрд╕ resolution рддрдХ resize рд╣реЛрдЧрд╛, рдЬрд┐рд╕рд╕реЗ resulting images рдмрдбрд╝реЗ рд╣реЛ рд╕рдХрддреЗ рд╣реИрдВ рдФрд░ VRAM рдЙрдкрдпреЛрдЧ рдмрдврд╝ рд╕рдХрддрд╛ рд╣реИред
    - `1024` рдХреЗ рд▓рд┐рдП рдЙрджрд╛рд╣рд░рдг рдЖрдХрд╛рд░: 1024x1024, 1766x1024, 1024x1766
  - `resolution_type=area`
    - **Deprecated**. рдЗрд╕рдХреА рдЬрдЧрд╣ `pixel_area` рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВред

### `--resolution`

- **What**: input image resolution, pixel edge length рдореЗрдВ рд╡реНрдпрдХреНрдд
- **Default**: 1024
- **Note**: рдпрджрд┐ dataset рдореЗрдВ resolution рд╕реЗрдЯ рдирд╣реАрдВ рд╣реИ, рддреЛ рдпрд╣реА global default рдЙрдкрдпреЛрдЧ рд╣реЛрдЧрд╛ред

### `--validation_resolution`

- **What**: output image resolution, pixels рдореЗрдВ; рдпрд╛ `widthxheight` рдлрд╝реЙрд░реНрдореИрдЯ рдореЗрдВ, рдЬреИрд╕реЗ `1024x1024`ред Multiple resolutions рдХреЛ comma рд╕реЗ рдЕрд▓рдЧ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред
- **Why**: validation рдХреЗ рджреМрд░рд╛рди рдмрдирдиреЗ рд╡рд╛рд▓реА рд╕рднреА images рдЗрд╕реА resolution рдкрд░ рд╣реЛрдВрдЧреАред рдпрд╣ рддрдм рдЙрдкрдпреЛрдЧреА рд╣реИ рдЬрдм рдореЙрдбрд▓ рдЕрд▓рдЧ resolution рдкрд░ train рд╣реЛ рд░рд╣рд╛ рд╣реЛред

### `--validation_method`

- **What**: validation runs рдХреИрд╕реЗ execute рд╣реЛрдВ, рдпрд╣ рдЪреБрдиреЗрдВред
- **Options**: `simpletuner-local` (рдбрд┐рдлрд╝реЙрд▓реНрдЯ) builtтАСin pipeline рдЪрд▓рд╛рддрд╛ рд╣реИ; `external-script` userтАСprovided executable рдЪрд▓рд╛рддрд╛ рд╣реИред
- **Why**: training рдХреЛ local pipeline work рдореЗрдВ рд░реЛрдХреЗ рдмрд┐рдирд╛ validation рдХреЛ external system рдореЗрдВ рд╣реИрдВрдбтАСрдСрдл рдХрд░рдиреЗ рджреЗрддрд╛ рд╣реИред

### `--validation_external_script`

- **What**: `--validation_method=external-script` рд╣реЛрдиреЗ рдкрд░ рдЪрд▓рд╛рдпрд╛ рдЬрд╛рдиреЗ рд╡рд╛рд▓рд╛ executableред рдпрд╣ shellтАСstyle splitting рдЙрдкрдпреЛрдЧ рдХрд░рддрд╛ рд╣реИ, рдЗрд╕рд▓рд┐рдП command string рдХреЛ рдареАрдХ рд╕реЗ quote рдХрд░реЗрдВред
- **Placeholders**: рдЖрдк training context рдкрд╛рд╕ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдЗрди tokens рдХреЛ embed рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ (`.format` рдХреЗ рд╕рд╛рде)ред Missing values рдЦрд╛рд▓реА string рд╕реЗ replace рд╣реЛрддреА рд╣реИрдВ рдЬрдм рддрдХ рдХрд┐ рдЙрд▓реНрд▓реЗрдЦ рди рдХрд┐рдпрд╛ рдЧрдпрд╛ рд╣реЛ:
  - `{local_checkpoint_path}` тЖТ `output_dir` рдХреЗ рдЕрдВрддрд░реНрдЧрдд latest checkpoint directory (рдХрдо рд╕реЗ рдХрдо рдПрдХ checkpoint рдЖрд╡рд╢реНрдпрдХ)ред
  - `{global_step}` тЖТ current global step.
  - `{tracker_run_name}` тЖТ `--tracker_run_name` рдХрд╛ рдорд╛рди.
  - `{tracker_project_name}` тЖТ `--tracker_project_name` рдХрд╛ рдорд╛рди.
  - `{model_family}` тЖТ `--model_family` рдХрд╛ рдорд╛рди.
  - `{model_type}` / `{lora_type}` тЖТ model type рдФрд░ LoRA flavour.
  - `{huggingface_path}` тЖТ `--hub_model_id` рдХрд╛ рдорд╛рди (рдпрджрд┐ рд╕реЗрдЯ рд╣реЛ)ред
  - `{remote_checkpoint_path}` тЖТ last upload рдХрд╛ remote URL (validation hook рдХреЗ рд▓рд┐рдП empty)ред
  - рдХреЛрдИ рднреА `validation_*` config value (рдЙрджрд╛., `validation_num_inference_steps`, `validation_guidance`, `validation_noise_scheduler`).
- **Example**: `--validation_external_script="/opt/tools/validate.sh {local_checkpoint_path} {global_step}"`

### `--validation_external_background`

- **What**: рд╕реЗрдЯ рд╣реЛрдиреЗ рдкрд░ `--validation_external_script` background рдореЗрдВ launch рд╣реЛрддрд╛ рд╣реИ (fireтАСandтАСforget)ред
- **Why**: external script рдХрд╛ рдЗрдВрддрдЬрд╝рд╛рд░ рдХрд┐рдП рдмрд┐рдирд╛ training рдЪрд▓рддреА рд░рд╣рддреА рд╣реИ; рдЗрд╕ рдореЛрдб рдореЗрдВ exit codes check рдирд╣реАрдВ рд╣реЛрддреЗред

### `--post_upload_script`

- **What**: рд╣рд░ publishing provider рдФрд░ Hugging Face Hub upload (final model рдФрд░ checkpoint uploads) рдХреЗ рдмрд╛рдж optional executable рдЪрд▓рддрд╛ рд╣реИред рдпрд╣ asynchronous рдЪрд▓рддрд╛ рд╣реИ рддрд╛рдХрд┐ training block рди рд╣реЛред
- **Placeholders**: `--validation_external_script` рдЬреИрд╕реЗ replacements, рд╕рд╛рде рд╣реА `{remote_checkpoint_path}` (provider рджреНрд╡рд╛рд░рд╛ рд▓реМрдЯрд╛рдпрд╛ рдЧрдпрд╛ URI) рддрд╛рдХрд┐ рдЖрдк published URL downstream systems рдХреЛ рднреЗрдЬ рд╕рдХреЗрдВред
- **Notes**:
  - scripts рд╣рд░ provider/upload рдкрд░ рдЪрд▓рддреА рд╣реИрдВ; errors рд▓реЙрдЧ рд╣реЛрддреЗ рд╣реИрдВ рд▓реЗрдХрд┐рди training рд░реЛрдХрддреЗ рдирд╣реАрдВред
  - рдЬрдм рдХреЛрдИ remote upload рди рд╣реЛ рддрдм рднреА scripts invoke рд╣реЛрддреА рд╣реИрдВ, рддрд╛рдХрд┐ рдЖрдк local automation (рдЙрджрд╛., рджреВрд╕рд░реЗ GPU рдкрд░ inference) рдЪрд▓рд╛ рд╕рдХреЗрдВред
  - SimpleTuner рдЖрдкрдХреА script рдХреЗ рдкрд░рд┐рдгрд╛рдо ingest рдирд╣реАрдВ рдХрд░рддрд╛ тАФ metrics рдпрд╛ images рд░рд┐рдХреЙрд░реНрдб рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рд╕реАрдзреЗ рдЕрдкрдиреЗ tracker рдкрд░ рд▓реЙрдЧ рдХрд░реЗрдВред
- **Example**:
  ```bash
  --post_upload_script='/opt/hooks/notify.sh {remote_checkpoint_path} {tracker_project_name} {tracker_run_name}'
  ```
  рдЬрд╣рд╛рдБ `/opt/hooks/notify.sh` рдЖрдкрдХреЗ tracking system рдХреЛ post рдХрд░ рд╕рдХрддрд╛ рд╣реИ:
  ```bash
  #!/usr/bin/env bash
  REMOTE="$1"
  PROJECT="$2"
  RUN="$3"
  curl -X POST "https://tracker.internal/api/runs/${PROJECT}/${RUN}/artifacts" \
       -H "Content-Type: application/json" \
       -d "{\"remote_uri\":\"${REMOTE}\"}"
  ```
- **Working samples**:
  - `simpletuner/examples/external-validation/replicate_post_upload.py` рдПрдХ Replicate hook рджрд┐рдЦрд╛рддрд╛ рд╣реИ рдЬреЛ `{remote_checkpoint_path}`, `{model_family}`, `{model_type}`, `{lora_type}`, рдФрд░ `{huggingface_path}` consume рдХрд░рдХреЗ uploads рдХреЗ рдмрд╛рдж inference рдЯреНрд░рд┐рдЧрд░ рдХрд░рддрд╛ рд╣реИред
  - `simpletuner/examples/external-validation/wavespeed_post_upload.py` рд╡рд╣реА placeholders рдХреЗ рд╕рд╛рде WaveSpeed hook рджрд┐рдЦрд╛рддрд╛ рд╣реИ рдФрд░ WaveSpeed рдХреА async polling рдЙрдкрдпреЛрдЧ рдХрд░рддрд╛ рд╣реИред
  - `simpletuner/examples/external-validation/fal_post_upload.py` fal.ai Flux LoRA hook рджрд┐рдЦрд╛рддрд╛ рд╣реИ (`FAL_KEY` рдЖрд╡рд╢реНрдпрдХ)ред
  - `simpletuner/examples/external-validation/use_second_gpu.py` secondary GPU рдкрд░ Flux LoRA inference рдЪрд▓рд╛рддрд╛ рд╣реИ рдФрд░ remote uploads рдХреЗ рдмрд┐рдирд╛ рднреА рдХрд╛рдо рдХрд░рддрд╛ рд╣реИред

### `--post_checkpoint_script`

- **What**: рд╣рд░ checkpoint directory disk рдкрд░ рд▓рд┐рдЦреЗ рдЬрд╛рдиреЗ рдХреЗ рддреБрд░рдВрдд рдмрд╛рдж рдЪрд▓рд╛рдпрд╛ рдЬрд╛рдиреЗ рд╡рд╛рд▓рд╛ executable (uploads рд╢реБрд░реВ рд╣реЛрдиреЗ рд╕реЗ рдкрд╣рд▓реЗ)ред main process рдкрд░ asynchronous рдЪрд▓рддрд╛ рд╣реИред
- **Placeholders**: `--validation_external_script` рдЬреИрд╕реЗ replacements, рдЬрд┐рдирдореЗрдВ `{local_checkpoint_path}`, `{global_step}`, `{tracker_run_name}`, `{tracker_project_name}`, `{model_family}`, `{model_type}`, `{lora_type}`, `{huggingface_path}` рдФрд░ рдХреЛрдИ рднреА `validation_*` config value рд╢рд╛рдорд┐рд▓ рд╣реИрдВред `{remote_checkpoint_path}` рдЗрд╕ hook рдХреЗ рд▓рд┐рдП рдЦрд╛рд▓реА рд╣реЛрддрд╛ рд╣реИред
- **Notes**:
  - Scheduled, manual, рдФрд░ rolling checkpoints рдкрд░ рдпрд╣ рддрдм fire рд╣реЛрддрд╛ рд╣реИ рдЬрдм local save рдкреВрд░рд╛ рд╣реЛ рдЬрд╛рдПред
  - Local automation (рджреВрд╕рд░реЗ volume рдкрд░ copy, eval jobs рдЪрд▓рд╛рдирд╛) рдХреЗ рд▓рд┐рдП рдЙрдкрдпреЛрдЧреА рд╣реИ, uploads рдХреЗ рдЦрддреНрдо рд╣реЛрдиреЗ рдХрд╛ рдЗрдВрддрдЬрд╝рд╛рд░ рдХрд┐рдП рдмрд┐рдирд╛ред
- **Example**:
  ```bash
  --post_checkpoint_script='/opt/hooks/run_eval.sh {local_checkpoint_path} {global_step}'
  ```


### `--validation_adapter_path`

- **What**: scheduled validations рдЪрд▓рд╛рддреЗ рд╕рдордп рдЕрд╕реНрдерд╛рдпреА рд░реВрдк рд╕реЗ рдПрдХ single LoRA adapter рд▓реЛрдб рдХрд░рддрд╛ рд╣реИред
- **Formats**:
  - Hugging Face repo: `org/repo` рдпрд╛ `org/repo:weight_name.safetensors` (рдбрд┐рдлрд╝реЙрд▓реНрдЯ `pytorch_lora_weights.safetensors`).
  - Local file рдпрд╛ directory path рдЬреЛ safetensors adapter рдХреА рдУрд░ рдЗрд╢рд╛рд░рд╛ рдХрд░реЗред
- **Notes**:
  - `--validation_adapter_config` рдХреЗ рд╕рд╛рде mutually exclusive; рджреЛрдиреЛрдВ рджреЗрдиреЗ рдкрд░ error рдЖрддрд╛ рд╣реИред
  - adapter рдХреЗрд╡рд▓ validation runs рдХреЗ рд▓рд┐рдП attach рд╣реЛрддрд╛ рд╣реИ (baseline training weights untouched рд░рд╣рддреЗ рд╣реИрдВ)ред

### `--validation_adapter_name`

- **What**: `--validation_adapter_path` рд╕реЗ рд▓реЛрдб рдХрд┐рдП рдЧрдП рдЕрд╕реНрдерд╛рдпреА adapter рдХреЗ рд▓рд┐рдП optional identifier.
- **Why**: logs/Web UI рдореЗрдВ adapter run рдХреЛ label рдХрд░рдиреЗ рдФрд░ рдХрдИ adapters sequentially test рд╣реЛрдиреЗ рдкрд░ predictable names рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдПред

### `--validation_adapter_strength`

- **What**: рдЕрд╕реНрдерд╛рдпреА adapter enable рд╣реЛрдиреЗ рдкрд░ strength multiplier (рдбрд┐рдлрд╝реЙрд▓реНрдЯ `1.0`).
- **Why**: training state рдмрджрд▓реЗ рдмрд┐рдирд╛ validation рдХреЗ рджреМрд░рд╛рди рд╣рд▓реНрдХрд╛/рддреЗрдЬрд╝ LoRA scaling sweep рдХрд░рдиреЗ рджреЗрддрд╛ рд╣реИ; рд╢реВрдиреНрдп рд╕реЗ рдмрдбрд╝рд╛ рдХреЛрдИ рднреА рдорд╛рди рд╕реНрд╡реАрдХрд╛рд░ рд╣реЛрддрд╛ рд╣реИред

### `--validation_adapter_mode`

- **Choices**: `adapter_only`, `comparison`, `none`
- **What**:
  - `adapter_only`: рдХреЗрд╡рд▓ рдЕрд╕реНрдерд╛рдпреА adapter рдХреЗ рд╕рд╛рде validations рдЪрд▓рд╛рдПрдБред
  - `comparison`: baseтАСmodel рдФрд░ adapterтАСenabled samples рджреЛрдиреЛрдВ рдЬрдирд░реЗрдЯ рдХрд░реЗрдВ рддрд╛рдХрд┐ sideтАСbyтАСside рд╕рдореАрдХреНрд╖рд╛ рд╣реЛ рд╕рдХреЗред
  - `none`: adapter attach рдХрд░рдирд╛ рдЫреЛрдбрд╝ рджреЗрдВ (CLI flags рд╣рдЯрд╛рдП рдмрд┐рдирд╛ рдлреАрдЪрд░ disable рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдЙрдкрдпреЛрдЧреА)ред

### `--validation_adapter_config`

- **What**: multiple validation adapter combinations рдХреЛ iterate рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП JSON file рдпрд╛ inline JSON.
- **Format**: entries рдХреА array рдпрд╛ `runs` array рд╡рд╛рд▓рд╛ objectред рд╣рд░ entry рдореЗрдВ рд╢рд╛рдорд┐рд▓ рд╣реЛ рд╕рдХрддрд╛ рд╣реИ:
  - `label`: logs/UI рдореЗрдВ рджрд┐рдЦрдиреЗ рд╡рд╛рд▓рд╛ friendly name.
  - `path`: Hugging Face repo ID рдпрд╛ local path (`--validation_adapter_path` рдЬреИрд╕рд╛ format)ред
  - `adapter_name`: рдкреНрд░рддрд┐ adapter optional identifier.
  - `strength`: optional scalar override.
  - `adapters`/`paths`: рдПрдХ рд╣реА run рдореЗрдВ multiple adapters рд▓реЛрдб рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП objects/strings рдХреА array.
- **Notes**:
  - рдпрд╣ рдкреНрд░рджрд╛рди рд╣реЛрдиреЗ рдкрд░ singleтАСadapter options (`--validation_adapter_path`, `--validation_adapter_name`, `--validation_adapter_strength`, `--validation_adapter_mode`) UI рдореЗрдВ ignore/disable рд╣реЛ рдЬрд╛рддреЗ рд╣реИрдВред
  - рд╣рд░ run рдХреЛ рдПрдХтАСрдПрдХ рдХрд░рдХреЗ load рдХрд┐рдпрд╛ рдЬрд╛рддрд╛ рд╣реИ рдФрд░ рдЕрдЧрд▓рд╛ рд╢реБрд░реВ рд╣реЛрдиреЗ рд╕реЗ рдкрд╣рд▓реЗ рдкреВрд░реА рддрд░рд╣ detach рдХрд┐рдпрд╛ рдЬрд╛рддрд╛ рд╣реИред

### `--validation_preview`

- **What**: Tiny AutoEncoders рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ diffusion sampling рдХреЗ рджреМрд░рд╛рди intermediate validation previews stream рдХрд░рддрд╛ рд╣реИ
- **Default**: False
- **Why**: validation images рдХреЗ generate рд╣реЛрдиреЗ рдХреЗ рджреМрд░рд╛рди realтАСtime preview рд╕рдХреНрд╖рдо рдХрд░рддрд╛ рд╣реИ; lightweight Tiny AutoEncoder models рджреНрд╡рд╛рд░рд╛ decode рд╣реЛрдХрд░ webhook callbacks рд╕реЗ рднреЗрдЬреЗ рдЬрд╛рддреЗ рд╣реИрдВред рдЗрд╕рд╕реЗ рдЖрдк рдкреВрд░реА generation рдХрд╛ рдЗрдВрддрдЬрд╝рд╛рд░ рдХрд┐рдП рдмрд┐рдирд╛ stepтАСbyтАСstep progress рджреЗрдЦ рд╕рдХрддреЗ рд╣реИрдВред
- **Notes**:
  - рдХреЗрд╡рд▓ Tiny AutoEncoder support рд╡рд╛рд▓реЗ model families рдкрд░ рдЙрдкрд▓рдмреНрдз (рдЙрджрд╛., Flux, SDXL, SD3)
  - preview images рдкреНрд░рд╛рдкреНрдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП webhook configuration рдЖрд╡рд╢реНрдпрдХ
  - previews рдХрд┐рддрдиреА рдмрд╛рд░ decode рд╣реЛрдВ, рдпрд╣ рдирд┐рдпрдВрддреНрд░рд┐рдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП `--validation_preview_steps` рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВ

### `--validation_preview_steps`

- **What**: validation previews decode рдФрд░ stream рдХрд░рдиреЗ рдХрд╛ interval
- **Default**: 1
- **Why**: validation sampling рдХреЗ рджреМрд░рд╛рди intermediate latents рдХрд┐рддрдиреА рдмрд╛рд░ decode рд╣реЛрдВ, рдпрд╣ рдирд┐рдпрдВрддреНрд░рд┐рдд рдХрд░рддрд╛ рд╣реИред рдЙрдЪреНрдЪ рдорд╛рди (рдЙрджрд╛. 3) Tiny AutoEncoder рдХрд╛ overhead рдШрдЯрд╛рддрд╛ рд╣реИ рдХреНрдпреЛрдВрдХрд┐ рд╣рд░ N steps рдкрд░ decode рд╣реЛрддрд╛ рд╣реИред
- **Example**: `--validation_num_inference_steps=20` рдФрд░ `--validation_preview_steps=5` рдХреЗ рд╕рд╛рде, generation process рдХреЗ рджреМрд░рд╛рди 4 preview images рдорд┐рд▓реЗрдВрдЧреА (steps 5, 10, 15, 20 рдкрд░)ред

### `--evaluation_type`

- **What**: validations рдХреЗ рджреМрд░рд╛рди generated images рдХреА CLIP evaluation рд╕рдХреНрд╖рдо рдХрд░реЗрдВред
- **Why**: CLIP scores validation prompt рдХреЗ рд╕рд╛рде generated image features рдХреА рджреВрд░реА рдирд┐рдХрд╛рд▓рддреЗ рд╣реИрдВред рдЗрд╕рд╕реЗ prompt adherence рдореЗрдВ рд╕реБрдзрд╛рд░ рдХрд╛ рд╕рдВрдХреЗрдд рдорд┐рд▓ рд╕рдХрддрд╛ рд╣реИ, рд▓реЗрдХрд┐рди рд╕рд╛рд░реНрдердХ рдкрд░рд┐рдгрд╛рдореЛрдВ рдХреЗ рд▓рд┐рдП рдмрдбрд╝реА рд╕рдВрдЦреНрдпрд╛ рдореЗрдВ validation prompts рдЪрд╛рд╣рд┐рдПред
- **Options**: "none" рдпрд╛ "clip"
- **Scheduling**: stepтАСbased scheduling рдХреЗ рд▓рд┐рдП `--eval_steps_interval` рдпрд╛ epochтАСbased scheduling рдХреЗ рд▓рд┐рдП `--eval_epoch_interval` рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВ (fractions рдЬреИрд╕реЗ `0.5` рдкреНрд░рддрд┐ epoch рдХрдИ рдмрд╛рд░ рдЪрд▓реЗрдВрдЧреЗ)ред рдпрджрд┐ рджреЛрдиреЛрдВ рд╕реЗрдЯ рд╣реЛрдВ, trainer warning рд▓реЙрдЧ рдХрд░реЗрдЧрд╛ рдФрд░ рджреЛрдиреЛрдВ schedules рдЪрд▓рд╛рдПрдЧрд╛ред

### `--eval_loss_disable`

- **What**: validation рдХреЗ рджреМрд░рд╛рди evaluation loss рдЧрдгрдирд╛ disable рдХрд░реЗрдВред
- **Why**: рдЬрдм eval dataset рдХреЙрдиреНрдлрд╝рд┐рдЧрд░ рд╣реЛ, loss рд╕реНрд╡рддрдГ рдЧрдгрдирд╛ рд╣реЛрддрд╛ рд╣реИред рдпрджрд┐ CLIP evaluation рд╕рдХреНрд╖рдо рд╣реИ, рддреЛ рджреЛрдиреЛрдВ рдЪрд▓реЗрдВрдЧреЗред рдпрд╣ flag eval loss рдХреЛ disable рдХрд░рдиреЗ рджреЗрддрд╛ рд╣реИ рдЬрдмрдХрд┐ CLIP evaluation рдЪрд╛рд▓реВ рд░рд╣рддрд╛ рд╣реИред

### `--validation_using_datasets`

- **What**: pure text-to-image generation рдХреЗ рдмрдЬрд╛рдп training datasets рд╕реЗ images validation рдХреЗ рд▓рд┐рдП use рдХрд░реЗрдВред
- **Why**: image-to-image (img2img) рдпрд╛ image-to-video (i2v) validation mode enable рдХрд░рддрд╛ рд╣реИ рдЬрд╣рд╛рдБ model training images рдХреЛ conditioning inputs рдХреЗ рд░реВрдк рдореЗрдВ use рдХрд░рддрд╛ рд╣реИред рдЙрдкрдпреЛрдЧреА рд╣реИ:
  - Edit/inpainting models test рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдЬрд┐рдиреНрд╣реЗрдВ input images рдЪрд╛рд╣рд┐рдП
  - Model image structure рдХреЛ рдХрд┐рддрдирд╛ preserve рдХрд░рддрд╛ рд╣реИ evaluate рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП
  - Dual text-to-image AND image-to-image workflows support рдХрд░рдиреЗ рд╡рд╛рд▓реЗ models рдХреЗ рд▓рд┐рдП (рдЬреИрд╕реЗ, Flux2, LTXVideo2)
  - **I2V video models** (HunyuanVideo, WAN, Kandinsky5Video): image dataset рд╕реЗ images рдХреЛ video generation validation рдХреЗ рд▓рд┐рдП first-frame conditioning input рдХреЗ рд░реВрдк рдореЗрдВ use рдХрд░реЗрдВ
- **Notes**:
  - Model рдореЗрдВ `IMG2IMG` рдпрд╛ `IMG2VIDEO` pipeline registered рд╣реЛрдирд╛ рдЪрд╛рд╣рд┐рдП
  - `--eval_dataset_id` рдХреЗ рд╕рд╛рде combine рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ specific dataset рд╕реЗ images рд▓реЗрдиреЗ рдХреЗ рд▓рд┐рдП
  - i2v models рдХреЗ рд▓рд┐рдП, рдпрд╣ training рдореЗрдВ use рд╣реЛрдиреЗ рд╡рд╛рд▓реА complex conditioning dataset pairing setup рдХреЗ рдмрд┐рдирд╛ simple image dataset validation рдХреЗ рд▓рд┐рдП use рдХрд░рдиреЗ рджреЗрддрд╛ рд╣реИ
  - Denoising strength normal validation timestep settings рд╕реЗ control рд╣реЛрддреА рд╣реИ

### `--eval_dataset_id`

- **What**: Evaluation/validation image sourcing рдХреЗ рд▓рд┐рдП specific dataset IDред
- **Why**: `--validation_using_datasets` рдпрд╛ conditioning-based validation use рдХрд░рддреЗ рд╕рдордп, рдпрд╣ control рдХрд░рддрд╛ рд╣реИ рдХреМрди рд╕рд╛ dataset input images provide рдХрд░реЗ:
  - рдЗрд╕ option рдХреЗ рдмрд┐рдирд╛, images рд╕рднреА training datasets рд╕реЗ randomly select рд╣реЛрддреА рд╣реИрдВ
  - рдЗрд╕ option рдХреЗ рд╕рд╛рде, рдХреЗрд╡рд▓ specified dataset validation inputs рдХреЗ рд▓рд┐рдП use рд╣реЛрддрд╛ рд╣реИ
- **Notes**:
  - Dataset ID рдЖрдкрдХреЗ dataloader config рдореЗрдВ configured dataset рд╕реЗ match рд╣реЛрдирд╛ рдЪрд╛рд╣рд┐рдП
  - Dedicated eval dataset use рдХрд░рдХреЗ consistent evaluation maintain рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП useful
  - Conditioning models рдХреЗ рд▓рд┐рдП, dataset рдХрд╛ conditioning data (рдпрджрд┐ рд╣реЛ) рднреА use рд╣реЛрдЧрд╛

---

## Conditioning рдФрд░ Validation Modes рдХреЛ рд╕рдордЭрдирд╛

SimpleTuner conditioning inputs (reference images, control signals, рдЖрджрд┐) use рдХрд░рдиреЗ рд╡рд╛рд▓реЗ models рдХреЗ рд▓рд┐рдП рддреАрди рдореБрдЦреНрдп paradigms support рдХрд░рддрд╛ рд╣реИ:

### 1. Models рдЬреЛ Conditioning REQUIRE рдХрд░рддреЗ рд╣реИрдВ

рдХреБрдЫ models conditioning inputs рдХреЗ рдмрд┐рдирд╛ function рдирд╣реАрдВ рдХрд░ рд╕рдХрддреЗ:

- **Flux Kontext**: Edit-style training рдХреЗ рд▓рд┐рдП рд╣рдореЗрд╢рд╛ reference images рдЪрд╛рд╣рд┐рдП
- **ControlNet training**: Control signal images require рдХрд░рддрд╛ рд╣реИ

рдЗрди models рдХреЗ рд▓рд┐рдП, conditioning dataset mandatory рд╣реИред WebUI conditioning options рдХреЛ required рджрд┐рдЦрд╛рдПрдЧреА, рдФрд░ training рдЗрдирдХреЗ рдмрд┐рдирд╛ fail рд╣реЛрдЧреАред

### 2. Models рдЬреЛ Optional Conditioning SUPPORT рдХрд░рддреЗ рд╣реИрдВ

рдХреБрдЫ models text-to-image AND image-to-image рджреЛрдиреЛрдВ modes рдореЗрдВ operate рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ:

- **Flux2**: Optional reference images рдХреЗ рд╕рд╛рде dual T2I/I2I training support рдХрд░рддрд╛ рд╣реИ
- **LTXVideo2**: Optional first-frame conditioning рдХреЗ рд╕рд╛рде T2V рдФрд░ I2V (image-to-video) рджреЛрдиреЛрдВ support рдХрд░рддрд╛ рд╣реИ
- **LongCat-Video**: Optional frame conditioning support рдХрд░рддрд╛ рд╣реИ
- **HunyuanVideo i2v**: First-frame conditioning рдХреЗ рд╕рд╛рде I2V support рдХрд░рддрд╛ рд╣реИ (flavours: `i2v-480p`, `i2v-720p`, рдЖрджрд┐)
- **WAN i2v**: First-frame conditioning рдХреЗ рд╕рд╛рде I2V support рдХрд░рддрд╛ рд╣реИ
- **Kandinsky5Video i2v**: First-frame conditioning рдХреЗ рд╕рд╛рде I2V support рдХрд░рддрд╛ рд╣реИ

рдЗрди models рдХреЗ рд▓рд┐рдП, рдЖрдк conditioning datasets ADD рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ рдкрд░ рдЬрд░реВрд░реА рдирд╣реАрдВред WebUI conditioning options рдХреЛ optional рджрд┐рдЦрд╛рдПрдЧреАред

**I2V Validation Shortcut**: i2v video models рдХреЗ рд▓рд┐рдП, рдЖрдк `--validation_using_datasets` рдХреЛ image dataset (via `--eval_dataset_id` specified) рдХреЗ рд╕рд╛рде use рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ validation conditioning images directly рдкреНрд░рд╛рдкреНрдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП, training рдореЗрдВ use рд╣реЛрдиреЗ рд╡рд╛рд▓реА full conditioning dataset pairing setup рдХреА рдЬрд░реВрд░рдд рдХреЗ рдмрд┐рдирд╛ред

### 3. Validation Modes

| Mode | Flag | Behavior |
|------|------|----------|
| **Text-to-Image/Video** | (default) | рдХреЗрд╡рд▓ text prompts рд╕реЗ generate |
| **Dataset-based (img2img)** | `--validation_using_datasets` | Datasets рд╕реЗ images partially denoise |
| **Dataset-based (i2v)** | `--validation_using_datasets` | i2v video models рдХреЗ рд▓рд┐рдП, images рдХреЛ first-frame conditioning рдХреЗ рд░реВрдк рдореЗрдВ use |
| **Conditioning-based** | (auto рдЬрдм conditioning configured рд╣реЛ) | Validation рдХреЗ рджреМрд░рд╛рди conditioning inputs use |

**Modes combine рдХрд░рдирд╛**: рдЬрдм model conditioning support рдХрд░рддрд╛ рд╣реИ AND `--validation_using_datasets` enabled рд╣реИ:
- Validation system datasets рд╕реЗ images рд▓реЗрддрд╛ рд╣реИ
- рдпрджрд┐ рдЙрди datasets рдореЗрдВ conditioning data рд╣реИ, рддреЛ automatically use рд╣реЛрддрд╛ рд╣реИ
- `--eval_dataset_id` use рдХрд░реЗрдВ control рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдХреМрди рд╕рд╛ dataset inputs provide рдХрд░реЗ

**I2V models рдХреЗ рд╕рд╛рде `--validation_using_datasets`**: i2v video models (HunyuanVideo, WAN, Kandinsky5Video) рдХреЗ рд▓рд┐рдП, рдпрд╣ flag enable рдХрд░рдиреЗ рдкрд░ validation рдХреЗ рд▓рд┐рдП simple image dataset use рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред Images validation videos generate рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП first-frame conditioning inputs рдХреЗ рд░реВрдк рдореЗрдВ use рд╣реЛрддреА рд╣реИрдВ, complex conditioning dataset pairing setup рдХреА рдЬрд░реВрд░рдд рдХреЗ рдмрд┐рдирд╛ред

### Conditioning Data Types

Different models different conditioning data expect рдХрд░рддреЗ рд╣реИрдВ:

| Type | Models | Dataset Setting |
|------|--------|-----------------|
| `conditioning` | ControlNet, Control | Dataset config рдореЗрдВ `type: conditioning` |
| `image` | Flux Kontext | `type: image` (standard image dataset) |
| `latents` | Flux, Flux2 | Conditioning automatically VAE-encoded рд╣реЛрддрд╛ рд╣реИ |

---

### `--caption_strategy`

- **What**: image captions derive рдХрд░рдиреЗ рдХреА рд░рдгрдиреАрддрд┐ред **Choices**: `textfile`, `filename`, `parquet`, `instanceprompt`
- **Why**: training images рдХреЗ captions рдХреИрд╕реЗ рдмрдирд╛рдП рдЬрд╛рдПрдБ, рдпрд╣ рддрдп рдХрд░рддрд╛ рд╣реИред
  - `textfile` image рдХреЗ рд╕рдорд╛рди рдлрд╝рд╛рдЗрд▓тАСрдирд╛рдо рд╡рд╛рд▓реА `.txt` рдлрд╝рд╛рдЗрд▓ рдХреЗ contents рдЙрдкрдпреЛрдЧ рдХрд░реЗрдЧрд╛
  - `filename` рдлрд╝рд╛рдЗрд▓тАСрдирд╛рдо рдХреЛ рдХреБрдЫ cleanup рдХрд░рдХреЗ caption рдХреЗ рд░реВрдк рдореЗрдВ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдЧрд╛ред
  - `parquet` dataset рдореЗрдВ parquet рдлрд╝рд╛рдЗрд▓ рд╣реЛрдиреЗ рдкрд░ `caption` column рдЙрдкрдпреЛрдЧ рдХрд░реЗрдЧрд╛ рдЬрдм рддрдХ `parquet_caption_column` рди рджрд┐рдпрд╛ рдЧрдпрд╛ рд╣реЛред рд╕рднреА captions рдореМрдЬреВрдж рд╣реЛрдиреЗ рдЪрд╛рд╣рд┐рдП рдЬрдм рддрдХ `parquet_fallback_caption_column` рди рджрд┐рдпрд╛ рдЧрдпрд╛ рд╣реЛред
  - `instanceprompt` dataset config рдореЗрдВ `instance_prompt` рдорд╛рди рдХреЛ рд╣рд░ image рдХреЗ prompt рдХреЗ рд░реВрдк рдореЗрдВ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдЧрд╛ред

### `--conditioning_multidataset_sampling` {#--conditioning_multidataset_sampling}

- **What**: multiple conditioning datasets рд╕реЗ sampling рдХреИрд╕реЗ рдХреА рдЬрд╛рдПред **Choices**: `combined`, `random`
- **Why**: multiple conditioning datasets (рдЙрджрд╛., multiple reference images рдпрд╛ control signals) рдХреЗ рд╕рд╛рде training рдХрд░рддреЗ рд╕рдордп рдпрд╣ рддрдп рдХрд░рддрд╛ рд╣реИ рдХрд┐ рдЙрдиреНрд╣реЗрдВ рдХреИрд╕реЗ рдЙрдкрдпреЛрдЧ рдХрд┐рдпрд╛ рдЬрд╛рдП:
  - `combined` conditioning inputs рдХреЛ stitch рдХрд░рдХреЗ training рдореЗрдВ рдПрдХ рд╕рд╛рде рджрд┐рдЦрд╛рддрд╛ рд╣реИред рдпрд╣ multiтАСimage compositing tasks рдХреЗ рд▓рд┐рдП рдЙрдкрдпреЛрдЧреА рд╣реИред
  - `random` рд╣рд░ sample рдХреЗ рд▓рд┐рдП рдПрдХ conditioning dataset рд░реИрдВрдбрдо рд░реВрдк рд╕реЗ рдЪреБрдирддрд╛ рд╣реИ, training рдХреЗ рджреМрд░рд╛рди conditions рдмрджрд▓рддреЗ рд╣реБрдПред
- **Note**: `combined` рдЙрдкрдпреЛрдЧ рдХрд░рдиреЗ рдкрд░ рдЖрдк conditioning datasets рдкрд░ рдЕрд▓рдЧ `captions` рдкрд░рд┐рднрд╛рд╖рд┐рдд рдирд╣реАрдВ рдХрд░ рд╕рдХрддреЗ; source dataset рдХреЗ captions рд╣реА рдЙрдкрдпреЛрдЧ рд╣реЛрддреЗ рд╣реИрдВред
- **See also**: multiple conditioning datasets рдХреЙрдиреНрдлрд╝рд┐рдЧрд░ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП [DATALOADER.md](DATALOADER.md#conditioning_data) рджреЗрдЦреЗрдВред

---

## ЁЯОЫ Training Parameters

### `--num_train_epochs`

- **What**: training epochs рдХреА рд╕рдВрдЦреНрдпрд╛ (рдХрд┐рддрдиреА рдмрд╛рд░ рд╕рднреА images рджреЗрдЦреА рдЬрд╛рддреА рд╣реИрдВ)ред рдЗрд╕реЗ 0 рд╕реЗрдЯ рдХрд░рдиреЗ рдкрд░ `--max_train_steps` рдХреЛ рдкреНрд░рд╛рдердорд┐рдХрддрд╛ рдорд┐рд▓рддреА рд╣реИред
- **Why**: image repeats рдХреА рд╕рдВрдЦреНрдпрд╛ рддрдп рдХрд░рддрд╛ рд╣реИ, рдЬреЛ training duration рдХреЛ рдкреНрд░рднрд╛рд╡рд┐рдд рдХрд░рддрд╛ рд╣реИред рдЕрдзрд┐рдХ epochs рдЖрдо рддреМрд░ рдкрд░ overfitting рдХрд╛ рдХрд╛рд░рдг рдмрдирддреЗ рд╣реИрдВ, рд▓реЗрдХрд┐рди рдЖрдкрдХреЗ concepts рд╕реАрдЦрдиреЗ рдХреЗ рд▓рд┐рдП рдЖрд╡рд╢реНрдпрдХ рд╣реЛ рд╕рдХрддреЗ рд╣реИрдВред рдЙрдЪрд┐рдд рдорд╛рди 5 рд╕реЗ 50 рдХреЗ рдмреАрдЪ рд╣реЛ рд╕рдХрддрд╛ рд╣реИред

### `--max_train_steps`

- **What**: рдЗрддрдиреЗ training steps рдХреЗ рдмрд╛рдж training рдмрдВрдж рд╣реЛрддреА рд╣реИред 0 рд╕реЗрдЯ рдХрд░рдиреЗ рдкрд░ `--num_train_epochs` рдХреЛ рдкреНрд░рд╛рдердорд┐рдХрддрд╛ рдорд┐рд▓рддреА рд╣реИред
- **Why**: training рдХреЛ рдЫреЛрдЯрд╛ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдЙрдкрдпреЛрдЧреАред

### `--ignore_final_epochs`

- **What**: рдЕрдВрддрд┐рдо рдЧрд┐рдиреЗ рдЧрдП epochs рдХреЛ ignore рдХрд░рдХреЗ `--max_train_steps` рдХреЛ рдкреНрд░рд╛рдердорд┐рдХрддрд╛ рджреЗрддрд╛ рд╣реИред
- **Why**: dataloader length рдмрджрд▓рдиреЗ рдкрд░ epoch calculation рдмрджрд▓ рдЬрд╛рддреА рд╣реИ рдФрд░ training рдЬрд▓реНрджреА рдЦрддреНрдо рд╣реЛ рд╕рдХрддреА рд╣реИред рдпрд╣ рд╡рд┐рдХрд▓реНрдк рдЕрдВрддрд┐рдо epochs рдХреЛ ignore рдХрд░рдХреЗ `--max_train_steps` рддрдХ training рдЬрд╛рд░реА рд░рдЦрддрд╛ рд╣реИред

### `--learning_rate`

- **What**: рд╕рдВрднрд╛рд╡рд┐рдд warmup рдХреЗ рдмрд╛рдж initial learning rateред
- **Why**: learning rate gradient updates рдХреЗ рд▓рд┐рдП рдПрдХ рддрд░рд╣ рдХрд╛ "step size" рд╣реИ тАФ рдмрд╣реБрдд рдЕрдзрд┐рдХ рд╣реЛрдиреЗ рдкрд░ solution рд╕реЗ рдЖрдЧреЗ рдирд┐рдХрд▓ рдЬрд╛рддреЗ рд╣реИрдВ, рдмрд╣реБрдд рдХрдо рд╣реЛрдиреЗ рдкрд░ ideal solution рддрдХ рдирд╣реАрдВ рдкрд╣реБрдБрдЪрддреЗред `full` tune рдХреЗ рд▓рд┐рдП рдиреНрдпреВрдирддрдо рдорд╛рди `1e-7` рдФрд░ рдЕрдзрд┐рдХрддрдо `1e-6` рддрдХ рд╣реЛ рд╕рдХрддрд╛ рд╣реИ, рдЬрдмрдХрд┐ `lora` tuning рдХреЗ рд▓рд┐рдП рдиреНрдпреВрдирддрдо `1e-5` рдФрд░ рдЕрдзрд┐рдХрддрдо `1e-3` рддрдХ рд╣реЛ рд╕рдХрддрд╛ рд╣реИред рдЙрдЪреНрдЪ learning rate рдЙрдкрдпреЛрдЧ рдХрд░рдиреЗ рдкрд░ EMA network рдФрд░ warmup рд▓рд╛рднрджрд╛рдпрдХ рд╣реЛрддреЗ рд╣реИрдВ тАФ рджреЗрдЦреЗрдВ `--use_ema`, `--lr_warmup_steps`, рдФрд░ `--lr_scheduler`ред

### `--lr_scheduler`

- **What**: рд╕рдордп рдХреЗ рд╕рд╛рде learning rate рдХреИрд╕реЗ scale рд╣реЛред
- **Choices**: constant, constant_with_warmup, cosine, cosine_with_restarts, **polynomial** (рдЕрдиреБрд╢рдВрд╕рд┐рдд), linear
- **Why**: loss landscape рдХреЛ explore рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП learning rate рдХреЛ рд╕рдордптАСрд╕рдордп рдкрд░ рдмрджрд▓рдирд╛ рдЙрдкрдпреЛрдЧреА рд╣реИред cosine schedule рдбрд┐рдлрд╝реЙрд▓реНрдЯ рд╣реИ, рдЬрд┐рд╕рд╕реЗ training рджреЛ extremes рдХреЗ рдмреАрдЪ smooth рддрд░реАрдХреЗ рд╕реЗ рдЪрд▓рддреА рд╣реИред constant learning rate рдореЗрдВ рдЕрдХреНрд╕рд░ рдмрд╣реБрдд рдКрдБрдЪрд╛ рдпрд╛ рдмрд╣реБрдд рдХрдо рдорд╛рди рдЪреБрди рд▓рд┐рдпрд╛ рдЬрд╛рддрд╛ рд╣реИ, рдЬрд┐рд╕рд╕реЗ divergence (рдмрд╣реБрдд рдКрдБрдЪрд╛) рдпрд╛ local minima рдореЗрдВ рдлрдБрд╕рдирд╛ (рдмрд╣реБрдд рдХрдо) рд╣реЛрддрд╛ рд╣реИред polynomial schedule warmup рдХреЗ рд╕рд╛рде рд╕рдмрд╕реЗ рдЕрдЪреНрдЫрд╛ рд░рд╣рддрд╛ рд╣реИ, рдЬрд╣рд╛рдБ рдпрд╣ рдзреАрд░реЗтАСрдзреАрд░реЗ `learning_rate` рддрдХ рдкрд╣реБрдБрдЪрддрд╛ рд╣реИ рдФрд░ рдлрд┐рд░ рдзреАрд░реЗтАСрдзреАрд░реЗ `--lr_end` рдХреЗ рдкрд╛рд╕ рдкрд╣реБрдБрдЪрддрд╛ рд╣реИред

### `--optimizer`

- **What**: training рдХреЗ рд▓рд┐рдП optimizerред
- **Choices**: adamw_bf16, ao-adamw8bit, ao-adamw4bit, ao-adamfp8, ao-adamwfp8, adamw_schedulefree, adamw_schedulefree+aggressive, adamw_schedulefree+no_kahan, optimi-stableadamw, optimi-adamw, optimi-lion, optimi-radam, optimi-ranger, optimi-adan, optimi-adam, optimi-sgd, soap, bnb-adagrad, bnb-adagrad8bit, bnb-adam, bnb-adam8bit, bnb-adamw, bnb-adamw8bit, bnb-adamw-paged, bnb-adamw8bit-paged, bnb-lion, bnb-lion8bit, bnb-lion-paged, bnb-lion8bit-paged, bnb-ademamix, bnb-ademamix8bit, bnb-ademamix-paged, bnb-ademamix8bit-paged, prodigy

> Note: рдХреБрдЫ optimisers nonтАСNVIDIA hardware рдкрд░ рдЙрдкрд▓рдмреНрдз рдирд╣реАрдВ рд╣реЛ рд╕рдХрддреЗред

### `--optimizer_config`

- **What**: optimizer settings рдХреЛ fineтАСtune рдХрд░реЗрдВред
- **Why**: optimizers рдореЗрдВ рдмрд╣реБрдд рд╕рд╛рд░реЗ settings рд╣реЛрддреЗ рд╣реИрдВ, рд╣рд░ рдПрдХ рдХреЗ рд▓рд┐рдП CLI argument рджреЗрдирд╛ рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рдирд╣реАрдВ рд╣реИред рдЗрд╕рд▓рд┐рдП рдЖрдк commaтАСseparated рд╕реВрдЪреА рджреЗрдХрд░ default settings override рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред
- **Example**: **prodigy** optimizer рдХреЗ рд▓рд┐рдП `d_coef` рд╕реЗрдЯ рдХрд░рдирд╛: `--optimizer_config=d_coef=0.1`

> Note: Optimizer betas dedicated parameters `--optimizer_beta1`, `--optimizer_beta2` рд╕реЗ override рдХрд┐рдП рдЬрд╛рддреЗ рд╣реИрдВред

### `--train_batch_size`

- **What**: training data loader рдХреЗ рд▓рд┐рдП batch sizeред
- **Why**: model memory consumption, convergence quality, рдФрд░ training speed рдкреНрд░рднрд╛рд╡рд┐рдд рдХрд░рддрд╛ рд╣реИред рдмрдбрд╝рд╛ batch size рд╕рд╛рдорд╛рдиреНрдпрддрдГ рдмреЗрд╣рддрд░ рдкрд░рд┐рдгрд╛рдо рджреЗрддрд╛ рд╣реИ, рд▓реЗрдХрд┐рди рдмрд╣реБрдд рдмрдбрд╝рд╛ batch size overfitting рдпрд╛ destabilized training рдХрд╛ рдХрд╛рд░рдг рдмрди рд╕рдХрддрд╛ рд╣реИ рдФрд░ training рдЕрд╡рдзрд┐ рднреА рдмрдврд╝рд╛ рд╕рдХрддрд╛ рд╣реИред рдкреНрд░рдпреЛрдЧ рдЬрд╝рд░реВрд░реА рд╣реИ, рд▓реЗрдХрд┐рди рд╕рд╛рдорд╛рдиреНрдпрддрдГ рд▓рдХреНрд╖реНрдп рдпрд╣ рд╣реИ рдХрд┐ training speed рдШрдЯрд╛рдП рдмрд┐рдирд╛ VRAM рдЕрдзрд┐рдХрддрдо рдЙрдкрдпреЛрдЧ рдореЗрдВ рд╣реЛред

### `--gradient_accumulation_steps`

- **What**: backward/update pass рдХрд░рдиреЗ рд╕реЗ рдкрд╣рд▓реЗ accumulate рдХрд┐рдП рдЬрд╛рдиреЗ рд╡рд╛рд▓реЗ steps рдХреА рд╕рдВрдЦреНрдпрд╛; рдпрд╣ memory рдмрдЪрд╛рдиреЗ рдХреЗ рд▓рд┐рдП рдХрд╛рдо рдХреЛ рдХрдИ batches рдореЗрдВ рдмрд╛рдБрдЯ рджреЗрддрд╛ рд╣реИ, рд▓реЗрдХрд┐рди training runtime рдмрдврд╝рддрд╛ рд╣реИред
- **Why**: рдмрдбрд╝реЗ models рдпрд╛ datasets рдХреЛ рд╕рдВрднрд╛рд▓рдиреЗ рдореЗрдВ рдЙрдкрдпреЛрдЧреАред

> Note: gradient accumulation steps рдЙрдкрдпреЛрдЧ рдХрд░рддреЗ рд╕рдордп рдХрд┐рд╕реА рднреА optimizer рдХреЗ рд▓рд┐рдП fused backward pass enable рди рдХрд░реЗрдВред

### `--allow_dataset_oversubscription` {#--allow_dataset_oversubscription}

- **What**: dataset effective batch size рд╕реЗ рдЫреЛрдЯрд╛ рд╣реЛрдиреЗ рдкрд░ `repeats` рд╕реНрд╡рддрдГ adjust рдХрд░рддрд╛ рд╣реИред
- **Why**: multiтАСGPU рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди рдХреЗ рд▓рд┐рдП рдиреНрдпреВрдирддрдо requirements рдкреВрд░реА рди рд╣реЛрдиреЗ рдкрд░ training failure рдХреЛ рд░реЛрдХрддрд╛ рд╣реИред
- **How it works**:
  - **effective batch size** рдХреА рдЧрдгрдирд╛ рдХрд░рддрд╛ рд╣реИ: `train_batch_size ├Ч num_gpus ├Ч gradient_accumulation_steps`
  - рдпрджрд┐ рдХрд┐рд╕реА aspect bucket рдореЗрдВ effective batch size рд╕реЗ рдХрдо samples рд╣реИрдВ, рддреЛ `repeats` рд╕реНрд╡рддрдГ рдмрдврд╝рд╛рддрд╛ рд╣реИ
  - рдХреЗрд╡рд▓ рддрдм рд▓рд╛рдЧреВ рд╣реЛрддрд╛ рд╣реИ рдЬрдм dataset config рдореЗрдВ `repeats` explicitly рд╕реЗрдЯ рди рд╣реЛ
  - adjustment рдФрд░ reasoning рджрд┐рдЦрд╛рдиреЗ рдХреЗ рд▓рд┐рдП warning рд▓реЙрдЧ рдХрд░рддрд╛ рд╣реИ
- **Use cases**:
  - рдХрдИ GPUs рдХреЗ рд╕рд╛рде рдЫреЛрдЯреЗ datasets (< 100 images)
  - datasets рдлрд┐рд░ рд╕реЗ рдХреЙрдиреНрдлрд╝рд┐рдЧрд░ рдХрд┐рдП рдмрд┐рдирд╛ рдЕрд▓рдЧ batch sizes рдХреЗ рд╕рд╛рде experimentation
  - full dataset рдЗрдХрдЯреНрдард╛ рдХрд░рдиреЗ рд╕реЗ рдкрд╣рд▓реЗ prototyping
- **Example**: 25 images, 8 GPUs, рдФрд░ `train_batch_size=4` рдХреЗ рд╕рд╛рде effective batch size 32 рд╣реЛрддрд╛ рд╣реИред рдпрд╣ flag `repeats=1` рд╕реНрд╡рддрдГ рд╕реЗрдЯ рдХрд░реЗрдЧрд╛ рддрд╛рдХрд┐ 50 samples (25 ├Ч 2) рдорд┐рд▓реЗрдВред
- **Note**: рдпрд╣ dataloader рдХреЙрдиреНрдлрд╝рд┐рдЧ рдореЗрдВ manuallyтАСset `repeats` values рдХреЛ override **рдирд╣реАрдВ** рдХрд░реЗрдЧрд╛ред `--disable_bucket_pruning` рдХреА рддрд░рд╣, рдпрд╣ flag рдмрд┐рдирд╛ surprising behavior рдХреЗ рд╕реБрд╡рд┐рдзрд╛ рджреЗрддрд╛ рд╣реИред

MultiтАСGPU training рдХреЗ рд▓рд┐рдП dataset sizing рдкрд░ рдЕрдзрд┐рдХ рд╡рд┐рд╡рд░рдг [DATALOADER.md](DATALOADER.md#automatic-dataset-oversubscription) рдореЗрдВ рджреЗрдЦреЗрдВред

---

## ЁЯЫа Advanced Optimizations

### `--use_ema`

- **What**: рдореЙрдбрд▓ рдХреЗ training рдЬреАрд╡рдирдХрд╛рд▓ рдореЗрдВ weights рдХрд╛ exponential moving average рд░рдЦрдирд╛, рдореЙрдбрд▓ рдХреЛ рд╕рдордптАСрд╕рдордп рдкрд░ рдЦреБрдж рдореЗрдВ backтАСmerge рдХрд░рдиреЗ рдЬреИрд╕рд╛ рд╣реИред
- **Why**: рдЕрдзрд┐рдХ system resources рдФрд░ рдереЛрдбрд╝рд╛ рдЕрдзрд┐рдХ runtime рдЦрд░реНрдЪ рдХрд░рдХреЗ training stability рдмреЗрд╣рддрд░ рд╣реЛрддреА рд╣реИред

### `--ema_device`

- **Choices**: `cpu`, `accelerator`; default: `cpu`
- **What**: EMA weights updates рдХреЗ рдмреАрдЪ рдХрд╣рд╛рдБ рд░рдЦреА рдЬрд╛рдПрдБред
- **Why**: EMA рдХреЛ accelerator рдкрд░ рд░рдЦрдиреЗ рд╕реЗ updates рддреЗрдЬрд╝ рд╣реЛрддреЗ рд╣реИрдВ рд▓реЗрдХрд┐рди VRAM рд▓рд╛рдЧрдд рдмрдврд╝рддреА рд╣реИред CPU рдкрд░ рд░рдЦрдиреЗ рд╕реЗ memory рджрдмрд╛рд╡ рдХрдо рд╣реЛрддрд╛ рд╣реИ, рд▓реЗрдХрд┐рди `--ema_cpu_only` рд╕реЗрдЯ рди рд╣реЛрдиреЗ рдкрд░ weights рдХреЛ рд╢рдЯрд▓ рдХрд░рдирд╛ рдкрдбрд╝рддрд╛ рд╣реИред

### `--ema_cpu_only`

- **What**: `--ema_device=cpu` рд╣реЛрдиреЗ рдкрд░ EMA weights рдХреЛ updates рдХреЗ рд▓рд┐рдП accelerator рдкрд░ рд╡рд╛рдкрд╕ рд▓реЗ рдЬрд╛рдиреЗ рд╕реЗ рд░реЛрдХрддрд╛ рд╣реИред
- **Why**: рдмрдбрд╝реЗ EMAs рдХреЗ рд▓рд┐рдП hostтАСtoтАСdevice transfer рд╕рдордп рдФрд░ VRAM рдЙрдкрдпреЛрдЧ рдмрдЪрд╛рддрд╛ рд╣реИред `--ema_device=accelerator` рд╣реЛрдиреЗ рдкрд░ рдЗрд╕рдХрд╛ рдкреНрд░рднрд╛рд╡ рдирд╣реАрдВ рд╣реИ рдХреНрдпреЛрдВрдХрд┐ weights рдкрд╣рд▓реЗ рд╕реЗ accelerator рдкрд░ рд╣реИрдВред

### `--ema_foreach_disable`

- **What**: EMA updates рдХреЗ рд▓рд┐рдП `torch._foreach_*` kernels рдХрд╛ рдЙрдкрдпреЛрдЧ disable рдХрд░рддрд╛ рд╣реИред
- **Why**: рдХреБрдЫ backтАСends рдпрд╛ hardware combinations рдореЗрдВ foreach ops рд╕рдорд╕реНрдпрд╛рдЧреНрд░рд╕реНрдд рд╣реЛрддреЗ рд╣реИрдВред рдЗрдиреНрд╣реЗрдВ disable рдХрд░рдиреЗ рдкрд░ scalar implementation рдЙрдкрдпреЛрдЧ рд╣реЛрддреА рд╣реИ, рдЬрд┐рд╕рд╕реЗ updates рдереЛрдбрд╝рд╛ рдзреАрдореЗ рд╣реЛ рдЬрд╛рддреЗ рд╣реИрдВред

### `--ema_update_interval`

- **What**: EMA shadow parameters рдХрд┐рддрдиреА рдмрд╛рд░ update рд╣реЛрдВ, рдпрд╣ рдХрдо рдХрд░рддрд╛ рд╣реИред
- **Why**: рд╣рд░ step рдкрд░ update рдХрд░рдирд╛ рдХрдИ workflows рдХреЗ рд▓рд┐рдП рдЖрд╡рд╢реНрдпрдХ рдирд╣реАрдВред рдЙрджрд╛рд╣рд░рдг рдХреЗ рд▓рд┐рдП, `--ema_update_interval=100` рд╣рд░ 100 optimizer steps рдкрд░ EMA update рдХрд░реЗрдЧрд╛, рдЬрд┐рд╕рд╕реЗ `--ema_device=cpu` рдпрд╛ `--ema_cpu_only` рдХреЗ рд╕рд╛рде overhead рдШрдЯрддрд╛ рд╣реИред

### `--ema_decay`

- **What**: EMA updates рд▓рд╛рдЧреВ рдХрд░рддреЗ рд╕рдордп smoothing factor рдирд┐рдпрдВрддреНрд░рд┐рдд рдХрд░рддрд╛ рд╣реИред
- **Why**: рдЙрдЪреНрдЪ рдорд╛рди (рдЙрджрд╛. `0.999`) EMA рдХреЛ рдзреАрд░реЗ рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛ рджреЗрдиреЗ рджреЗрддреЗ рд╣реИрдВ рд▓реЗрдХрд┐рди рдмрд╣реБрдд рд╕реНрдерд┐рд░ weights рджреЗрддреЗ рд╣реИрдВред рдХрдо рдорд╛рди (рдЙрджрд╛. `0.99`) рдирдП training signals рдХреЗ рд╕рд╛рде рддреЗрдЬрд╝ adapt рд╣реЛрддреЗ рд╣реИрдВред

### `--snr_gamma`

- **What**: minтАСSNR weighted loss factor рдЙрдкрдпреЛрдЧ рдХрд░рддрд╛ рд╣реИред
- **Why**: Minimum SNR gamma loss factor рдХреЛ schedule рдореЗрдВ timestep рдХреА рд╕реНрдерд┐рддрд┐ рдХреЗ рдЕрдиреБрд╕рд╛рд░ weigh рдХрд░рддрд╛ рд╣реИред рдмрд╣реБрдд noisy timesteps рдХрд╛ рдпреЛрдЧрджрд╛рди рдХрдо рд╣реЛрддрд╛ рд╣реИ рдФрд░ рдХрдотАСnoise timesteps рдХрд╛ рдпреЛрдЧрджрд╛рди рдмрдврд╝рддрд╛ рд╣реИред рдореВрд▓ рдкреЗрдкрд░ рджреНрд╡рд╛рд░рд╛ рдЕрдиреБрд╢рдВрд╕рд┐рдд рдорд╛рди **5** рд╣реИ, рд▓реЗрдХрд┐рди рдЖрдк **1** рд╕реЗ **20** рддрдХ рдорд╛рди рдЙрдкрдпреЛрдЧ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ (рдЖрдорддреМрд░ рдкрд░ 20 рдХреЛ max рдорд╛рдирд╛ рдЬрд╛рддрд╛ рд╣реИ; 20 рд╕реЗ рдКрдкрд░ рдмрджрд▓рд╛рд╡ рдХрдо рд╣реЛрддрд╛ рд╣реИ)ред **1** рд╕рдмрд╕реЗ рдордЬрдмреВрдд рдкреНрд░рднрд╛рд╡ рджреЗрддрд╛ рд╣реИред

### `--use_soft_min_snr`

- **What**: loss landscape рдкрд░ рдЕрдзрд┐рдХ gradual weighting рдХреЗ рд╕рд╛рде рдореЙрдбрд▓ рдЯреНрд░реЗрди рдХрд░рддрд╛ рд╣реИред
- **Why**: pixel diffusion models training рдореЗрдВ рд╡рд┐рд╢рд┐рд╖реНрдЯ loss weighting schedule рдХреЗ рдмрд┐рдирд╛ degrade рд╣реЛ рд╕рдХрддреЗ рд╣реИрдВред DeepFloyd рдореЗрдВ softтАСminтАСsnrтАСgamma рд▓рдЧрднрдЧ рдЕрдирд┐рд╡рд╛рд░реНрдп рдкрд╛рдпрд╛ рдЧрдпрд╛ред Latent diffusion models рдореЗрдВ рдЖрдкрдХреЛ рд╕рдлрд▓рддрд╛ рдорд┐рд▓ рд╕рдХрддреА рд╣реИ, рд▓реЗрдХрд┐рди рдЫреЛрдЯреЗ рдкреНрд░рдпреЛрдЧреЛрдВ рдореЗрдВ рдЗрд╕рд╕реЗ blurry results рд╣реЛрдиреЗ рдХреА рд╕рдВрднрд╛рд╡рдирд╛ рджрд┐рдЦреАред

### `--diff2flow_enabled`

- **What**: epsilon рдпрд╛ vтАСprediction models рдХреЗ рд▓рд┐рдП DiffusionтАСtoтАСFlow bridge рд╕рдХреНрд╖рдо рдХрд░рддрд╛ рд╣реИред
- **Why**: model architecture рдмрджрд▓реЗ рдмрд┐рдирд╛ standard diffusion objectives рд╡рд╛рд▓реЗ рдореЙрдбрд▓реНрд╕ рдХреЛ flowтАСmatching targets (noise - latents) рдЙрдкрдпреЛрдЧ рдХрд░рдиреЗ рджреЗрддрд╛ рд╣реИред
- **Note**: Experimental рдлреАрдЪрд░ред

### `--diff2flow_loss`

- **What**: native prediction loss рдХреА рдмрдЬрд╛рдп Flow Matching loss рдкрд░ trainingред
- **Why**: `--diff2flow_enabled` рдХреЗ рд╕рд╛рде enabled рд╣реЛрдиреЗ рдкрд░, loss рдХреЛ model рдХреЗ native target (epsilon рдпрд╛ velocity) рдХреА рдЬрдЧрд╣ flow target (noise - latents) рдХреЗ рдЦрд┐рд▓рд╛рдл compute рдХрд░рддрд╛ рд╣реИред
- **Note**: `--diff2flow_enabled` рдЖрд╡рд╢реНрдпрдХ рд╣реИред

### `--scheduled_sampling_max_step_offset`

- **What**: training рдХреЗ рджреМрд░рд╛рди "roll out" рд╣реЛрдиреЗ рд╡рд╛рд▓реЗ steps рдХреА рдЕрдзрд┐рдХрддрдо рд╕рдВрдЦреНрдпрд╛ред
- **Why**: Scheduled Sampling (Rollout) рд╕рдХреНрд╖рдо рдХрд░рддрд╛ рд╣реИ, рдЬрд╣рд╛рдБ рдореЙрдбрд▓ training рдХреЗ рджреМрд░рд╛рди рдХреБрдЫ steps рдХреЗ рд▓рд┐рдП рдЕрдкрдиреЗ inputs рдЦреБрдж generate рдХрд░рддрд╛ рд╣реИред рдЗрд╕рд╕реЗ рдореЙрдбрд▓ рдЕрдкрдиреА рдЧрд▓рддрд┐рдпрд╛рдБ рд╕реБрдзрд╛рд░рдирд╛ рд╕реАрдЦрддрд╛ рд╣реИ рдФрд░ exposure bias рдШрдЯрддрд╛ рд╣реИред
- **Default**: 0 (disabled). рд╕рдХреНрд╖рдо рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рд╕рдХрд╛рд░рд╛рддреНрдордХ integer (рдЙрджрд╛., 5 рдпрд╛ 10) рджреЗрдВред

### `--scheduled_sampling_strategy`

- **What**: rollout offset рдЪреБрдирдиреЗ рдХреА рд░рдгрдиреАрддрд┐ред
- **Choices**: `uniform`, `biased_early`, `biased_late`.
- **Default**: `uniform`.
- **Why**: rollout рд▓рдВрдмрд╛рдЗрдпреЛрдВ рдХрд╛ distribution рдирд┐рдпрдВрддреНрд░рд┐рдд рдХрд░рддрд╛ рд╣реИред `uniform` рд╕рдорд╛рди рд░реВрдк рд╕реЗ sample рдХрд░рддрд╛ рд╣реИ; `biased_early` рдЫреЛрдЯреЗ rollouts рдХреЛ рдкреНрд░рд╛рдердорд┐рдХрддрд╛ рджреЗрддрд╛ рд╣реИ; `biased_late` рд▓рдВрдмреЗ rollouts рдХреЛ рдкреНрд░рд╛рдердорд┐рдХрддрд╛ рджреЗрддрд╛ рд╣реИред

### `--scheduled_sampling_probability`

- **What**: рдХрд┐рд╕реА sample рдХреЗ рд▓рд┐рдП nonтАСzero rollout offset рд▓рд╛рдЧреВ рд╣реЛрдиреЗ рдХреА рд╕рдВрднрд╛рд╡рдирд╛ред
- **Default**: 0.0.
- **Why**: scheduled sampling рдХрд┐рддрдиреА рдмрд╛рд░ рд▓рд╛рдЧреВ рд╣реЛ, рдпрд╣ рдирд┐рдпрдВрддреНрд░рд┐рдд рдХрд░рддрд╛ рд╣реИред 0.0 рдЗрд╕реЗ disable рдХрд░рддрд╛ рд╣реИ рдЪрд╛рд╣реЗ `max_step_offset` > 0 рд╣реЛред 1.0 рд╣рд░ sample рдкрд░ рд▓рд╛рдЧреВ рдХрд░рддрд╛ рд╣реИред

### `--scheduled_sampling_prob_start`

- **What**: ramp рдХреА рд╢реБрд░реБрдЖрдд рдореЗрдВ scheduled sampling рдХреА initial probabilityред
- **Default**: 0.0.

### `--scheduled_sampling_prob_end`

- **What**: ramp рдХреЗ рдЕрдВрдд рдореЗрдВ scheduled sampling рдХреА final probabilityред
- **Default**: 0.5.

### `--scheduled_sampling_ramp_steps`

- **What**: `prob_start` рд╕реЗ `prob_end` рддрдХ probability рдмрдврд╝рд╛рдиреЗ рдХреЗ steps рдХреА рд╕рдВрдЦреНрдпрд╛ред
- **Default**: 0 (рдХреЛрдИ ramp рдирд╣реАрдВ)ред

### `--scheduled_sampling_start_step`

- **What**: scheduled sampling ramp рд╢реБрд░реВ рдХрд░рдиреЗ рдХрд╛ global stepред
- **Default**: 0.0.

### `--scheduled_sampling_ramp_shape`

- **What**: probability ramp рдХрд╛ рдЖрдХрд╛рд░ред
- **Choices**: `linear`, `cosine`.
- **Default**: `linear`.

### `--scheduled_sampling_sampler`

- **What**: rollout generation steps рдХреЗ рд▓рд┐рдП рдЙрдкрдпреЛрдЧ рдХрд┐рдпрд╛ рдЬрд╛рдиреЗ рд╡рд╛рд▓рд╛ solverред
- **Choices**: `unipc`, `euler`, `dpm`, `rk4`.
- **Default**: `unipc`.

### `--scheduled_sampling_order`

- **What**: rollout рдХреЗ рд▓рд┐рдП solver рдХрд╛ orderред
- **Default**: 2.

### `--scheduled_sampling_reflexflow`

- **What**: flowтАСmatching models рдХреЗ рд▓рд┐рдП scheduled sampling рдХреЗ рджреМрд░рд╛рди ReflexFlowтАСstyle enhancements (antiтАСdrift + frequencyтАСcompensated weighting) рд╕рдХреНрд╖рдо рдХрд░реЗрдВред
- **Why**: directional regularization рдФрд░ biasтАСaware loss weighting рдЬреЛрдбрд╝рдХрд░ flowтАСmatching models рдореЗрдВ exposure bias рдШрдЯрд╛рддрд╛ рд╣реИред
- **Default**: `--scheduled_sampling_max_step_offset` > 0 рд╣реЛрдиреЗ рдкрд░ flowтАСmatching models рдХреЗ рд▓рд┐рдП autoтАСenable; `--scheduled_sampling_reflexflow=false` рд╕реЗ override рдХрд░реЗрдВред

### `--scheduled_sampling_reflexflow_alpha`

- **What**: exposure bias рд╕реЗ рдирд┐рдХрд▓реЗ frequencyтАСcompensation weight рдХрд╛ scaling factorред
- **Default**: 1.0.
- **Why**: flowтАСmatching models рдореЗрдВ rollout рдХреЗ рджреМрд░рд╛рди рдмрдбрд╝реЗ exposure bias рд╡рд╛рд▓реЗ рдХреНрд╖реЗрддреНрд░реЛрдВ рдХреЛ рдЕрдзрд┐рдХ weight рджреЗрддрд╛ рд╣реИред

### `--scheduled_sampling_reflexflow_beta1`

- **What**: ReflexFlow antiтАСdrift (directional) regularizer рдХрд╛ weightред
- **Default**: 10.0.
- **Why**: flowтАСmatching models рдореЗрдВ scheduled sampling рдЙрдкрдпреЛрдЧ рдХрд░рддреЗ рд╕рдордп рдореЙрдбрд▓ рдХреЛ target clean sample рдХреЗ рд╕рд╛рде рдЕрдкрдиреА predicted direction align рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдХрд┐рддрдирд╛ рдордЬрдмреВрддреА рд╕реЗ рдкреНрд░реЛрддреНрд╕рд╛рд╣рд┐рдд рдХрд┐рдпрд╛ рдЬрд╛рдП, рдпрд╣ рдирд┐рдпрдВрддреНрд░рд┐рдд рдХрд░рддрд╛ рд╣реИред

### `--scheduled_sampling_reflexflow_beta2`

- **What**: ReflexFlow frequencyтАСcompensation (loss reweighting) term рдХрд╛ weightред
- **Default**: 1.0.
- **Why**: reweighted flowтАСmatching loss рдХреЛ scale рдХрд░рддрд╛ рд╣реИ, рдЬреИрд╕рд╛ ReflexFlow paper рдореЗрдВ ╬▓тВВ knob рдХреЗ рд░реВрдк рдореЗрдВ рдмрддрд╛рдпрд╛ рдЧрдпрд╛ рд╣реИред

---

## ЁЯОп CREPA (Cross-frame Representation Alignment)

CREPA рдПрдХ regularization рддрдХрдиреАрдХ рд╣реИ рдЬреЛ video diffusion models рдХреА fineтАСtuning рдореЗрдВ temporal consistency рд╕реБрдзрд╛рд░рддреА рд╣реИ, adjacent frames рд╕реЗ pretrained visual features рдХреЗ рд╕рд╛рде hidden states align рдХрд░рдХреЗред рдпрд╣ рдкреЗрдкрд░ ["Cross-Frame Representation Alignment for Fine-Tuning Video Diffusion Models"](https://arxiv.org/abs/2506.09229) рдкрд░ рдЖрдзрд╛рд░рд┐рдд рд╣реИред

### `--crepa_enabled`

- **What**: training рдХреЗ рджреМрд░рд╛рди CREPA regularization рд╕рдХреНрд╖рдо рдХрд░реЗрдВред
- **Why**: рдкрдбрд╝реЛрд╕реА frames рдХреЗ DINOv2 features рдХреЗ рд╕рд╛рде DiT hidden states align рдХрд░рдХреЗ рд╡реАрдбрд┐рдпреЛ frames рдореЗрдВ semantic consistency рдмрдврд╝рд╛рддрд╛ рд╣реИред
- **Default**: `false`
- **Note**: рдХреЗрд╡рд▓ video models рдкрд░ рд▓рд╛рдЧреВ (Wan, LTXVideo, SanaVideo, Kandinsky5)ред

### `--crepa_block_index`

- **What**: alignment рдХреЗ рд▓рд┐рдП рдХрд┐рд╕ transformer block рдХреЗ hidden states рдЙрдкрдпреЛрдЧ рд╣реЛрдВред
- **Why**: рдкреЗрдкрд░ CogVideoX рдХреЗ рд▓рд┐рдП block 8 рдФрд░ Hunyuan Video рдХреЗ рд▓рд┐рдП block 10 рд╕реБрдЭрд╛рддрд╛ рд╣реИред рд╢реБрд░реБрдЖрддреА blocks рдЕрдХреНрд╕рд░ рдмреЗрд╣рддрд░ рдХрд╛рдо рдХрд░рддреЗ рд╣реИрдВ рдХреНрдпреЛрдВрдХрд┐ рд╡реЗ DiT рдХрд╛ "encoder" рд╣рд┐рд╕реНрд╕рд╛ рд╣реЛрддреЗ рд╣реИрдВред
- **Required**: рд╣рд╛рдБ, рдЬрдм CREPA enabled рд╣реЛред

### `--crepa_lambda`

- **What**: рдореБрдЦреНрдп training loss рдХреЗ рдореБрдХрд╛рдмрд▓реЗ CREPA alignment loss рдХрд╛ weightред
- **Why**: alignment regularization training рдХреЛ рдХрд┐рддрдирд╛ рдкреНрд░рднрд╛рд╡рд┐рдд рдХрд░реЗ, рдпрд╣ рдирд┐рдпрдВрддреНрд░рд┐рдд рдХрд░рддрд╛ рд╣реИред рдкреЗрдкрд░ CogVideoX рдХреЗ рд▓рд┐рдП 0.5 рдФрд░ Hunyuan Video рдХреЗ рд▓рд┐рдП 1.0 рдЙрдкрдпреЛрдЧ рдХрд░рддрд╛ рд╣реИред
- **Default**: `0.5`

### `--crepa_adjacent_distance`

- **What**: neighbor frame alignment рдХреЗ рд▓рд┐рдП рджреВрд░реА `d`ред
- **Why**: рдкреЗрдкрд░ рдХреА Equation 6 рдХреЗ рдЕрдиреБрд╕рд╛рд░, $K = \{f-d, f+d\}$ рдмрддрд╛рддрд╛ рд╣реИ рдХрд┐ рдХрд┐рди neighboring frames рд╕реЗ align рдХрд░рдирд╛ рд╣реИред `d=1` рд╣реЛрдиреЗ рдкрд░ рд╣рд░ frame рдЕрдкрдиреЗ immediate neighbors рд╕реЗ align рдХрд░рддрд╛ рд╣реИред
- **Default**: `1`

### `--crepa_adjacent_tau`

- **What**: exponential distance weighting рдХреЗ рд▓рд┐рдП temperature coefficientред
- **Why**: $e^{-|k-f|/\tau}$ рдХреЗ рдЬрд░рд┐рдП alignment weight рдХрд┐рддрдиреА рдЬрд▓реНрджреА decay рд╣реЛ, рдпрд╣ рдирд┐рдпрдВрддреНрд░рд┐рдд рдХрд░рддрд╛ рд╣реИред рдХрдо рдорд╛рди immediate neighbors рдкрд░ рдЕрдзрд┐рдХ рдЬреЛрд░ рджреЗрддрд╛ рд╣реИред
- **Default**: `1.0`

### `--crepa_cumulative_neighbors`

- **What**: adjacent mode рдХреА рдЬрдЧрд╣ cumulative mode рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВред
- **Why**:
  - **Adjacent mode (рдбрд┐рдлрд╝реЙрд▓реНрдЯ)**: рдХреЗрд╡рд▓ exact рджреВрд░реА `d` рд╡рд╛рд▓реЗ frames рд╕реЗ align рдХрд░рддрд╛ рд╣реИ (рдкреЗрдкрд░ рдХреЗ $K = \{f-d, f+d\}$ рдЬреИрд╕рд╛)
  - **Cumulative mode**: рджреВрд░реА 1 рд╕реЗ `d` рддрдХ рд╕рднреА frames рд╕реЗ align рдХрд░рддрд╛ рд╣реИ, smoother gradients рджреЗрддрд╛ рд╣реИ
- **Default**: `false`

### `--crepa_normalize_neighbour_sum`

- **What**: neighborтАСsum alignment рдХреЛ perтАСframe weight sum рд╕реЗ normalize рдХрд░реЗрдВред
- **Why**: `crepa_alignment_score` рдХреЛ [-1, 1] рдореЗрдВ рд░рдЦрддрд╛ рд╣реИ рдФрд░ loss scale рдХреЛ рдЕрдзрд┐рдХ literal рдмрдирд╛рддрд╛ рд╣реИред рдпрд╣ рдкреЗрдкрд░ рдХреА Eq. (6) рд╕реЗ experimental deviation рд╣реИред
- **Default**: `false`

### `--crepa_normalize_by_frames`

- **What**: alignment loss рдХреЛ frames рдХреА рд╕рдВрдЦреНрдпрд╛ рд╕реЗ normalize рдХрд░реЗрдВред
- **Why**: video length рдХреЗ рдмрд╛рд╡рдЬреВрдж loss scale consistent рд░рд╣рддрд╛ рд╣реИред Disable рдХрд░рдиреЗ рдкрд░ рд▓рдВрдмреЗ videos рдХреЛ stronger alignment signal рдорд┐рд▓рддрд╛ рд╣реИред
- **Default**: `true`

### `--crepa_spatial_align`

- **What**: рдЬрдм DiT рдФрд░ encoder рдХреЗ token counts рдЕрд▓рдЧ рд╣реЛрдВ рддреЛ spatial interpolation рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВред
- **Why**: DiT hidden states рдФрд░ DINOv2 features рдХреА spatial resolutions рдЕрд▓рдЧ рд╣реЛ рд╕рдХрддреА рд╣реИрдВред рд╕рдХреНрд╖рдо рд╣реЛрдиреЗ рдкрд░ bilinear interpolation рдЙрдиреНрд╣реЗрдВ spatially align рдХрд░рддрд╛ рд╣реИ; disabled рд╣реЛрдиреЗ рдкрд░ global pooling fallback рд╣реЛрддрд╛ рд╣реИред
- **Default**: `true`

### `--crepa_model`

- **What**: feature extraction рдХреЗ рд▓рд┐рдП рдХреМрдитАСрд╕рд╛ pretrained encoder рдЙрдкрдпреЛрдЧ рд╣реЛред
- **Why**: рдкреЗрдкрд░ DINOv2тАСg (ViTтАСGiant) рдЙрдкрдпреЛрдЧ рдХрд░рддрд╛ рд╣реИред `dinov2_vitb14` рдЬреИрд╕реЗ рдЫреЛрдЯреЗ variants рдХрдо memory рд▓реЗрддреЗ рд╣реИрдВред
- **Default**: `dinov2_vitg14`
- **Choices**: `dinov2_vitg14`, `dinov2_vitb14`, `dinov2_vits14`

### `--crepa_encoder_frames_batch_size`

- **What**: external feature encoder parallel рдореЗрдВ рдХрд┐рддрдиреЗ frames рдкреНрд░реЛрд╕реЗрд╕ рдХрд░реЗред 0 рдпрд╛ negative рд╣реЛрдиреЗ рдкрд░ рдкреВрд░реЗ batch рдХреЗ рд╕рднреА frames рдПрдХ рд╕рд╛рде рдкреНрд░реЛрд╕реЗрд╕ рд╣реЛрддреЗ рд╣реИрдВред рдпрджрд┐ рд╕рдВрдЦреНрдпрд╛ divisor рдирд╣реАрдВ рд╣реИ, рддреЛ remainder рдЫреЛрдЯреЗ batch рдХреЗ рд░реВрдк рдореЗрдВ рд╕рдВрднрд╛рд▓рд╛ рдЬрд╛рдПрдЧрд╛ред
- **Why**: DINOтАСlike encoders image models рд╣реИрдВ, рдЗрд╕рд▓рд┐рдП рд╡реЗ VRAM рдмрдЪрд╛рдиреЗ рдХреЗ рд▓рд┐рдП frames рдХреЛ sliced batches рдореЗрдВ рдкреНрд░реЛрд╕реЗрд╕ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ, рдЧрддрд┐ рдХреА рдХреАрдордд рдкрд░ред
- **Default**: `-1`

### `--crepa_use_backbone_features`

- **What**: external encoder skip рдХрд░реЗрдВ рдФрд░ diffusion model рдХреЗ рдЕрдВрджрд░ student block рдХреЛ teacher block рдХреЗ рд╕рд╛рде align рдХрд░реЗрдВред
- **Why**: рдЬрдм backbone рдХреЗ рдкрд╛рд╕ рдкрд╣рд▓реЗ рд╕реЗ рдордЬрдмреВрдд semantic layer рд╣реЛ, рддрдм DINOv2 рд▓реЛрдб рдХрд░рдиреЗ рд╕реЗ рдмрдЪрддрд╛ рд╣реИред
- **Default**: `false`

### `--crepa_teacher_block_index`

- **What**: backbone features рдЙрдкрдпреЛрдЧ рдХрд░рддреЗ рд╕рдордп teacher block indexред
- **Why**: external encoder рдХреЗ рдмрд┐рдирд╛, earlier student block рдХреЛ later teacher block рд╕реЗ align рдХрд░рдиреЗ рджреЗрддрд╛ рд╣реИред unset рд╣реЛрдиреЗ рдкрд░ student block рдкрд░ fallback рд╣реЛрддрд╛ рд╣реИред
- **Default**: рдпрджрд┐ рдирд╣реАрдВ рджрд┐рдпрд╛ рдЧрдпрд╛, рддреЛ `crepa_block_index` рдЙрдкрдпреЛрдЧ рд╣реЛрдЧрд╛ред

### `--crepa_encoder_image_size`

- **What**: encoder рдХреЗ рд▓рд┐рдП input resolutionред
- **Why**: DINOv2 models рдЕрдкрдиреЗ training resolution рдкрд░ рдмреЗрд╣рддрд░ рдХрд╛рдо рдХрд░рддреЗ рд╣реИрдВред giant model 518x518 рдЙрдкрдпреЛрдЧ рдХрд░рддрд╛ рд╣реИред
- **Default**: `518`

### `--crepa_scheduler`

- **What**: training рдХреЗ рджреМрд░рд╛рди CREPA coefficient decay рдХрд╛ scheduleред
- **Why**: рдЬреИрд╕реЗ-рдЬреИрд╕реЗ training рдЖрдЧреЗ рдмрдврд╝реЗ, CREPA regularization strength рдХреЛ рдХрдо рдХрд░рдиреЗ рджреЗрддрд╛ рд╣реИ, deep encoder features рдкрд░ overfitting рд░реЛрдХрддрд╛ рд╣реИред
- **Options**: `constant`, `linear`, `cosine`, `polynomial`
- **Default**: `constant`

### `--crepa_warmup_steps`

- **What**: CREPA weight рдХреЛ 0 рд╕реЗ `crepa_lambda` рддрдХ linearly ramp рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП steps рдХреА рд╕рдВрдЦреНрдпрд╛ред
- **Why**: gradual warmup CREPA regularization рд╢реБрд░реВ рд╣реЛрдиреЗ рд╕реЗ рдкрд╣рд▓реЗ early training рдХреЛ stabilize рдХрд░рдиреЗ рдореЗрдВ рдорджрдж рдХрд░ рд╕рдХрддрд╛ рд╣реИред
- **Default**: `0`

### `--crepa_decay_steps`

- **What**: decay рдХреЗ рд▓рд┐рдП рдХреБрд▓ steps (warmup рдХреЗ рдмрд╛рдж)ред 0 рд╕реЗрдЯ рдХрд░рдиреЗ рдкрд░ рдкреВрд░реА training run рдкрд░ decay рд╣реЛрдЧрд╛ред
- **Why**: decay phase рдХреА duration рдирд┐рдпрдВрддреНрд░рд┐рдд рдХрд░рддрд╛ рд╣реИред warmup рдкреВрд░рд╛ рд╣реЛрдиреЗ рдХреЗ рдмрд╛рдж decay рд╢реБрд░реВ рд╣реЛрддрд╛ рд╣реИред
- **Default**: `0` (`max_train_steps` рдЙрдкрдпреЛрдЧ рд╣реЛрдЧрд╛)

### `--crepa_lambda_end`

- **What**: decay рдкреВрд░рд╛ рд╣реЛрдиреЗ рдХреЗ рдмрд╛рдж final CREPA weightред
- **Why**: 0 рд╕реЗрдЯ рдХрд░рдиреЗ рдкрд░ training рдХреЗ рдЕрдВрдд рдореЗрдВ CREPA рдкреНрд░рднрд╛рд╡реА рд░реВрдк рд╕реЗ disable рд╣реЛ рдЬрд╛рддрд╛ рд╣реИ, text2video рдХреЗ рд▓рд┐рдП рдЙрдкрдпреЛрдЧреА рдЬрд╣рд╛рдБ CREPA artifacts рдкреИрджрд╛ рдХрд░ рд╕рдХрддрд╛ рд╣реИред
- **Default**: `0.0`

### `--crepa_power`

- **What**: polynomial decay рдХреЗ рд▓рд┐рдП power factorред 1.0 = linear, 2.0 = quadratic, рдЖрджрд┐ред
- **Why**: higher values рд╢реБрд░реБрдЖрдд рдореЗрдВ рддреЗрдЬ decay рдХрд░рддреЗ рд╣реИрдВ рдЬреЛ рдЕрдВрдд рдХреА рдУрд░ рдзреАрдорд╛ рд╣реЛ рдЬрд╛рддрд╛ рд╣реИред
- **Default**: `1.0`

### `--crepa_cutoff_step`

- **What**: hard cutoff step рдЬрд┐рд╕рдХреЗ рдмрд╛рдж CREPA disable рд╣реЛ рдЬрд╛рддрд╛ рд╣реИред
- **Why**: model temporal alignment рдкрд░ converge рд╣реЛрдиреЗ рдХреЗ рдмрд╛рдж CREPA disable рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдЙрдкрдпреЛрдЧреАред
- **Default**: `0` (рдХреЛрдИ step-based cutoff рдирд╣реАрдВ)

### `--crepa_similarity_threshold`

- **What**: similarity EMA threshold рдЬрд┐рд╕ рдкрд░ CREPA cutoff trigger рд╣реЛрддрд╛ рд╣реИред
- **Why**: рдЬрдм alignment score (`crepa_alignment_score`) рдХрд╛ exponential moving average рдЗрд╕ рдорд╛рди рддрдХ рдкрд╣реБрдБрдЪрддрд╛ рд╣реИ, рддреЛ deep encoder features рдкрд░ overfitting рд░реЛрдХрдиреЗ рдХреЗ рд▓рд┐рдП CREPA disable рд╣реЛ рдЬрд╛рддрд╛ рд╣реИред text2video training рдХреЗ рд▓рд┐рдП рд╡рд┐рд╢реЗрд╖ рд░реВрдк рд╕реЗ рдЙрдкрдпреЛрдЧреАред `crepa_normalize_neighbour_sum` enable рди рд╣реЛрдиреЗ рдкрд░ alignment score 1.0 рд╕реЗ рдКрдкрд░ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИред
- **Default**: None (disabled)

### `--crepa_similarity_ema_decay`

- **What**: similarity tracking рдХреЗ рд▓рд┐рдП exponential moving average decay factorред
- **Why**: higher values smoother tracking рджреЗрддреЗ рд╣реИрдВ (0.99 тЙИ 100-step window), lower values changes рдкрд░ рддреЗрдЬ react рдХрд░рддреЗ рд╣реИрдВред
- **Default**: `0.99`

### `--crepa_threshold_mode`

- **What**: similarity threshold рдкрд╣реБрдБрдЪрдиреЗ рдкрд░ рд╡реНрдпрд╡рд╣рд╛рд░ред
- **Options**: `permanent` (threshold hit рд╣реЛрдиреЗ рдкрд░ CREPA permanently off рд░рд╣рддрд╛ рд╣реИ), `recoverable` (similarity рдЧрд┐рд░рдиреЗ рдкрд░ CREPA рдлрд┐рд░ рд╕реЗ enable рд╣реЛрддрд╛ рд╣реИ)
- **Default**: `permanent`

### Example Configuration

```toml
# Enable CREPA for video fine-tuning
crepa_enabled = true
crepa_block_index = 8          # Adjust based on your model
crepa_lambda = 0.5
crepa_adjacent_distance = 1
crepa_adjacent_tau = 1.0
crepa_cumulative_neighbors = false
crepa_normalize_neighbour_sum = false
crepa_normalize_by_frames = true
crepa_spatial_align = true
crepa_model = "dinov2_vitg14"
crepa_encoder_frames_batch_size = -1
crepa_use_backbone_features = false
# crepa_teacher_block_index = 16
crepa_encoder_image_size = 518

# CREPA Scheduling (optional)
# crepa_scheduler = "cosine"           # Decay type: constant, linear, cosine, polynomial
# crepa_warmup_steps = 100             # Warmup before CREPA kicks in
# crepa_decay_steps = 1000             # Steps for decay (0 = entire training)
# crepa_lambda_end = 0.0               # Final weight after decay
# crepa_cutoff_step = 5000             # Hard cutoff step (0 = disabled)
# crepa_similarity_threshold = 0.9    # Similarity-based cutoff
# crepa_threshold_mode = "permanent"   # permanent or recoverable
```

---

## ЁЯФД Checkpointing and Resumption

### `--checkpoint_step_interval` (alias: `--checkpointing_steps`)

- **What**: training state checkpoints рдХрд┐рддрдиреЗ steps рдкрд░ рд╕реЗрд╡ рд╣реЛрдВ (steps рдореЗрдВ interval)ред
- **Why**: training resume рдФрд░ inference рдХреЗ рд▓рд┐рдП рдЙрдкрдпреЛрдЧреАред рд╣рд░ *n* iterations рдкрд░ Diffusers filesystem layout рдореЗрдВ `.safetensors` format рдХрд╛ partial checkpoint рд╕реЗрд╡ рд╣реЛрдЧрд╛ред

---

## ЁЯФБ LayerSync (Hidden State Self-Alignment)

LayerSync рдПрдХ "student" layer рдХреЛ рдЙрд╕реА transformer рдХреЗ рдПрдХ рдордЬрдмреВрдд "teacher" layer рд╕реЗ match рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдкреНрд░реЛрддреНрд╕рд╛рд╣рд┐рдд рдХрд░рддрд╛ рд╣реИ, hidden tokens рдкрд░ cosine similarity рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗред

### `--layersync_enabled`

- **What**: рдПрдХ рд╣реА рдореЙрдбрд▓ рдХреЗ рдЕрдВрджрд░ рджреЛ transformer blocks рдХреЗ рдмреАрдЪ LayerSync hiddenтАСstate alignment рд╕рдХреНрд╖рдо рдХрд░реЗрдВред
- **Notes**: hiddenтАСstate buffer allocate рдХрд░рддрд╛ рд╣реИ; required flags missing рд╣реЛрдВ рддреЛ startup рдкрд░ error рджреЗрддрд╛ рд╣реИред
- **Default**: `false`

### `--layersync_student_block`

- **What**: student anchor рдХреЗ рд░реВрдк рдореЗрдВ рдЙрдкрдпреЛрдЧ рд╣реЛрдиреЗ рд╡рд╛рд▓рд╛ transformer block indexред
- **Indexing**: LayerSync рдкреЗрдкрд░тАСstyle 1тАСbased depths рдпрд╛ 0тАСbased layer ids рд╕реНрд╡реАрдХрд╛рд░ рдХрд░рддрд╛ рд╣реИ; implementation рдкрд╣рд▓реЗ `idx-1` рдЖрдЬрд╝рдорд╛рддрд╛ рд╣реИ, рдлрд┐рд░ `idx`ред
- **Required**: рд╣рд╛рдБ, рдЬрдм LayerSync enabled рд╣реЛред

### `--layersync_teacher_block`

- **What**: teacher target рдХреЗ рд░реВрдк рдореЗрдВ рдЙрдкрдпреЛрдЧ рд╣реЛрдиреЗ рд╡рд╛рд▓рд╛ transformer block index (student рд╕реЗ рдЧрд╣рд░рд╛ рд╣реЛ рд╕рдХрддрд╛ рд╣реИ)ред
- **Indexing**: student block рдХреА рддрд░рд╣ рд╣реА 1тАСbasedтАСfirst, рдлрд┐рд░ 0тАСbased fallbackред
- **Default**: omit рд╣реЛрдиреЗ рдкрд░ student block рд╣реА рдЙрдкрдпреЛрдЧ рд╣реЛрддрд╛ рд╣реИ рддрд╛рдХрд┐ loss selfтАСsimilarity рдмрди рдЬрд╛рдПред

### `--layersync_lambda`

- **What**: student рдФрд░ teacher hidden states рдХреЗ рдмреАрдЪ LayerSync cosine alignment loss (negative cosine similarity) рдХрд╛ weightред
- **Effect**: base loss рдХреЗ рдКрдкрд░ рдЬреЛрдбрд╝рд╛ рдЧрдпрд╛ auxiliary regularizer scale рдХрд░рддрд╛ рд╣реИ; рдЙрдЪреНрдЪ рдорд╛рди student tokens рдХреЛ teacher tokens рд╕реЗ рдЕрдзрд┐рдХ alignment рдХреЗ рд▓рд┐рдП push рдХрд░рддреЗ рд╣реИрдВред
- **Upstream name**: рдореВрд▓ LayerSync codebase рдореЗрдВ `--reg-weight`.
- **Required**: LayerSync enabled рд╣реЛрдиреЗ рдкрд░ > 0 рд╣реЛрдирд╛ рдЪрд╛рд╣рд┐рдП (рдЕрдиреНрдпрдерд╛ training abort рд╣реЛрддреА рд╣реИ)ред
- **Default**: LayerSync enabled рд╣реЛрдиреЗ рдкрд░ `0.2` (reference repo рд╕реЗ рдореЗрд▓), рдЕрдиреНрдпрдерд╛ `0.0`.

Upstream option mapping (LayerSync тЖТ SimpleTuner):
- `--encoder-depth` тЖТ `--layersync_student_block` (upstream рдЬреИрд╕рд╛ 1тАСbased depth рдпрд╛ 0тАСbased layer index рд╕реНрд╡реАрдХрд╛рд░ рдХрд░рддрд╛ рд╣реИ)
- `--gt-encoder-depth` тЖТ `--layersync_teacher_block` (1тАСbased preferred; omit рд╣реЛрдиреЗ рдкрд░ student рдкрд░ рдбрд┐рдлрд╝реЙрд▓реНрдЯ)
- `--reg-weight` тЖТ `--layersync_lambda`

> Notes: LayerSync рд╣рдореЗрд╢рд╛ similarity рд╕реЗ рдкрд╣рд▓реЗ teacher hidden state detach рдХрд░рддрд╛ рд╣реИ, reference implementation рд╕реЗ рдореЗрд▓ рдЦрд╛рддреЗ рд╣реБрдПред рдпрд╣ рдЙрди рдореЙрдбрд▓реЛрдВ рдкрд░ рдирд┐рд░реНрднрд░ рдХрд░рддрд╛ рд╣реИ рдЬреЛ transformer hidden states expose рдХрд░рддреЗ рд╣реИрдВ (SimpleTuner рдХреЗ рдЕрдзрд┐рдХрд╛рдВрд╢ transformer backbones) рдФрд░ hiddenтАСstate buffer рдХреЗ рд▓рд┐рдП perтАСstep memory рдЬреЛрдбрд╝рддрд╛ рд╣реИ; VRAM tight рд╣реЛ рддреЛ disable рдХрд░реЗрдВред

### `--checkpoint_epoch_interval`

- **What**: рд╣рд░ N рдкреВрд░реНрдг epochs рдкрд░ checkpointing рдЪрд▓рд╛рдПрдБред
- **Why**: stepтАСbased checkpoints рдХреЛ рдкреВрд░рдХ рдХрд░рддрд╛ рд╣реИ, рддрд╛рдХрд┐ multiтАСdataset sampling рдХреЗ рдХрд╛рд░рдг step counts рдмрджрд▓рдиреЗ рдкрд░ рднреА epoch boundaries рдкрд░ state capture рд╣реЛ рд╕рдХреЗред

### `--resume_from_checkpoint`

- **What**: training resume рдХрд░рдирд╛ рд╣реИ рдпрд╛ рдирд╣реАрдВ рдФрд░ рдХрд╣рд╛рдБ рд╕реЗред `latest`, local checkpoint рдирд╛рдо/рдкрде, рдпрд╛ S3/R2 URI рд╕реНрд╡реАрдХрд╛рд░ рдХрд░рддрд╛ рд╣реИред
- **Why**: saved state рд╕реЗ training рдЬрд╛рд░реА рд░рдЦрдиреЗ рджреЗрддрд╛ рд╣реИ, manual рд░реВрдк рд╕реЗ рдпрд╛ latest рдЙрдкрд▓рдмреНрдз checkpoint рд╕реЗред
- **Remote resume**: рдкреВрд░рд╛ URI (`s3://bucket/jobs/.../checkpoint-100`) рдпрд╛ bucket-relative key (`jobs/.../checkpoint-100`) рджреЗрдВред `latest` рдХреЗрд╡рд▓ local `output_dir` рдкрд░ рдХрд╛рдо рдХрд░рддрд╛ рд╣реИуАВ
- **Requirements**: remote resume рдХреЗ рд▓рд┐рдП publishing_config рдореЗрдВ S3 entry (bucket + credentials) рдЪрд╛рд╣рд┐рдП рдЬреЛ checkpoint read рдХрд░ рд╕рдХреЗред
- **Notes**: remote checkpoints рдореЗрдВ `checkpoint_manifest.json` рд╣реЛрдирд╛ рдЪрд╛рд╣рд┐рдП (рд╣рд╛рд▓ рдХреА SimpleTuner runs рд╕реЗ generated)ред рдПрдХ checkpoint рдореЗрдВ `unet` рдФрд░ рд╡реИрдХрд▓реНрдкрд┐рдХ рд░реВрдк рд╕реЗ `unet_ema` subfolder рд╣реЛрддрд╛ рд╣реИред `unet` рдХреЛ рдХрд┐рд╕реА рднреА Diffusers layout SDXL рдореЙрдбрд▓ рдореЗрдВ рд░рдЦрд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИ, рдЬрд┐рд╕рд╕реЗ рдЗрд╕реЗ рд╕рд╛рдорд╛рдиреНрдп рдореЙрдбрд▓ рдХреА рддрд░рд╣ рдЙрдкрдпреЛрдЧ рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИред

> тД╣я╕П PixArt, SD3, рдпрд╛ Hunyuan рдЬреИрд╕реЗ transformer рдореЙрдбрд▓ `transformer` рдФрд░ `transformer_ema` subfolder рдирд╛рдо рдЙрдкрдпреЛрдЧ рдХрд░рддреЗ рд╣реИрдВред

### `--disk_low_threshold`

- **What**: checkpoint saves рд╕реЗ рдкрд╣рд▓реЗ рдЖрд╡рд╢реНрдпрдХ рдиреНрдпреВрдирддрдо рдЦрд╛рд▓реА disk spaceред
- **Why**: disk full errors рд╕реЗ training crash рдХреЛ рд░реЛрдХрддрд╛ рд╣реИ, рдХрдо space рдХрд╛ рдЬрд▓реНрджреА рдкрддрд╛ рд▓рдЧрд╛рдХрд░ configured action рд▓реЗрддрд╛ рд╣реИред
- **Format**: size string рдЬреИрд╕реЗ `100G`, `50M`, `1T`, `500K`, рдпрд╛ plain bytesред
- **Default**: None (feature disabled)

### `--disk_low_action`

- **What**: disk space threshold рд╕реЗ рдХрдо рд╣реЛрдиреЗ рдкрд░ рд▓рд┐рдпрд╛ рдЬрд╛рдиреЗ рд╡рд╛рд▓рд╛ actionред
- **Choices**: `stop`, `wait`, `script`
- **Default**: `stop`
- **Behavior**:
  - `stop`: error message рдХреЗ рд╕рд╛рде training рддреБрд░рдВрдд рд╕рдорд╛рдкреНрдд рдХрд░рддрд╛ рд╣реИред
  - `wait`: space рдЙрдкрд▓рдмреНрдз рд╣реЛрдиреЗ рддрдХ рд╣рд░ 30 seconds рдореЗрдВ loop рдХрд░рддрд╛ рд╣реИред рдЕрдирд┐рд╢реНрдЪрд┐рдд рдХрд╛рд▓ рддрдХ рдкреНрд░рддреАрдХреНрд╖рд╛ рдХрд░ рд╕рдХрддрд╛ рд╣реИред
  - `script`: space рдЦрд╛рд▓реА рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП `--disk_low_script` рджреНрд╡рд╛рд░рд╛ specified script рдЪрд▓рд╛рддрд╛ рд╣реИред

### `--disk_low_script`

- **What**: disk space рдХрдо рд╣реЛрдиреЗ рдкрд░ рдЪрд▓рд╛рдиреЗ рдХреЗ рд▓рд┐рдП cleanup script рдХрд╛ pathред
- **Why**: disk space рдХрдо рд╣реЛрдиреЗ рдкрд░ automated cleanup (рдЬреИрд╕реЗ рдкреБрд░рд╛рдиреЗ checkpoints рд╣рдЯрд╛рдирд╛, cache clear рдХрд░рдирд╛) рдХреА рдЕрдиреБрдорддрд┐ рджреЗрддрд╛ рд╣реИред
- **Notes**: рдХреЗрд╡рд▓ `--disk_low_action=script` рд╣реЛрдиреЗ рдкрд░ рдЙрдкрдпреЛрдЧ рд╣реЛрддрд╛ рд╣реИред script executable рд╣реЛрдирд╛ рдЪрд╛рд╣рд┐рдПред рдпрджрд┐ script fail рд╣реЛрддреА рд╣реИ рдпрд╛ рдкрд░реНрдпрд╛рдкреНрдд space рдЦрд╛рд▓реА рдирд╣реАрдВ рдХрд░рддреА, training error рдХреЗ рд╕рд╛рде рд░реБрдХ рдЬрд╛рдПрдЧреАред
- **Default**: None

---

## ЁЯУК Logging and Monitoring

### `--logging_dir`

- **What**: TensorBoard logs рдХреЗ рд▓рд┐рдП directoryред
- **Why**: training progress рдФрд░ performance metrics рдореЙрдирд┐рдЯрд░ рдХрд░рдиреЗ рджреЗрддрд╛ рд╣реИред

### `--report_to`

- **What**: results рдФрд░ logs рд░рд┐рдкреЛрд░реНрдЯ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП platform рдирд┐рд░реНрджрд┐рд╖реНрдЯ рдХрд░рддрд╛ рд╣реИред
- **Why**: TensorBoard, wandb, рдпрд╛ comet_ml рдЬреИрд╕реА platforms рдХреЗ рд╕рд╛рде integration рд╕рдХреНрд╖рдо рдХрд░рддрд╛ рд╣реИред multiple trackers рдкрд░ рд░рд┐рдкреЛрд░реНрдЯ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП comma рд╕реЗ рдЕрд▓рдЧ values рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВ;
- **Choices**: wandb, tensorboard, comet_ml

## Environment configuration variables

рдКрдкрд░ рджрд┐рдП рдЧрдП рд╡рд┐рдХрд▓реНрдк рдЕрдзрд┐рдХрддрд░ `config.json` рдкрд░ рд▓рд╛рдЧреВ рд╣реЛрддреЗ рд╣реИрдВ тАФ рд▓реЗрдХрд┐рди рдХреБрдЫ entries `config.env` рдореЗрдВ рд╕реЗрдЯ рдХрд░рдиреА рдкрдбрд╝рддреА рд╣реИрдВред

- `TRAINING_NUM_PROCESSES` рдХреЛ рд╕рд┐рд╕реНрдЯрдо рдореЗрдВ GPUs рдХреА рд╕рдВрдЦреНрдпрд╛ рдкрд░ рд╕реЗрдЯ рдХрд░реЗрдВред рдЕрдзрд┐рдХрд╛рдВрд╢ рдЙрдкрдпреЛрдЧтАСрдорд╛рдорд▓реЛрдВ рдореЗрдВ рдЗрд╕рд╕реЗ DistributedDataParallel (DDP) training рд╕рдХреНрд╖рдо рд╣реЛ рдЬрд╛рддреА рд╣реИред рдпрджрд┐ рдЖрдк `config.env` рдЙрдкрдпреЛрдЧ рдирд╣реАрдВ рдХрд░рдирд╛ рдЪрд╛рд╣рддреЗ, рддреЛ `config.json` рдореЗрдВ `num_processes` рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВред
- `TRAINING_DYNAMO_BACKEND` рдбрд┐рдлрд╝реЙрд▓реНрдЯ рд░реВрдк рд╕реЗ `no` рд╣реИ, рд▓реЗрдХрд┐рди рдЗрд╕реЗ рдХрд┐рд╕реА рднреА рд╕рдорд░реНрдерд┐рдд torch.compile backend (рдЙрджрд╛. `inductor`, `aot_eager`, `cudagraphs`) рдкрд░ рд╕реЗрдЯ рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИ рдФрд░ `--dynamo_mode`, `--dynamo_fullgraph`, рдпрд╛ `--dynamo_use_regional_compilation` рдХреЗ рд╕рд╛рде finer tuning рдХреЗ рд▓рд┐рдП рдЬреЛрдбрд╝рд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИ
- `SIMPLETUNER_LOG_LEVEL` рдбрд┐рдлрд╝реЙрд▓реНрдЯ рд░реВрдк рд╕реЗ `INFO` рд╣реИ, рд▓реЗрдХрд┐рди issue reports рдХреЗ рд▓рд┐рдП `debug.log` рдореЗрдВ рдЕрдзрд┐рдХ рдЬрд╛рдирдХрд╛рд░реА рдЬреЛрдбрд╝рдиреЗ рд╣реЗрддреБ рдЗрд╕реЗ `DEBUG` рдкрд░ рд╕реЗрдЯ рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИ
- `VENV_PATH` рдХреЛ рдЖрдкрдХреЗ python virtual env рдХреА рд▓реЛрдХреЗрд╢рди рдкрд░ рд╕реЗрдЯ рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИ рдпрджрд┐ рд╡рд╣ рд╕рд╛рдорд╛рдиреНрдп `.venv` рд▓реЛрдХреЗрд╢рди рдореЗрдВ рдирд╣реАрдВ рд╣реИ
- `ACCELERATE_EXTRA_ARGS` рдХреЛ unset рдЫреЛрдбрд╝рд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИ, рдпрд╛ рдЗрд╕рдореЗрдВ `--multi_gpu` рдпрд╛ FSDPтАСspecific flags рдЬреИрд╕реЗ рдЕрддрд┐рд░рд┐рдХреНрдд arguments рдЬреЛрдбрд╝реЗ рдЬрд╛ рд╕рдХрддреЗ рд╣реИрдВ

---

рдпрд╣ рдПрдХ рдмреЗрд╕рд┐рдХ overview рд╣реИ рддрд╛рдХрд┐ рдЖрдк рд╢реБрд░реБрдЖрдд рдХрд░ рд╕рдХреЗрдВред рдкреВрд░реНрдг options рд╕реВрдЪреА рдФрд░ рдЕрдзрд┐рдХ рд╡рд┐рд╕реНрддреГрдд рд╕реНрдкрд╖реНрдЯреАрдХрд░рдг рдХреЗ рд▓рд┐рдП, рдХреГрдкрдпрд╛ рдкреВрд░реА specification рджреЗрдЦреЗрдВ:

```
usage: train.py [-h] --model_family
                {kolors,auraflow,omnigen,flux,deepfloyd,cosmos2image,sana,qwen_image,pixart_sigma,sdxl,sd1x,sd2x,wan,hidream,sd3,lumina2,ltxvideo}
                [--model_flavour MODEL_FLAVOUR] [--controlnet [CONTROLNET]]
                [--pretrained_model_name_or_path PRETRAINED_MODEL_NAME_OR_PATH]
                --output_dir OUTPUT_DIR [--logging_dir LOGGING_DIR]
                --model_type {full,lora} [--seed SEED]
                [--resolution RESOLUTION]
                [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                [--prediction_type {epsilon,v_prediction,sample,flow_matching}]
                [--pretrained_vae_model_name_or_path PRETRAINED_VAE_MODEL_NAME_OR_PATH]
                [--vae_dtype {default,fp32,fp16,bf16}]
                [--vae_cache_ondemand [VAE_CACHE_ONDEMAND]]
                [--accelerator_cache_clear_interval ACCELERATOR_CACHE_CLEAR_INTERVAL]
                [--aspect_bucket_rounding {1,2,3,4,5,6,7,8,9}]
                [--base_model_precision {no_change,int8-quanto,int4-quanto,int2-quanto,int8-torchao,nf4-bnb,int4-torchao,fp8-quanto,fp8uz-quanto,fp8-torchao}]
                [--text_encoder_1_precision {no_change,int8-quanto,int4-quanto,int2-quanto,int8-torchao,nf4-bnb,int4-torchao,fp8-quanto,fp8uz-quanto,fp8-torchao}]
                [--text_encoder_2_precision {no_change,int8-quanto,int4-quanto,int2-quanto,int8-torchao,nf4-bnb,int4-torchao,fp8-quanto,fp8uz-quanto,fp8-torchao}]
                [--text_encoder_3_precision {no_change,int8-quanto,int4-quanto,int2-quanto,int8-torchao,nf4-bnb,int4-torchao,fp8-quanto,fp8uz-quanto,fp8-torchao}]
                [--text_encoder_4_precision {no_change,int8-quanto,int4-quanto,int2-quanto,int8-torchao,nf4-bnb,int4-torchao,fp8-quanto,fp8uz-quanto,fp8-torchao}]
                [--gradient_checkpointing_interval GRADIENT_CHECKPOINTING_INTERVAL]
                [--offload_during_startup [OFFLOAD_DURING_STARTUP]]
                [--quantize_via {cpu,accelerator,pipeline}]
                [--quantization_config QUANTIZATION_CONFIG]
                [--fuse_qkv_projections [FUSE_QKV_PROJECTIONS]]
                [--control [CONTROL]]
                [--controlnet_custom_config CONTROLNET_CUSTOM_CONFIG]
                [--controlnet_model_name_or_path CONTROLNET_MODEL_NAME_OR_PATH]
                [--tread_config TREAD_CONFIG]
                [--pretrained_transformer_model_name_or_path PRETRAINED_TRANSFORMER_MODEL_NAME_OR_PATH]
                [--pretrained_transformer_subfolder PRETRAINED_TRANSFORMER_SUBFOLDER]
                [--pretrained_unet_model_name_or_path PRETRAINED_UNET_MODEL_NAME_OR_PATH]
                [--pretrained_unet_subfolder PRETRAINED_UNET_SUBFOLDER]
                [--pretrained_t5_model_name_or_path PRETRAINED_T5_MODEL_NAME_OR_PATH]
                [--pretrained_gemma_model_name_or_path PRETRAINED_GEMMA_MODEL_NAME_OR_PATH]
                [--revision REVISION] [--variant VARIANT]
                [--base_model_default_dtype {bf16,fp32}]
                [--unet_attention_slice [UNET_ATTENTION_SLICE]]
                [--num_train_epochs NUM_TRAIN_EPOCHS]
                [--max_train_steps MAX_TRAIN_STEPS]
                [--train_batch_size TRAIN_BATCH_SIZE]
                [--learning_rate LEARNING_RATE] --optimizer
                {adamw_bf16,ao-adamw8bit,ao-adamw4bit,ao-adamfp8,ao-adamwfp8,adamw_schedulefree,adamw_schedulefree+aggressive,adamw_schedulefree+no_kahan,optimi-stableadamw,optimi-adamw,optimi-lion,optimi-radam,optimi-ranger,optimi-adan,optimi-adam,optimi-sgd,soap,prodigy}
                [--optimizer_config OPTIMIZER_CONFIG]
                [--lr_scheduler {linear,sine,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}]
                [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                [--lr_warmup_steps LR_WARMUP_STEPS]
                [--checkpoints_total_limit CHECKPOINTS_TOTAL_LIMIT]
                [--gradient_checkpointing [GRADIENT_CHECKPOINTING]]
                [--train_text_encoder [TRAIN_TEXT_ENCODER]]
                [--text_encoder_lr TEXT_ENCODER_LR]
                [--lr_num_cycles LR_NUM_CYCLES] [--lr_power LR_POWER]
                [--use_soft_min_snr [USE_SOFT_MIN_SNR]] [--use_ema [USE_EMA]]
                [--ema_device {accelerator,cpu}]
                [--ema_cpu_only [EMA_CPU_ONLY]]
                [--ema_update_interval EMA_UPDATE_INTERVAL]
                [--ema_foreach_disable [EMA_FOREACH_DISABLE]]
                [--ema_decay EMA_DECAY] [--lora_rank LORA_RANK]
                [--lora_alpha LORA_ALPHA] [--lora_type {standard,lycoris}]
                [--lora_dropout LORA_DROPOUT]
                [--lora_init_type {default,gaussian,loftq,olora,pissa}]
                [--peft_lora_mode {standard,singlora}]
                [--peft_lora_target_modules PEFT_LORA_TARGET_MODULES]
                [--singlora_ramp_up_steps SINGLORA_RAMP_UP_STEPS]
                [--init_lora INIT_LORA] [--lycoris_config LYCORIS_CONFIG]
                [--init_lokr_norm INIT_LOKR_NORM]
                [--flux_lora_target {mmdit,context,context+ffs,all,all+ffs,ai-toolkit,tiny,nano,controlnet,all+ffs+embedder,all+ffs+embedder+controlnet}]
                [--use_dora [USE_DORA]]
                [--resolution_type {pixel,area,pixel_area}]
                --data_backend_config DATA_BACKEND_CONFIG
                [--caption_strategy {filename,textfile,instance_prompt,parquet}]
                [--conditioning_multidataset_sampling {combined,random}]
                [--instance_prompt INSTANCE_PROMPT]
                [--parquet_caption_column PARQUET_CAPTION_COLUMN]
                [--parquet_filename_column PARQUET_FILENAME_COLUMN]
                [--ignore_missing_files [IGNORE_MISSING_FILES]]
                [--vae_cache_scan_behaviour {recreate,sync}]
                [--vae_enable_slicing [VAE_ENABLE_SLICING]]
                [--vae_enable_tiling [VAE_ENABLE_TILING]]
                [--vae_enable_patch_conv [VAE_ENABLE_PATCH_CONV]]
                [--vae_batch_size VAE_BATCH_SIZE]
                [--caption_dropout_probability CAPTION_DROPOUT_PROBABILITY]
                [--tokenizer_max_length TOKENIZER_MAX_LENGTH]
                [--validation_step_interval VALIDATION_STEP_INTERVAL]
                [--validation_epoch_interval VALIDATION_EPOCH_INTERVAL]
                [--disable_benchmark [DISABLE_BENCHMARK]]
                [--validation_prompt VALIDATION_PROMPT]
                [--num_validation_images NUM_VALIDATION_IMAGES]
                [--num_eval_images NUM_EVAL_IMAGES]
                [--eval_steps_interval EVAL_STEPS_INTERVAL]
                [--eval_epoch_interval EVAL_EPOCH_INTERVAL]
                [--eval_timesteps EVAL_TIMESTEPS]
                [--eval_dataset_pooling [EVAL_DATASET_POOLING]]
                [--evaluation_type {none,clip}]
                [--pretrained_evaluation_model_name_or_path PRETRAINED_EVALUATION_MODEL_NAME_OR_PATH]
                [--validation_guidance VALIDATION_GUIDANCE]
                [--validation_num_inference_steps VALIDATION_NUM_INFERENCE_STEPS]
                [--validation_on_startup [VALIDATION_ON_STARTUP]]
                [--validation_using_datasets [VALIDATION_USING_DATASETS]]
                [--validation_torch_compile [VALIDATION_TORCH_COMPILE]]
                [--validation_guidance_real VALIDATION_GUIDANCE_REAL]
                [--validation_no_cfg_until_timestep VALIDATION_NO_CFG_UNTIL_TIMESTEP]
                [--validation_negative_prompt VALIDATION_NEGATIVE_PROMPT]
                [--validation_randomize [VALIDATION_RANDOMIZE]]
                [--validation_seed VALIDATION_SEED]
                [--validation_disable [VALIDATION_DISABLE]]
                [--validation_prompt_library [VALIDATION_PROMPT_LIBRARY]]
                [--user_prompt_library USER_PROMPT_LIBRARY]
                [--eval_dataset_id EVAL_DATASET_ID]
                [--validation_stitch_input_location {left,right}]
                [--validation_guidance_rescale VALIDATION_GUIDANCE_RESCALE]
                [--validation_disable_unconditional [VALIDATION_DISABLE_UNCONDITIONAL]]
                [--validation_guidance_skip_layers VALIDATION_GUIDANCE_SKIP_LAYERS]
                [--validation_guidance_skip_layers_start VALIDATION_GUIDANCE_SKIP_LAYERS_START]
                [--validation_guidance_skip_layers_stop VALIDATION_GUIDANCE_SKIP_LAYERS_STOP]
                [--validation_guidance_skip_scale VALIDATION_GUIDANCE_SKIP_SCALE]
                [--validation_lycoris_strength VALIDATION_LYCORIS_STRENGTH]
                [--validation_noise_scheduler {ddim,ddpm,euler,euler-a,unipc,dpm++,perflow}]
                [--validation_num_video_frames VALIDATION_NUM_VIDEO_FRAMES]
                [--validation_audio_only [VALIDATION_AUDIO_ONLY]]
                [--validation_resolution VALIDATION_RESOLUTION]
                [--validation_seed_source {cpu,gpu}]
                [--i_know_what_i_am_doing [I_KNOW_WHAT_I_AM_DOING]]
                [--flow_sigmoid_scale FLOW_SIGMOID_SCALE]
                [--flux_fast_schedule [FLUX_FAST_SCHEDULE]]
                [--flow_use_uniform_schedule [FLOW_USE_UNIFORM_SCHEDULE]]
                [--flow_use_beta_schedule [FLOW_USE_BETA_SCHEDULE]]
                [--flow_beta_schedule_alpha FLOW_BETA_SCHEDULE_ALPHA]
                [--flow_beta_schedule_beta FLOW_BETA_SCHEDULE_BETA]
                [--flow_schedule_shift FLOW_SCHEDULE_SHIFT]
                [--flow_schedule_auto_shift [FLOW_SCHEDULE_AUTO_SHIFT]]
                [--flux_guidance_mode {constant,random-range}]
                [--flux_attention_masked_training [FLUX_ATTENTION_MASKED_TRAINING]]
                [--flux_guidance_value FLUX_GUIDANCE_VALUE]
                [--flux_guidance_min FLUX_GUIDANCE_MIN]
                [--flux_guidance_max FLUX_GUIDANCE_MAX]
                [--t5_padding {zero,unmodified}]
                [--sd3_clip_uncond_behaviour {empty_string,zero}]
                [--sd3_t5_uncond_behaviour {empty_string,zero}]
                [--soft_min_snr_sigma_data SOFT_MIN_SNR_SIGMA_DATA]
                [--mixed_precision {no,fp16,bf16,fp8}]
                [--attention_mechanism {diffusers,xformers,flash-attn,flash-attn-2,flash-attn-3,flash-attn-3-varlen,flex,cudnn,native-efficient,native-flash,native-math,native-npu,native-xla,sla,sageattention,sageattention-int8-fp16-triton,sageattention-int8-fp16-cuda,sageattention-int8-fp8-cuda}]
                [--sageattention_usage {training,inference,training+inference}]
                [--disable_tf32 [DISABLE_TF32]]
                [--set_grads_to_none [SET_GRADS_TO_NONE]]
                [--noise_offset NOISE_OFFSET]
                [--noise_offset_probability NOISE_OFFSET_PROBABILITY]
                [--input_perturbation INPUT_PERTURBATION]
                [--input_perturbation_steps INPUT_PERTURBATION_STEPS]
                [--lr_end LR_END] [--lr_scale [LR_SCALE]]
                [--lr_scale_sqrt [LR_SCALE_SQRT]]
                [--ignore_final_epochs [IGNORE_FINAL_EPOCHS]]
                [--freeze_encoder_before FREEZE_ENCODER_BEFORE]
                [--freeze_encoder_after FREEZE_ENCODER_AFTER]
                [--freeze_encoder_strategy {before,between,after}]
                [--layer_freeze_strategy {none,bitfit}]
                [--fully_unload_text_encoder [FULLY_UNLOAD_TEXT_ENCODER]]
                [--save_text_encoder [SAVE_TEXT_ENCODER]]
                [--text_encoder_limit TEXT_ENCODER_LIMIT]
                [--prepend_instance_prompt [PREPEND_INSTANCE_PROMPT]]
                [--only_instance_prompt [ONLY_INSTANCE_PROMPT]]
                [--data_aesthetic_score DATA_AESTHETIC_SCORE]
                [--delete_unwanted_images [DELETE_UNWANTED_IMAGES]]
                [--delete_problematic_images [DELETE_PROBLEMATIC_IMAGES]]
                [--disable_bucket_pruning [DISABLE_BUCKET_PRUNING]]
                [--disable_segmented_timestep_sampling [DISABLE_SEGMENTED_TIMESTEP_SAMPLING]]
                [--preserve_data_backend_cache [PRESERVE_DATA_BACKEND_CACHE]]
                [--override_dataset_config [OVERRIDE_DATASET_CONFIG]]
                [--cache_dir CACHE_DIR] [--cache_dir_text CACHE_DIR_TEXT]
                [--cache_dir_vae CACHE_DIR_VAE]
                [--compress_disk_cache [COMPRESS_DISK_CACHE]]
                [--aspect_bucket_disable_rebuild [ASPECT_BUCKET_DISABLE_REBUILD]]
                [--keep_vae_loaded [KEEP_VAE_LOADED]]
                [--skip_file_discovery SKIP_FILE_DISCOVERY]
                [--data_backend_sampling {uniform,auto-weighting}]
                [--image_processing_batch_size IMAGE_PROCESSING_BATCH_SIZE]
                [--write_batch_size WRITE_BATCH_SIZE]
                [--read_batch_size READ_BATCH_SIZE]
                [--enable_multiprocessing [ENABLE_MULTIPROCESSING]]
                [--max_workers MAX_WORKERS]
                [--aws_max_pool_connections AWS_MAX_POOL_CONNECTIONS]
                [--torch_num_threads TORCH_NUM_THREADS]
                [--dataloader_prefetch [DATALOADER_PREFETCH]]
                [--dataloader_prefetch_qlen DATALOADER_PREFETCH_QLEN]
                [--aspect_bucket_worker_count ASPECT_BUCKET_WORKER_COUNT]
                [--aspect_bucket_alignment {8,16,24,32,64}]
                [--minimum_image_size MINIMUM_IMAGE_SIZE]
                [--maximum_image_size MAXIMUM_IMAGE_SIZE]
                [--target_downsample_size TARGET_DOWNSAMPLE_SIZE]
                [--max_upscale_threshold MAX_UPSCALE_THRESHOLD]
                [--metadata_update_interval METADATA_UPDATE_INTERVAL]
                [--debug_aspect_buckets [DEBUG_ASPECT_BUCKETS]]
                [--debug_dataset_loader [DEBUG_DATASET_LOADER]]
                [--print_filenames [PRINT_FILENAMES]]
                [--print_sampler_statistics [PRINT_SAMPLER_STATISTICS]]
                [--timestep_bias_strategy {earlier,later,range,none}]
                [--timestep_bias_begin TIMESTEP_BIAS_BEGIN]
                [--timestep_bias_end TIMESTEP_BIAS_END]
                [--timestep_bias_multiplier TIMESTEP_BIAS_MULTIPLIER]
                [--timestep_bias_portion TIMESTEP_BIAS_PORTION]
                [--training_scheduler_timestep_spacing {leading,linspace,trailing}]
                [--inference_scheduler_timestep_spacing {leading,linspace,trailing}]
                [--loss_type {l2,huber,smooth_l1}]
                [--huber_schedule {snr,exponential,constant}]
                [--huber_c HUBER_C] [--snr_gamma SNR_GAMMA]
                [--masked_loss_probability MASKED_LOSS_PROBABILITY]
                [--hidream_use_load_balancing_loss [HIDREAM_USE_LOAD_BALANCING_LOSS]]
                [--hidream_load_balancing_loss_weight HIDREAM_LOAD_BALANCING_LOSS_WEIGHT]
                [--adam_beta1 ADAM_BETA1] [--adam_beta2 ADAM_BETA2]
                [--optimizer_beta1 OPTIMIZER_BETA1]
                [--optimizer_beta2 OPTIMIZER_BETA2]
                [--optimizer_cpu_offload_method {none}]
                [--gradient_precision {unmodified,fp32}]
                [--adam_weight_decay ADAM_WEIGHT_DECAY]
                [--adam_epsilon ADAM_EPSILON] [--prodigy_steps PRODIGY_STEPS]
                [--max_grad_norm MAX_GRAD_NORM]
                [--grad_clip_method {value,norm}]
                [--optimizer_offload_gradients [OPTIMIZER_OFFLOAD_GRADIENTS]]
                [--fuse_optimizer [FUSE_OPTIMIZER]]
                [--optimizer_release_gradients [OPTIMIZER_RELEASE_GRADIENTS]]
                [--push_to_hub [PUSH_TO_HUB]]
                [--push_to_hub_background [PUSH_TO_HUB_BACKGROUND]]
                [--push_checkpoints_to_hub [PUSH_CHECKPOINTS_TO_HUB]]
                [--publishing_config PUBLISHING_CONFIG]
                [--hub_model_id HUB_MODEL_ID]
                [--model_card_private [MODEL_CARD_PRIVATE]]
                [--model_card_safe_for_work [MODEL_CARD_SAFE_FOR_WORK]]
                [--model_card_note MODEL_CARD_NOTE]
                [--modelspec_comment MODELSPEC_COMMENT]
                [--report_to {tensorboard,wandb,comet_ml,all,none}]
                [--checkpoint_step_interval CHECKPOINT_STEP_INTERVAL]
                [--checkpoint_epoch_interval CHECKPOINT_EPOCH_INTERVAL]
                [--checkpointing_rolling_steps CHECKPOINTING_ROLLING_STEPS]
                [--checkpointing_use_tempdir [CHECKPOINTING_USE_TEMPDIR]]
                [--checkpoints_rolling_total_limit CHECKPOINTS_ROLLING_TOTAL_LIMIT]
                [--tracker_run_name TRACKER_RUN_NAME]
                [--tracker_project_name TRACKER_PROJECT_NAME]
                [--tracker_image_layout {gallery,table}]
                [--enable_watermark [ENABLE_WATERMARK]]
                [--framerate FRAMERATE]
                [--seed_for_each_device [SEED_FOR_EACH_DEVICE]]
                [--snr_weight SNR_WEIGHT]
                [--rescale_betas_zero_snr [RESCALE_BETAS_ZERO_SNR]]
                [--webhook_config WEBHOOK_CONFIG]
                [--webhook_reporting_interval WEBHOOK_REPORTING_INTERVAL]
                [--distillation_method {lcm,dcm,dmd,perflow}]
                [--distillation_config DISTILLATION_CONFIG]
                [--ema_validation {none,ema_only,comparison}]
                [--local_rank LOCAL_RANK] [--ltx_train_mode {t2v,i2v}]
                [--ltx_i2v_prob LTX_I2V_PROB]
                [--ltx_partial_noise_fraction LTX_PARTIAL_NOISE_FRACTION]
                [--ltx_protect_first_frame [LTX_PROTECT_FIRST_FRAME]]
                [--offload_param_path OFFLOAD_PARAM_PATH]
                [--offset_noise [OFFSET_NOISE]]
                [--quantize_activations [QUANTIZE_ACTIVATIONS]]
                [--refiner_training [REFINER_TRAINING]]
                [--refiner_training_invert_schedule [REFINER_TRAINING_INVERT_SCHEDULE]]
                [--refiner_training_strength REFINER_TRAINING_STRENGTH]
                [--sdxl_refiner_uses_full_range [SDXL_REFINER_USES_FULL_RANGE]]
                [--sana_complex_human_instruction SANA_COMPLEX_HUMAN_INSTRUCTION]

The following SimpleTuner command-line options are available:

options:
  -h, --help            show this help message and exit
  --model_family {kolors,auraflow,omnigen,flux,deepfloyd,cosmos2image,sana,qwen_image,pixart_sigma,sdxl,sd1x,sd2x,wan,hidream,sd3,lumina2,ltxvideo}
                        The base model architecture family to train
  --model_flavour MODEL_FLAVOUR
                        Specific variant of the selected model family
  --controlnet [CONTROLNET]
                        Train ControlNet (full or LoRA) branches alongside the
                        primary network.
  --pretrained_model_name_or_path PRETRAINED_MODEL_NAME_OR_PATH
                        Optional override of the model checkpoint. Leave blank
                        to use the default path for the selected model
                        flavour.
  --output_dir OUTPUT_DIR
                        Directory where model checkpoints and logs will be
                        saved
  --logging_dir LOGGING_DIR
                        Directory for TensorBoard logs
  --model_type {full,lora}
                        Choose between full model training or LoRA adapter
                        training
  --seed SEED           Seed used for deterministic training behaviour
  --resolution RESOLUTION
                        Resolution for training images
  --resume_from_checkpoint RESUME_FROM_CHECKPOINT
                        Select checkpoint to resume training from
  --prediction_type {epsilon,v_prediction,sample,flow_matching}
                        The parameterization type for the diffusion model
  --pretrained_vae_model_name_or_path PRETRAINED_VAE_MODEL_NAME_OR_PATH
                        Path to pretrained VAE model
  --vae_dtype {default,fp32,fp16,bf16}
                        Precision for VAE encoding/decoding. Lower precision
                        saves memory.
  --vae_cache_ondemand [VAE_CACHE_ONDEMAND]
                        Process VAE latents during training instead of
                        precomputing them
  --vae_cache_disable [VAE_CACHE_DISABLE]
                        Implicitly enables on-demand caching and disables
                        writing embeddings to disk.
  --accelerator_cache_clear_interval ACCELERATOR_CACHE_CLEAR_INTERVAL
                        Clear the cache from VRAM every X steps to prevent
                        memory leaks
  --aspect_bucket_rounding {1,2,3,4,5,6,7,8,9}
                        Number of decimal places to round aspect ratios to for
                        bucket creation
  --base_model_precision {no_change,int8-quanto,int4-quanto,int2-quanto,int8-torchao,nf4-bnb,int4-torchao,fp8-quanto,fp8uz-quanto,fp8-torchao}
                        Precision for loading the base model. Lower precision
                        saves memory.
  --text_encoder_1_precision {no_change,int8-quanto,int4-quanto,int2-quanto,int8-torchao,nf4-bnb,int4-torchao,fp8-quanto,fp8uz-quanto,fp8-torchao}
                        Precision for text encoders. Lower precision saves
                        memory.
  --text_encoder_2_precision {no_change,int8-quanto,int4-quanto,int2-quanto,int8-torchao,nf4-bnb,int4-torchao,fp8-quanto,fp8uz-quanto,fp8-torchao}
                        Precision for text encoders. Lower precision saves
                        memory.
  --text_encoder_3_precision {no_change,int8-quanto,int4-quanto,int2-quanto,int8-torchao,nf4-bnb,int4-torchao,fp8-quanto,fp8uz-quanto,fp8-torchao}
                        Precision for text encoders. Lower precision saves
                        memory.
  --text_encoder_4_precision {no_change,int8-quanto,int4-quanto,int2-quanto,int8-torchao,nf4-bnb,int4-torchao,fp8-quanto,fp8uz-quanto,fp8-torchao}
                        Precision for text encoders. Lower precision saves
                        memory.
  --gradient_checkpointing_interval GRADIENT_CHECKPOINTING_INTERVAL
                        Checkpoint every N transformer blocks
  --offload_during_startup [OFFLOAD_DURING_STARTUP]
                        Offload text encoders to CPU during VAE caching
  --quantize_via {cpu,accelerator,pipeline}
                        Where to perform model quantization
  --quantization_config QUANTIZATION_CONFIG
                        JSON or file path describing Diffusers quantization
                        config for pipeline quantization
  --fuse_qkv_projections [FUSE_QKV_PROJECTIONS]
                        Enables Flash Attention 3 when supported; otherwise
                        falls back to PyTorch SDPA.
  --control [CONTROL]   Enable channel-wise control style training
  --controlnet_custom_config CONTROLNET_CUSTOM_CONFIG
                        Custom configuration for ControlNet models
  --controlnet_model_name_or_path CONTROLNET_MODEL_NAME_OR_PATH
                        Path to ControlNet model weights to preload
  --tread_config TREAD_CONFIG
                        Configuration for TREAD training method
  --pretrained_transformer_model_name_or_path PRETRAINED_TRANSFORMER_MODEL_NAME_OR_PATH
                        Path to pretrained transformer model
  --pretrained_transformer_subfolder PRETRAINED_TRANSFORMER_SUBFOLDER
                        Subfolder containing transformer model weights
  --pretrained_unet_model_name_or_path PRETRAINED_UNET_MODEL_NAME_OR_PATH
                        Path to pretrained UNet model
  --pretrained_unet_subfolder PRETRAINED_UNET_SUBFOLDER
                        Subfolder containing UNet model weights
  --pretrained_t5_model_name_or_path PRETRAINED_T5_MODEL_NAME_OR_PATH
                        Path to pretrained T5 model
  --pretrained_gemma_model_name_or_path PRETRAINED_GEMMA_MODEL_NAME_OR_PATH
                        Path to pretrained Gemma model
  --revision REVISION   Git branch/tag/commit for model version
  --variant VARIANT     Model variant (e.g., fp16, bf16)
  --base_model_default_dtype {bf16,fp32}
                        Default precision for quantized base model weights
  --unet_attention_slice [UNET_ATTENTION_SLICE]
                        Enable attention slicing for SDXL UNet
  --num_train_epochs NUM_TRAIN_EPOCHS
                        Number of times to iterate through the entire dataset
  --max_train_steps MAX_TRAIN_STEPS
                        Maximum number of training steps (0 = use epochs
                        instead)
  --train_batch_size TRAIN_BATCH_SIZE
                        Number of samples processed per forward/backward pass
                        (per device).
  --learning_rate LEARNING_RATE
                        Base learning rate for training
  --optimizer {adamw_bf16,ao-adamw8bit,ao-adamw4bit,ao-adamfp8,ao-adamwfp8,adamw_schedulefree,adamw_schedulefree+aggressive,adamw_schedulefree+no_kahan,optimi-stableadamw,optimi-adamw,optimi-lion,optimi-radam,optimi-ranger,optimi-adan,optimi-adam,optimi-sgd,soap,prodigy}
                        Optimization algorithm for training
  --optimizer_config OPTIMIZER_CONFIG
                        Comma-separated key=value pairs forwarded to the
                        selected optimizer
  --lr_scheduler {linear,sine,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}
                        How learning rate changes during training
  --gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS
                        Number of steps to accumulate gradients
  --lr_warmup_steps LR_WARMUP_STEPS
                        Number of steps to gradually increase LR from 0
  --checkpoints_total_limit CHECKPOINTS_TOTAL_LIMIT
                        Maximum number of checkpoints to keep on disk
  --gradient_checkpointing [GRADIENT_CHECKPOINTING]
                        Trade compute for memory during training
  --train_text_encoder [TRAIN_TEXT_ENCODER]
                        Also train the text encoder (CLIP) model
  --text_encoder_lr TEXT_ENCODER_LR
                        Separate learning rate for text encoder
  --lr_num_cycles LR_NUM_CYCLES
                        Number of cosine annealing cycles
  --lr_power LR_POWER   Power for polynomial decay scheduler
  --use_soft_min_snr [USE_SOFT_MIN_SNR]
                        Use soft clamping instead of hard clamping for Min-SNR
  --use_ema [USE_EMA]   Maintain an exponential moving average copy of the
                        model during training.
  --ema_device {accelerator,cpu}
                        Where to keep the EMA weights in-between updates.
  --ema_cpu_only [EMA_CPU_ONLY]
                        Keep EMA weights exclusively on CPU even when
                        ema_device would normally move them.
  --ema_update_interval EMA_UPDATE_INTERVAL
                        Update EMA weights every N optimizer steps
  --ema_foreach_disable [EMA_FOREACH_DISABLE]
                        Fallback to standard tensor ops instead of
                        torch.foreach updates.
  --ema_decay EMA_DECAY
                        Smoothing factor for EMA updates (closer to 1.0 =
                        slower drift).
  --lora_rank LORA_RANK
                        Dimension of LoRA update matrices
  --lora_alpha LORA_ALPHA
                        Scaling factor for LoRA updates
  --lora_type {standard,lycoris}
                        LoRA implementation type
  --lora_dropout LORA_DROPOUT
                        LoRA dropout randomly ignores neurons during training.
                        This can help prevent overfitting.
  --lora_init_type {default,gaussian,loftq,olora,pissa}
                        The initialization type for the LoRA model
  --peft_lora_mode {standard,singlora}
                        PEFT LoRA training mode
  --peft_lora_target_modules PEFT_LORA_TARGET_MODULES
                        JSON array (or path to a JSON file) listing PEFT
                        LoRA target module names. Overrides preset targets.
  --singlora_ramp_up_steps SINGLORA_RAMP_UP_STEPS
                        Number of ramp-up steps for SingLoRA
  --slider_lora_target [SLIDER_LORA_TARGET]
                        Route LoRA training to slider-friendly targets
                        (self-attn + conv/time embeddings). Only affects
                        standard PEFT LoRA.
  --init_lora INIT_LORA
                        Specify an existing LoRA or LyCORIS safetensors file
                        to initialize the adapter
  --lycoris_config LYCORIS_CONFIG
                        Path to LyCORIS configuration JSON file
  --init_lokr_norm INIT_LOKR_NORM
                        Perturbed normal initialization for LyCORIS LoKr
                        layers
  --flux_lora_target {mmdit,context,context+ffs,all,all+ffs,ai-toolkit,tiny,nano,controlnet,all+ffs+embedder,all+ffs+embedder+controlnet}
                        Which layers to train in Flux models
  --use_dora [USE_DORA]
                        Enable DoRA (Weight-Decomposed LoRA)
  --resolution_type {pixel,area,pixel_area}
                        How to interpret the resolution value
  --data_backend_config DATA_BACKEND_CONFIG
                        Select a saved dataset configuration (managed in
                        Datasets & Environments tabs)
  --caption_strategy {filename,textfile,instance_prompt,parquet}
                        How to load captions for images
  --conditioning_multidataset_sampling {combined,random}
                        How to sample from multiple conditioning datasets
  --instance_prompt INSTANCE_PROMPT
                        Instance prompt for training
  --parquet_caption_column PARQUET_CAPTION_COLUMN
                        Column name containing captions in parquet files
  --parquet_filename_column PARQUET_FILENAME_COLUMN
                        Column name containing image paths in parquet files
  --ignore_missing_files [IGNORE_MISSING_FILES]
                        Continue training even if some files are missing
  --vae_cache_scan_behaviour {recreate,sync}
                        How to scan VAE cache for missing files
  --vae_enable_slicing [VAE_ENABLE_SLICING]
                        Enable VAE attention slicing for memory efficiency
  --vae_enable_tiling [VAE_ENABLE_TILING]
                        Enable VAE tiling for large images
  --vae_enable_patch_conv [VAE_ENABLE_PATCH_CONV]
                        Enable patch-based 3D conv for HunyuanVideo VAE to
                        reduce peak VRAM (slight slowdown)
  --vae_batch_size VAE_BATCH_SIZE
                        Batch size for VAE encoding during caching
  --caption_dropout_probability CAPTION_DROPOUT_PROBABILITY
                        Caption dropout will randomly drop captions and, for
                        SDXL, size conditioning inputs based on this
                        probability
  --tokenizer_max_length TOKENIZER_MAX_LENGTH
                        Override the tokenizer sequence length (advanced).
  --validation_step_interval VALIDATION_STEP_INTERVAL
                        Run validation every N training steps (deprecated alias: --validation_steps)
  --validation_epoch_interval VALIDATION_EPOCH_INTERVAL
                        Run validation every N training epochs
  --disable_benchmark [DISABLE_BENCHMARK]
                        Skip generating baseline comparison images before
                        training starts
  --validation_prompt VALIDATION_PROMPT
                        Prompt to use for validation images
  --num_validation_images NUM_VALIDATION_IMAGES
                        Number of images to generate per validation
  --num_eval_images NUM_EVAL_IMAGES
                        Number of images to generate for evaluation metrics
  --eval_steps_interval EVAL_STEPS_INTERVAL
                        Run evaluation every N training steps
  --eval_epoch_interval EVAL_EPOCH_INTERVAL
                        Run evaluation every N training epochs (decimals run
                        multiple times per epoch)
  --eval_timesteps EVAL_TIMESTEPS
                        Number of timesteps for evaluation
  --eval_dataset_pooling [EVAL_DATASET_POOLING]
                        Combine evaluation metrics from all datasets into a
                        single chart
  --evaluation_type {none,clip}
                        Type of evaluation metrics to compute
  --pretrained_evaluation_model_name_or_path PRETRAINED_EVALUATION_MODEL_NAME_OR_PATH
                        Path to pretrained model for evaluation metrics
  --validation_guidance VALIDATION_GUIDANCE
                        CFG guidance scale for validation images
  --validation_num_inference_steps VALIDATION_NUM_INFERENCE_STEPS
                        Number of diffusion steps for validation renders
  --validation_on_startup [VALIDATION_ON_STARTUP]
                        Run validation on the base model before training
                        starts
  --validation_using_datasets [VALIDATION_USING_DATASETS]
                        Use random images from training datasets for
                        validation
  --validation_torch_compile [VALIDATION_TORCH_COMPILE]
                        Use torch.compile() on validation pipeline for speed
  --validation_guidance_real VALIDATION_GUIDANCE_REAL
                        CFG value for distilled models (e.g., FLUX schnell)
  --validation_no_cfg_until_timestep VALIDATION_NO_CFG_UNTIL_TIMESTEP
                        Skip CFG for initial timesteps (Flux only)
  --validation_negative_prompt VALIDATION_NEGATIVE_PROMPT
                        Negative prompt for validation images
  --validation_randomize [VALIDATION_RANDOMIZE]
                        Use random seeds for each validation
  --validation_seed VALIDATION_SEED
                        Fixed seed for reproducible validation images
  --validation_disable [VALIDATION_DISABLE]
                        Completely disable validation image generation
  --validation_prompt_library [VALIDATION_PROMPT_LIBRARY]
                        Use SimpleTuner's built-in prompt library
  --user_prompt_library USER_PROMPT_LIBRARY
                        Path to custom JSON prompt library
  --eval_dataset_id EVAL_DATASET_ID
                        Specific dataset to use for evaluation metrics
  --validation_stitch_input_location {left,right}
                        Where to place input image in img2img validations
  --validation_guidance_rescale VALIDATION_GUIDANCE_RESCALE
                        CFG rescale value for validation
  --validation_disable_unconditional [VALIDATION_DISABLE_UNCONDITIONAL]
                        Disable unconditional image generation during
                        validation
  --validation_guidance_skip_layers VALIDATION_GUIDANCE_SKIP_LAYERS
                        JSON list of transformer layers to skip during
                        classifier-free guidance
  --validation_guidance_skip_layers_start VALIDATION_GUIDANCE_SKIP_LAYERS_START
                        Starting layer index to skip guidance
  --validation_guidance_skip_layers_stop VALIDATION_GUIDANCE_SKIP_LAYERS_STOP
                        Ending layer index to skip guidance
  --validation_guidance_skip_scale VALIDATION_GUIDANCE_SKIP_SCALE
                        Scale guidance strength when applying layer skipping
  --validation_lycoris_strength VALIDATION_LYCORIS_STRENGTH
                        Strength multiplier for LyCORIS validation
  --validation_noise_scheduler {ddim,ddpm,euler,euler-a,unipc,dpm++,perflow}
                        Noise scheduler for validation
  --validation_num_video_frames VALIDATION_NUM_VIDEO_FRAMES
                        Number of frames for video validation
  --validation_audio_only [VALIDATION_AUDIO_ONLY]
                        Disable video generation during validation and emit
                        audio only
  --validation_resolution VALIDATION_RESOLUTION
                        Override resolution for validation images (pixels or
                        megapixels)
  --validation_seed_source {cpu,gpu}
                        Source device used to generate validation seeds
  --i_know_what_i_am_doing [I_KNOW_WHAT_I_AM_DOING]
                        Unlock experimental overrides and bypass built-in
                        safety limits.
  --flow_sigmoid_scale FLOW_SIGMOID_SCALE
                        Scale factor for sigmoid timestep sampling for flow-
                        matching models.
  --flux_fast_schedule [FLUX_FAST_SCHEDULE]
                        Use experimental fast schedule for Flux training
  --flow_use_uniform_schedule [FLOW_USE_UNIFORM_SCHEDULE]
                        Use uniform schedule instead of sigmoid for flow-
                        matching
  --flow_use_beta_schedule [FLOW_USE_BETA_SCHEDULE]
                        Use beta schedule instead of sigmoid for flow-matching
  --flow_beta_schedule_alpha FLOW_BETA_SCHEDULE_ALPHA
                        Alpha value for beta schedule (default: 2.0)
  --flow_beta_schedule_beta FLOW_BETA_SCHEDULE_BETA
                        Beta value for beta schedule (default: 2.0)
  --flow_schedule_shift FLOW_SCHEDULE_SHIFT
                        Shift the noise schedule for flow-matching models
  --flow_schedule_auto_shift [FLOW_SCHEDULE_AUTO_SHIFT]
                        Auto-adjust schedule shift based on image resolution
  --flux_guidance_mode {constant,random-range}
                        Guidance mode for Flux training
  --flux_attention_masked_training [FLUX_ATTENTION_MASKED_TRAINING]
                        Enable attention masked training for Flux models
  --flux_guidance_value FLUX_GUIDANCE_VALUE
                        Guidance value for constant mode
  --flux_guidance_min FLUX_GUIDANCE_MIN
                        Minimum guidance value for random-range mode
  --flux_guidance_max FLUX_GUIDANCE_MAX
                        Maximum guidance value for random-range mode
  --t5_padding {zero,unmodified}
                        Padding behavior for T5 text encoder
  --sd3_clip_uncond_behaviour {empty_string,zero}
                        How SD3 handles unconditional prompts
  --sd3_t5_uncond_behaviour {empty_string,zero}
                        How SD3 T5 handles unconditional prompts
  --soft_min_snr_sigma_data SOFT_MIN_SNR_SIGMA_DATA
                        Sigma data for soft min SNR weighting
  --mixed_precision {no,fp16,bf16,fp8}
                        Precision for training computations
  --attention_mechanism {diffusers,xformers,flash-attn,flash-attn-2,flash-attn-3,flash-attn-3-varlen,flex,cudnn,native-efficient,native-flash,native-math,native-npu,native-xla,sla,sageattention,sageattention-int8-fp16-triton,sageattention-int8-fp16-cuda,sageattention-int8-fp8-cuda}
                        Attention computation backend
  --sageattention_usage {training,inference,training+inference}
                        When to use SageAttention
  --disable_tf32 [DISABLE_TF32]
                        Force IEEE FP32 precision (disables TF32) using
                        PyTorch's fp32_precision controls when available
  --set_grads_to_none [SET_GRADS_TO_NONE]
                        Set gradients to None instead of zero
  --noise_offset NOISE_OFFSET
                        Add noise offset to training
  --noise_offset_probability NOISE_OFFSET_PROBABILITY
                        Probability of applying noise offset
  --input_perturbation INPUT_PERTURBATION
                        Add additional noise only to the inputs fed to the
                        model during training
  --input_perturbation_steps INPUT_PERTURBATION_STEPS
                        Only apply input perturbation over the first N steps
                        with linear decay
  --lr_end LR_END       A polynomial learning rate will end up at this value
                        after the specified number of warmup steps
  --lr_scale [LR_SCALE]
                        Scale the learning rate by the number of GPUs,
                        gradient accumulation steps, and batch size
  --lr_scale_sqrt [LR_SCALE_SQRT]
                        If using --lr_scale, use the square root of (number of
                        GPUs * gradient accumulation steps * batch size)
  --ignore_final_epochs [IGNORE_FINAL_EPOCHS]
                        When provided, the max epoch counter will not
                        determine the end of the training run
  --freeze_encoder_before FREEZE_ENCODER_BEFORE
                        When using 'before' strategy, we will freeze layers
                        earlier than this
  --freeze_encoder_after FREEZE_ENCODER_AFTER
                        When using 'after' strategy, we will freeze layers
                        later than this
  --freeze_encoder_strategy {before,between,after}
                        When freezing the text encoder, we can use the
                        'before', 'between', or 'after' strategy
  --layer_freeze_strategy {none,bitfit}
                        When freezing parameters, we can use the 'none' or
                        'bitfit' strategy
  --fully_unload_text_encoder [FULLY_UNLOAD_TEXT_ENCODER]
                        If set, will fully unload the text_encoder from memory
                        when not in use
  --save_text_encoder [SAVE_TEXT_ENCODER]
                        If set, will save the text encoder after training
  --text_encoder_limit TEXT_ENCODER_LIMIT
                        When training the text encoder, we want to limit how
                        long it trains for to avoid catastrophic loss
  --prepend_instance_prompt [PREPEND_INSTANCE_PROMPT]
                        When determining the captions from the filename,
                        prepend the instance prompt as an enforced keyword
  --only_instance_prompt [ONLY_INSTANCE_PROMPT]
                        Use the instance prompt instead of the caption from
                        filename
  --data_aesthetic_score DATA_AESTHETIC_SCORE
                        Since currently we do not calculate aesthetic scores
                        for data, we will statically set it to one value. This
                        is only used by the SDXL Refiner
  --delete_unwanted_images [DELETE_UNWANTED_IMAGES]
                        If set, will delete images that are not of a minimum
                        size to save on disk space for large training runs
  --delete_problematic_images [DELETE_PROBLEMATIC_IMAGES]
                        If set, any images that error out during load will be
                        removed from the underlying storage medium
  --disable_bucket_pruning [DISABLE_BUCKET_PRUNING]
                        When training on very small datasets, you might not
                        care that the batch sizes will outpace your image
                        count. Setting this option will prevent SimpleTuner
                        from deleting your bucket lists that do not meet the
                        minimum image count requirements. Use at your own
                        risk, it may end up throwing off your statistics or
                        epoch tracking
  --disable_segmented_timestep_sampling [DISABLE_SEGMENTED_TIMESTEP_SAMPLING]
                        By default, the timestep schedule is divided into
                        roughly `train_batch_size` number of segments, and
                        then each of those are sampled from separately. This
                        improves the selection distribution, but may not be
                        desired in certain training scenarios, eg. when
                        limiting the timestep selection range
  --preserve_data_backend_cache [PRESERVE_DATA_BACKEND_CACHE]
                        For very large cloud storage buckets that will never
                        change, enabling this option will prevent the trainer
                        from scanning it at startup, by preserving the cache
                        files that we generate. Be careful when using this,
                        as, switching datasets can result in the preserved
                        cache being used, which would be problematic.
                        Currently, cache is not stored in the dataset itself
                        but rather, locally. This may change in a future
                        release
  --override_dataset_config [OVERRIDE_DATASET_CONFIG]
                        When provided, the dataset's config will not be
                        checked against the live backend config
  --cache_dir CACHE_DIR
                        The directory where the downloaded models and datasets
                        will be stored
  --cache_dir_text CACHE_DIR_TEXT
                        This is the path to a local directory that will
                        contain your text embed cache
  --cache_dir_vae CACHE_DIR_VAE
                        This is the path to a local directory that will
                        contain your VAE outputs
  --compress_disk_cache [COMPRESS_DISK_CACHE]
                        If set, will gzip-compress the disk cache for Pytorch
                        files. This will save substantial disk space, but may
                        slow down the training process
  --aspect_bucket_disable_rebuild [ASPECT_BUCKET_DISABLE_REBUILD]
                        When using a randomised aspect bucket list, the VAE
                        and aspect cache are rebuilt on each epoch. With a
                        large and diverse enough dataset, rebuilding the
                        aspect list may take a long time, and this may be
                        undesirable. This option will not override
                        vae_cache_clear_each_epoch. If both options are
                        provided, only the VAE cache will be rebuilt
  --keep_vae_loaded [KEEP_VAE_LOADED]
                        If set, will keep the VAE loaded in memory. This can
                        reduce disk churn, but consumes VRAM during the
                        forward pass
  --skip_file_discovery SKIP_FILE_DISCOVERY
                        Comma-separated values of which stages to skip
                        discovery for. Skipping any stage will speed up
                        resumption, but will increase the risk of errors, as
                        missing images or incorrectly bucketed images may not
                        be caught. Valid options: aspect, vae, text, metadata
  --data_backend_sampling {uniform,auto-weighting}
                        When using multiple data backends, the sampling
                        weighting can be set to 'uniform' or 'auto-weighting'
  --image_processing_batch_size IMAGE_PROCESSING_BATCH_SIZE
                        When resizing and cropping images, we do it in
                        parallel using processes or threads. This defines how
                        many images will be read into the queue before they
                        are processed
  --write_batch_size WRITE_BATCH_SIZE
                        When using certain storage backends, it is better to
                        batch smaller writes rather than continuous
                        dispatching. In SimpleTuner, write batching is
                        currently applied during VAE caching, when many small
                        objects are written. This mostly applies to S3, but
                        some shared server filesystems may benefit as well.
                        Default: 64
  --read_batch_size READ_BATCH_SIZE
                        Used by the VAE cache to prefetch image data. This is
                        the number of images to read ahead
  --enable_multiprocessing [ENABLE_MULTIPROCESSING]
                        If set, will use processes instead of threads during
                        metadata caching operations
  --max_workers MAX_WORKERS
                        How many active threads or processes to run during VAE
                        caching
  --aws_max_pool_connections AWS_MAX_POOL_CONNECTIONS
                        When using AWS backends, the maximum number of
                        connections to keep open to the S3 bucket at a single
                        time
  --torch_num_threads TORCH_NUM_THREADS
                        The number of threads to use for PyTorch operations.
                        This is not the same as the number of workers
  --dataloader_prefetch [DATALOADER_PREFETCH]
                        When provided, the dataloader will read-ahead and
                        attempt to retrieve latents, text embeds, and other
                        metadata ahead of the time when the batch is required,
                        so that it can be immediately available
  --dataloader_prefetch_qlen DATALOADER_PREFETCH_QLEN
                        Set the number of prefetched batches
  --aspect_bucket_worker_count ASPECT_BUCKET_WORKER_COUNT
                        The number of workers to use for aspect bucketing.
                        This is a CPU-bound task, so the number of workers
                        should be set to the number of CPU threads available.
                        If you use an I/O bound backend, an even higher value
                        may make sense. Default: 12
  --aspect_bucket_alignment {8,16,24,32,64}
                        When training diffusion models, the image sizes
                        generally must align to a 64 pixel interval
  --minimum_image_size MINIMUM_IMAGE_SIZE
                        The minimum resolution for both sides of input images
  --maximum_image_size MAXIMUM_IMAGE_SIZE
                        When cropping images that are excessively large, the
                        entire scene context may be lost, eg. the crop might
                        just end up being a portion of the background. To
                        avoid this, a maximum image size may be provided,
                        which will result in very-large images being
                        downsampled before cropping them. This value uses
                        --resolution_type to determine whether it is a pixel
                        edge or megapixel value
  --target_downsample_size TARGET_DOWNSAMPLE_SIZE
                        When using --maximum_image_size, very-large images
                        exceeding that value will be downsampled to this
                        target size before cropping
  --max_upscale_threshold MAX_UPSCALE_THRESHOLD
                        Limit upscaling of small images to prevent quality
                        degradation (opt-in). When set, filters out aspect
                        buckets requiring upscaling beyond this threshold.
                        For example, 0.2 allows up to 20% upscaling. Default
                        (None) allows unlimited upscaling. Must be between 0
                        and 1.
  --metadata_update_interval METADATA_UPDATE_INTERVAL
                        When generating the aspect bucket indicies, we want to
                        save it every X seconds
  --debug_aspect_buckets [DEBUG_ASPECT_BUCKETS]
                        If set, will print excessive debugging for aspect
                        bucket operations
  --debug_dataset_loader [DEBUG_DATASET_LOADER]
                        If set, will print excessive debugging for data loader
                        operations
  --print_filenames [PRINT_FILENAMES]
                        If any image files are stopping the process eg. due to
                        corruption or truncation, this will help identify
                        which is at fault
  --print_sampler_statistics [PRINT_SAMPLER_STATISTICS]
                        If provided, will print statistics about the dataset
                        sampler. This is useful for debugging
  --timestep_bias_strategy {earlier,later,range,none}
                        Strategy for biasing timestep sampling
  --timestep_bias_begin TIMESTEP_BIAS_BEGIN
                        Beginning of timestep bias range
  --timestep_bias_end TIMESTEP_BIAS_END
                        End of timestep bias range
  --timestep_bias_multiplier TIMESTEP_BIAS_MULTIPLIER
                        Multiplier for timestep bias probability
  --timestep_bias_portion TIMESTEP_BIAS_PORTION
                        Portion of training steps to apply timestep bias
  --training_scheduler_timestep_spacing {leading,linspace,trailing}
                        Timestep spacing for training scheduler
  --inference_scheduler_timestep_spacing {leading,linspace,trailing}
                        Timestep spacing for inference scheduler
  --loss_type {l2,huber,smooth_l1}
                        Loss function for training
  --huber_schedule {snr,exponential,constant}
                        Schedule for Huber loss transition threshold
  --huber_c HUBER_C     Transition point between L2 and L1 regions for Huber
                        loss
  --snr_gamma SNR_GAMMA
                        SNR weighting gamma value (0 = disabled)
  --masked_loss_probability MASKED_LOSS_PROBABILITY
                        Probability of applying masked loss weighting per
                        batch
  --hidream_use_load_balancing_loss [HIDREAM_USE_LOAD_BALANCING_LOSS]
                        Apply experimental load balancing loss when training
                        HiDream models.
  --hidream_load_balancing_loss_weight HIDREAM_LOAD_BALANCING_LOSS_WEIGHT
                        Strength multiplier for HiDream load balancing loss.
  --adam_beta1 ADAM_BETA1
                        First moment decay rate for Adam optimizers
  --adam_beta2 ADAM_BETA2
                        Second moment decay rate for Adam optimizers
  --optimizer_beta1 OPTIMIZER_BETA1
                        First moment decay rate for optimizers
  --optimizer_beta2 OPTIMIZER_BETA2
                        Second moment decay rate for optimizers
  --optimizer_cpu_offload_method {none}
                        Method for CPU offloading optimizer states
  --gradient_precision {unmodified,fp32}
                        Precision for gradient computation
  --adam_weight_decay ADAM_WEIGHT_DECAY
                        L2 regularisation strength for Adam-family optimizers.
  --adam_epsilon ADAM_EPSILON
                        Small constant added for numerical stability.
  --prodigy_steps PRODIGY_STEPS
                        Number of steps Prodigy should spend adapting its
                        learning rate.
  --max_grad_norm MAX_GRAD_NORM
                        Gradient clipping threshold to prevent exploding
                        gradients.
  --grad_clip_method {value,norm}
                        Strategy for applying max_grad_norm during clipping.
  --optimizer_offload_gradients [OPTIMIZER_OFFLOAD_GRADIENTS]
                        Move optimizer gradients to CPU to save GPU memory.
  --fuse_optimizer [FUSE_OPTIMIZER]
                        Enable fused kernels when offloading to reduce memory
                        overhead.
  --optimizer_release_gradients [OPTIMIZER_RELEASE_GRADIENTS]
                        Free gradient tensors immediately after optimizer step
                        when using Optimi optimizers.
  --push_to_hub [PUSH_TO_HUB]
                        Automatically upload the trained model to your Hugging
                        Face Hub repository.
  --push_to_hub_background [PUSH_TO_HUB_BACKGROUND]
                        Run Hub uploads in a background worker so training is
                        not blocked while pushing.
  --push_checkpoints_to_hub [PUSH_CHECKPOINTS_TO_HUB]
                        Upload intermediate checkpoints to the same Hugging
                        Face repository during training.
  --publishing_config PUBLISHING_CONFIG
                        Optional JSON/file path describing additional
                        publishing targets (S3/Backblaze B2/Azure Blob/Dropbox).
  --hub_model_id HUB_MODEL_ID
                        If left blank, SimpleTuner derives a name from the
                        project settings when pushing to Hub.
  --model_card_private [MODEL_CARD_PRIVATE]
                        Create the Hugging Face repository as private instead
                        of public.
  --model_card_safe_for_work [MODEL_CARD_SAFE_FOR_WORK]
                        Remove the default NSFW warning from the generated
                        model card on Hugging Face Hub.
  --model_card_note MODEL_CARD_NOTE
                        Optional note that appears at the top of the generated
                        model card.
  --modelspec_comment MODELSPEC_COMMENT
                        Text embedded in safetensors file metadata as
                        modelspec.comment, visible in external model viewers.
  --report_to {tensorboard,wandb,comet_ml,all,none}
                        Where to log training metrics
  --checkpoint_step_interval CHECKPOINT_STEP_INTERVAL
                        Save model checkpoint every N steps (deprecated alias: --checkpointing_steps)
  --checkpoint_epoch_interval CHECKPOINT_EPOCH_INTERVAL
                        Save model checkpoint every N epochs
  --checkpointing_rolling_steps CHECKPOINTING_ROLLING_STEPS
                        Rolling checkpoint window size for continuous
                        checkpointing
  --checkpointing_use_tempdir [CHECKPOINTING_USE_TEMPDIR]
                        Use temporary directory for checkpoint files before
                        final save
  --checkpoints_rolling_total_limit CHECKPOINTS_ROLLING_TOTAL_LIMIT
                        Maximum number of rolling checkpoints to keep
  --tracker_run_name TRACKER_RUN_NAME
                        Name for this training run in tracking platforms
  --tracker_project_name TRACKER_PROJECT_NAME
                        Project name in tracking platforms
  --tracker_image_layout {gallery,table}
                        How validation images are displayed in trackers
  --enable_watermark [ENABLE_WATERMARK]
                        Add invisible watermark to generated images
  --framerate FRAMERATE
                        Framerate for video model training
  --seed_for_each_device [SEED_FOR_EACH_DEVICE]
                        Use a unique deterministic seed per GPU instead of
                        sharing one seed across devices.
  --snr_weight SNR_WEIGHT
                        Weight factor for SNR-based loss scaling
  --rescale_betas_zero_snr [RESCALE_BETAS_ZERO_SNR]
                        Rescale betas for zero terminal SNR
  --webhook_config WEBHOOK_CONFIG
                        Path to webhook configuration file
  --webhook_reporting_interval WEBHOOK_REPORTING_INTERVAL
                        Interval for webhook reports (seconds)
  --distillation_method {lcm,dcm,dmd,perflow}
                        Method for model distillation
  --distillation_config DISTILLATION_CONFIG
                        Path to distillation configuration file
  --ema_validation {none,ema_only,comparison}
                        Control how EMA weights are used during validation
                        runs.
  --local_rank LOCAL_RANK
                        Local rank for distributed training
  --ltx_train_mode {t2v,i2v}
                        Training mode for LTX models
  --ltx_i2v_prob LTX_I2V_PROB
                        Probability of using image-to-video training for LTX
  --ltx_partial_noise_fraction LTX_PARTIAL_NOISE_FRACTION
                        Fraction of noise to add for LTX partial training
  --ltx_protect_first_frame [LTX_PROTECT_FIRST_FRAME]
                        Protect the first frame from noise in LTX training
  --offload_param_path OFFLOAD_PARAM_PATH
                        Path to offloaded parameter files
  --offset_noise [OFFSET_NOISE]
                        Enable offset-noise training
  --quantize_activations [QUANTIZE_ACTIVATIONS]
                        Quantize model activations during training
  --refiner_training [REFINER_TRAINING]
                        Enable refiner model training mode
  --refiner_training_invert_schedule [REFINER_TRAINING_INVERT_SCHEDULE]
                        Invert the noise schedule for refiner training
  --refiner_training_strength REFINER_TRAINING_STRENGTH
                        Strength of refiner training
  --sdxl_refiner_uses_full_range [SDXL_REFINER_USES_FULL_RANGE]
                        Use full timestep range for SDXL refiner
  --sana_complex_human_instruction SANA_COMPLEX_HUMAN_INSTRUCTION
                        Complex human instruction for Sana model training
```
