# Dreambooth (entrenamiento de un solo sujeto)

## Antecedentes

El t칠rmino Dreambooth se refiere a una t칠cnica desarrollada por Google para inyectar sujetos afin치ndolos en un modelo usando un peque침o conjunto de im치genes de alta calidad ([paper](https://dreambooth.github.io)).

En el contexto del fine-tuning, Dreambooth agrega nuevas t칠cnicas para ayudar a prevenir el colapso del modelo debido a, p. ej., overfitting o artefactos.

### Im치genes de regularizaci칩n

Las im치genes de regularizaci칩n suelen ser generadas por el modelo que est치s entrenando, usando un token que se parece a tu clase.

No **tienen** que ser im치genes sint칠ticas generadas por el modelo, pero esto posiblemente tenga mejor rendimiento que usar datos reales (p. ej., fotos de personas reales).

Ejemplo: Si est치s entrenando im치genes de un sujeto masculino, tus datos de regularizaci칩n ser칤an fotos o muestras sint칠ticas generadas de sujetos masculinos aleatorios.

> 游릭 Las im치genes de regularizaci칩n pueden configurarse como un dataset separado, lo que permite mezclarlas de forma uniforme con tus datos de entrenamiento.

### Entrenamiento con token raro

Un concepto de valor dudoso del paper original era hacer una b칰squeda inversa en el vocabulario del tokenizer del modelo para encontrar una cadena "rara" con muy poco entrenamiento asociado.

Desde entonces, la idea ha evolucionado y se ha debatido, con un bando opuesto decidiendo entrenar contra el nombre de una celebridad suficientemente similar, ya que esto requiere menos c칩mputo.

> 游리 El entrenamiento con token raro est치 soportado en SimpleTuner, pero no hay una herramienta disponible para ayudarte a encontrar uno.

### P칠rdida de preservaci칩n del prior

El modelo contiene algo llamado "prior" que, en teor칤a, podr칤a preservarse durante el entrenamiento de Dreambooth. Sin embargo, en experimentos con Stable Diffusion no pareci칩 ayudar: el modelo simplemente sobreajusta su propio conocimiento.

> 游릭 ([#1031](https://github.com/bghira/SimpleTuner/issues/1031)) La p칠rdida de preservaci칩n del prior est치 soportada en SimpleTuner cuando se entrenan adaptadores LyCORIS estableciendo `is_regularisation_data` en ese dataset.

### P칠rdida enmascarada

Las m치scaras de imagen pueden definirse en pares con los datos de imagen. Las partes oscuras de la m치scara har치n que los c치lculos de p칠rdida ignoren esas partes de la imagen.

Existe un [script](/scripts/toolkit/datasets/masked_loss/generate_dataset_masks.py) para generar estas m치scaras, dado un input_dir y output_dir:

```bash
python generate_dataset_masks.py --input_dir /images/input \
                      --output_dir /images/output \
                      --text_input "person"
```

Sin embargo, esto no tiene funcionalidades avanzadas como el difuminado de padding de m치scara.

Al definir tu dataset de m치scaras:

- Cada imagen debe tener una m치scara. Usa una imagen completamente blanca si no quieres enmascarar.
- Configura `dataset_type=conditioning` en tu carpeta de datos de condicionamiento (m치scara)
- Configura `conditioning_type=mask` en tu dataset de m치scaras
- Configura `conditioning_data=` con el `id` de tu dataset de condicionamiento en tu dataset de im치genes

```json
[
    {
        "id": "dreambooth-data",
        "type": "local",
        "dataset_type": "image",
        "conditioning_data": "dreambooth-conditioning",
        "instance_data_dir": "/training/datasets/test_datasets/dreambooth",
        "cache_dir_vae": "/training/cache/vae/sdxl/dreambooth-data",
        "caption_strategy": "instanceprompt",
        "instance_prompt": "an dreambooth",
        "metadata_backend": "discovery",
        "resolution": 1024,
        "minimum_image_size": 1024,
        "maximum_image_size": 1024,
        "target_downsample_size": 1024,
        "crop": true,
        "crop_aspect": "square",
        "crop_style": "center",
        "resolution_type": "pixel_area"
    },
    {
        "id": "dreambooth-conditioning",
        "type": "local",
        "dataset_type": "conditioning",
        "instance_data_dir": "/training/datasets/test_datasets/dreambooth_mask",
        "resolution": 1024,
        "minimum_image_size": 1024,
        "maximum_image_size": 1024,
        "target_downsample_size": 1024,
        "crop": true,
        "crop_aspect": "square",
        "crop_style": "center",
        "resolution_type": "pixel_area",
        "conditioning_type": "mask"
    },
    {
        "id": "an example backend for text embeds.",
        "dataset_type": "text_embeds",
        "default": true,
        "type": "local",
        "cache_dir": "/training/cache/text/sdxl-base/masked_loss"
    }
]
```

## Setup

Seguir el [tutorial](TUTORIAL.md) es necesario antes de continuar con la configuraci칩n espec칤fica de Dreambooth.

Para ajuste de DeepFloyd, se recomienda visitar [esta p치gina](DEEPFLOYD.md) para tips espec칤ficos relacionados con la configuraci칩n de ese modelo.

### Entrenamiento con modelos cuantizados (solo LoRA/LyCORIS)

Probado en sistemas Apple y NVIDIA, Hugging Face Optimum-Quanto puede usarse para reducir la precisi칩n y los requisitos de VRAM.

Dentro de tu venv de SimpleTuner:

```bash
pip install optimum-quanto
```

Los niveles de precisi칩n disponibles dependen de tu hardware y sus capacidades.

- int2-quanto, int4-quanto, **int8-quanto** (recomendado)
- fp8-quanto, fp8-torchao (solo para CUDA >= 8.9, p. ej., 4090 o H100)
- nf4-bnb (requerido para usuarios con baja VRAM)

Dentro de tu config.json, los siguientes valores deber칤an modificarse o a침adirse:
```json
{
    "base_model_precision": "int8-quanto",
    "text_encoder_1_precision": "no_change",
    "text_encoder_2_precision": "no_change",
    "text_encoder_3_precision": "no_change"
}
```

Dentro de nuestro dataloader config `multidatabackend-dreambooth.json`, se ver치 algo as칤:

```json
[
    {
        "id": "subjectname-data-512px",
        "type": "local",
        "instance_data_dir": "/training/datasets/subjectname",
        "caption_strategy": "instanceprompt",
        "instance_prompt": "subjectname",
        "cache_dir_vae": "/training/vae_cache/subjectname",
        "repeats": 100,
        "crop": false,
        "resolution": 512,
        "resolution_type": "pixel_area",
        "minimum_image_size": 192
    },
    {
        "id": "subjectname-data-1024px",
        "type": "local",
        "instance_data_dir": "/training/datasets/subjectname",
        "caption_strategy": "instanceprompt",
        "instance_prompt": "subjectname",
        "cache_dir_vae": "/training/vae_cache/subjectname-1024px",
        "repeats": 100,
        "crop": false,
        "resolution": 1024,
        "resolution_type": "pixel_area",
        "minimum_image_size": 768
    },
    {
        "id": "regularisation-data",
        "type": "local",
        "instance_data_dir": "/training/datasets/regularisation",
        "caption_strategy": "instanceprompt",
        "instance_prompt": "a picture of a man",
        "cache_dir_vae": "/training/vae_cache/regularisation",
        "repeats": 0,
        "resolution": 512,
        "resolution_type": "pixel_area",
        "minimum_image_size": 192,
        "is_regularisation_data": true
    },
    {
        "id": "regularisation-data-1024px",
        "type": "local",
        "instance_data_dir": "/training/datasets/regularisation",
        "caption_strategy": "instanceprompt",
        "instance_prompt": "a picture of a man",
        "cache_dir_vae": "/training/vae_cache/regularisation-1024px",
        "repeats": 0,
        "resolution": 1024,
        "resolution_type": "pixel_area",
        "minimum_image_size": 768,
        "is_regularisation_data": true
    },
    {
        "id": "textembeds",
        "type": "local",
        "dataset_type": "text_embeds",
        "default": true,
        "cache_dir": "/training/text_cache/sdxl_base"
    }
]
```

Algunos valores clave se ajustaron para facilitar el entrenamiento de un solo sujeto:

- Ahora tenemos dos datasets configurados dos veces, para un total de cuatro datasets. Los datos de regularizaci칩n son opcionales y el entrenamiento puede funcionar mejor sin ellos. Puedes eliminar ese dataset de la lista si lo deseas.
- La resoluci칩n se establece en 512px y 1024px con bucketing mixto, lo que puede ayudar a mejorar la velocidad de entrenamiento y la convergencia.
- El tama침o m칤nimo de imagen se establece en 192px o 768px, lo que permitir치 escalar hacia arriba algunas im치genes peque침as, lo cual puede ser necesario para datasets con unas pocas im치genes importantes pero de baja resoluci칩n.
- `caption_strategy` ahora es `instanceprompt`, lo que significa que usaremos el valor `instance_prompt` para cada imagen en el dataset como su caption.
  - **Nota:** Usar el instance prompt es el m칠todo tradicional de entrenamiento Dreambooth, pero captions cortas pueden funcionar mejor. Si descubres que el modelo no generaliza, quiz치 valga la pena intentar usar captions.

### Consideraciones del dataset de regularizaci칩n

Para un dataset de regularizaci칩n:

- Establece `repeats` muy alto en tu sujeto Dreambooth para que el conteo de im치genes en los datos Dreambooth se multiplique `repeats` veces y supere el conteo de im치genes de tu conjunto de regularizaci칩n
  - Si tu conjunto de regularizaci칩n tiene 1000 im치genes y tienes 10 im치genes en tu conjunto de entrenamiento, querr치s un valor de repeats de al menos 100 para obtener resultados r치pidos
- `minimum_image_size` se ha incrementado para asegurar que no introducimos demasiados artefactos de baja calidad
- De manera similar, usar captions m치s descriptivos puede ayudar a evitar el olvido. Cambiar de `instanceprompt` a `textfile` u otras estrategias requerir치 crear archivos `.txt` para cada imagen.
- Cuando `is_regularisation_data` (o 游쥟릖 `is_regularization_data` con z, para usuarios estadounidenses) se establece, los datos de este conjunto se alimentar치n al modelo base para obtener una predicci칩n que pueda usarse como objetivo de p칠rdida para el modelo LyCORIS estudiante.
  - Nota: actualmente esto solo funciona con un adaptador LyCORIS.

## Seleccionar un instance prompt

Como se mencion칩 antes, el enfoque original de Dreambooth era la selecci칩n de tokens raros para entrenar.

Alternativamente, se podr칤a usar el nombre real del sujeto o el de una celebridad "suficientemente similar".

Despu칠s de varios experimentos de entrenamiento, parece que una celebridad "suficientemente similar" es la mejor opci칩n, especialmente si al pedir el nombre real de la persona el resultado se ve dis칤mil.

# Scheduled Sampling (Rollout)

Al entrenar con datasets peque침os como en Dreambooth, los modelos pueden sobreajustarse r치pidamente al ruido "perfecto" a침adido durante el entrenamiento. Esto lleva a **sesgo de exposici칩n**: el modelo aprende a denoising entradas perfectas pero falla cuando se enfrenta a sus propias salidas ligeramente imperfectas durante la inferencia.

**Scheduled Sampling (Rollout)** aborda esto permitiendo ocasionalmente que el modelo genere sus propios latentes ruidosos por unos pasos durante el bucle de entrenamiento. En lugar de entrenar con ruido gaussiano puro + se침al, entrena con muestras "rollout" que contienen los errores previos del modelo. Esto ense침a al modelo a corregirse, resultando en una generaci칩n de sujetos m치s robusta y estable.

> 游릭 Esta funci칩n es experimental pero muy recomendada para datasets peque침os donde el sobreajuste o el "frying" es com칰n.
> 丘멆잺 Habilitar rollout aumenta los requisitos de c칩mputo, ya que el modelo debe realizar pasos de inferencia extra durante el bucle de entrenamiento.

Para habilitarlo, agrega estas claves a tu `config.json`:

```json
{
  "scheduled_sampling_max_step_offset": 10,
  "scheduled_sampling_probability": 1.0,
  "scheduled_sampling_ramp_steps": 1000,
  "scheduled_sampling_sampler": "unipc"
}
```

*   `scheduled_sampling_max_step_offset`: Cu치ntos pasos generar. Un valor peque침o (p. ej., 5-10) suele ser suficiente.
*   `scheduled_sampling_probability`: Con qu칠 frecuencia aplicar esta t칠cnica (0.0 a 1.0).
*   `scheduled_sampling_ramp_steps`: Incrementa la probabilidad durante los primeros N pasos para evitar desestabilizar el entrenamiento temprano.

# Media m칩vil exponencial (EMA)

Un segundo modelo puede entrenarse en paralelo a tu checkpoint, casi gratis: solo se consume memoria del sistema (por defecto), no m치s VRAM.

Aplicar `use_ema=true` en tu archivo de configuraci칩n habilitar치 esta funci칩n.

# Seguimiento de puntuaciones CLIP

Si deseas habilitar evaluaciones para puntuar el rendimiento del modelo, consulta [este documento](evaluation/CLIP_SCORES.md) para informaci칩n sobre configuraci칩n e interpretaci칩n de puntuaciones CLIP.

# P칠rdida de evaluaci칩n estable

Si deseas usar p칠rdida MSE estable para puntuar el rendimiento del modelo, consulta [este documento](evaluation/EVAL_LOSS.md) para informaci칩n sobre configuraci칩n e interpretaci칩n de la p칠rdida de evaluaci칩n.

# Previsualizaciones de validaci칩n

SimpleTuner admite streaming de previsualizaciones intermedias de validaci칩n durante la generaci칩n usando modelos Tiny AutoEncoder. Esta funci칩n te permite ver tus im치genes de validaci칩n generadas paso a paso en tiempo real v칤a callbacks de webhook, en lugar de esperar a la generaci칩n completa.

## Habilitar previsualizaciones de validaci칩n

Para habilitar previsualizaciones de validaci칩n, a침ade lo siguiente a tu `config.json`:

```json
{
  "validation_preview": true,
  "validation_preview_steps": 1
}
```

## Requisitos

- Familia de modelos con soporte de Tiny AutoEncoder (Flux, SDXL, SD3, etc.)
- Configuraci칩n de webhook para recibir las im치genes de preview
- La validaci칩n debe estar habilitada (`validation_disable` no debe establecerse en true)

## Opciones de configuraci칩n

- `--validation_preview`: Habilita/deshabilita la funci칩n de preview (default: false)
- `--validation_preview_steps`: Controla con qu칠 frecuencia se decodifican previsualizaciones durante el muestreo (default: 1)
  - Establece 1 para recibir un preview en cada paso de muestreo
  - Establece valores m치s altos (p. ej., 3 o 5) para reducir el overhead del decodificado de Tiny AutoEncoder

## Ejemplo

Con `validation_num_inference_steps=20` y `validation_preview_steps=5`, recibir치s previsualizaciones en los pasos 5, 10, 15 y 20 durante cada generaci칩n de validaci칩n.

# Ajuste de refiner

Si eres fan del refiner de SDXL, puede que descubras que hace que tus generaciones "arruinen" los resultados de tu modelo Dreamboothed.

SimpleTuner soporta entrenar el refiner de SDXL usando LoRA y full rank.

Esto requiere un par de consideraciones:
- Las im치genes deben ser exclusivamente de alta calidad
- Los text embeds no pueden compartirse con los del modelo base
- Los VAE embeds **s칤** pueden compartirse con los del modelo base

Necesitar치s actualizar `cache_dir` en tu configuraci칩n de dataloader, `multidatabackend.json`:

```json
[
    {
        "id": "textembeds",
        "type": "local",
        "dataset_type": "text_embeds",
        "default": true,
        "cache_dir": "/training/text_cache/sdxl_refiner"
    }
]
```

Si deseas apuntar a una puntuaci칩n est칠tica espec칤fica con tus datos, puedes a침adir esto a `config/config.json`:

```bash
"--data_aesthetic_score": 5.6,
```

Actualiza **5.6** al score que quieras targetear. El default es **7.0**.

> 丘멆잺 Al entrenar el refiner de SDXL, tus prompts de validaci칩n ser치n ignorados. En su lugar, se refinar치n im치genes aleatorias de tus datasets.
