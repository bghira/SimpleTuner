# SimpleTuner üíπ

> ‚ÑπÔ∏è No se env√≠an datos a terceros salvo a trav√©s de los flags opt-in `report_to`, `push_to_hub` o webhooks que deben configurarse manualmente.

**SimpleTuner** est√° orientado a la simplicidad, con un enfoque en que el c√≥digo sea f√°cil de entender. Esta base de c√≥digo sirve como un ejercicio acad√©mico compartido y se agradecen las contribuciones.

Si quieres unirte a nuestra comunidad, nos puedes encontrar [en Discord](https://discord.gg/JGkSwEbjRb) a trav√©s de Terminus Research Group.
Si tienes alguna pregunta, no dudes en contactarnos all√≠.

<img width="1944" height="1657" alt="image" src="https://github.com/user-attachments/assets/af3a24ec-7347-4ddf-8edf-99818a246de1" />


## Tabla de contenidos

- [Filosof√≠a de dise√±o](#filosof√≠a-de-dise√±o)
- [Tutorial](#tutorial)
- [Caracter√≠sticas](#caracter√≠sticas)
  - [Caracter√≠sticas principales de entrenamiento](#caracter√≠sticas-principales-de-entrenamiento)
  - [Compatibilidad de arquitectura de modelos](#compatibilidad-de-arquitectura-de-modelos)
  - [T√©cnicas avanzadas de entrenamiento](#t√©cnicas-avanzadas-de-entrenamiento)
  - [Caracter√≠sticas espec√≠ficas del modelo](#caracter√≠sticas-espec√≠ficas-del-modelo)
  - [Gu√≠as de inicio r√°pido](#gu√≠as-de-inicio-r√°pido)
- [Requisitos de hardware](#requisitos-de-hardware)
- [Kit de herramientas](#kit-de-herramientas)
- [Instalaci√≥n](#instalaci√≥n)
- [Soluci√≥n de problemas](#soluci√≥n-de-problemas)

## Filosof√≠a de dise√±o

- **Simplicidad**: Apuntar a buenos valores predeterminados para la mayor√≠a de los casos de uso, de modo que se requiera menos ajuste.
- **Versatilidad**: Dise√±ado para manejar un amplio rango de cantidades de im√°genes, desde peque√±os datasets hasta colecciones extensas.
- **Funciones de vanguardia**: Solo incorpora funciones con eficacia comprobada, evitando agregar opciones sin probar.

## Tutorial

Por favor, explora completamente este README antes de iniciar el [nuevo tutorial de Web UI](/documentation/webui/TUTORIAL.md) o el [tutorial cl√°sico de l√≠nea de comandos](/documentation/TUTORIAL.md), ya que este documento contiene informaci√≥n vital que podr√≠as necesitar primero.

Para un inicio r√°pido configurado manualmente sin leer toda la documentaci√≥n ni usar interfaces web, puedes usar la gu√≠a de [Quick Start](/documentation/QUICKSTART.md).

Para sistemas con memoria limitada, consulta el [documento de DeepSpeed](/documentation/DEEPSPEED.md), que explica c√≥mo usar ü§óAccelerate para configurar DeepSpeed de Microsoft para el offload del estado del optimizador. Para sharding basado en DTensor y paralelismo de contexto, lee la [gu√≠a de FSDP2](/documentation/FSDP2.md), que cubre el nuevo flujo FullyShardedDataParallel v2 dentro de SimpleTuner.

Para entrenamiento distribuido multi-nodo, [esta gu√≠a](/documentation/DISTRIBUTED.md) ayudar√° a ajustar las configuraciones de las gu√≠as INSTALL y Quickstart para que sean adecuadas para entrenamiento multi-nodo y optimizadas para datasets de im√°genes con miles de millones de muestras.

---

## Caracter√≠sticas

SimpleTuner ofrece soporte de entrenamiento integral en m√∫ltiples arquitecturas de modelos de difusi√≥n con disponibilidad consistente de funciones:

### Caracter√≠sticas principales de entrenamiento

- **Web UI f√°cil de usar** - Gestiona todo el ciclo de vida de entrenamiento desde un panel moderno
- **Entrenamiento multimodal** - Pipeline unificado para modelos generativos de **Imagen, Video y Audio**
- **Entrenamiento multi-GPU** - Entrenamiento distribuido en m√∫ltiples GPUs con optimizaci√≥n autom√°tica
- **Cach√© avanzada** - Embeddings de imagen, video, audio y captions en cach√© en disco para entrenamientos m√°s r√°pidos
- **Aspect bucketing** - Soporte para tama√±os y relaciones de aspecto variadas en imagen/video
- **Concept sliders** - Targeting compatible con sliders para LoRA/LyCORIS/full (v√≠a LyCORIS `full`) con muestreo positivo/negativo/neutral y fuerza por prompt; ver la [gu√≠a de Slider LoRA](/documentation/SLIDER_LORA.md)
- **Optimizaci√≥n de memoria** - La mayor√≠a de los modelos entrenables en GPU de 24G, muchos en 16G con optimizaciones
- **Integraci√≥n con DeepSpeed y FSDP2** - Entrena modelos grandes en GPUs m√°s peque√±as con sharding de optim/grad/param, atenci√≥n paralela de contexto, gradient checkpointing y offload del estado del optimizador
- **Entrenamiento en S3** - Entrena directamente desde almacenamiento en la nube (Cloudflare R2, Wasabi S3)
- **Soporte EMA** - Pesos de media m√≥vil exponencial para mayor estabilidad y calidad
- **Trackers de experimentos personalizados** - Coloca un `accelerate.GeneralTracker` en `simpletuner/custom-trackers` y usa `--report_to=custom-tracker --custom_tracker=<name>`

### Funciones multiusuario y empresariales

SimpleTuner incluye una plataforma completa de entrenamiento multiusuario con funciones de nivel empresarial - **gratuita y de c√≥digo abierto, para siempre**.

- **Orquestaci√≥n de workers** - Registra workers de GPU distribuidos que se conectan autom√°ticamente a un panel central y reciben trabajos v√≠a SSE; soporta workers ef√≠meros (lanzados en la nube) y persistentes (siempre activos); ver la [Gu√≠a de orquestaci√≥n de workers](/documentation/experimental/server/WORKERS.md)
- **Integraci√≥n SSO** - Autenticaci√≥n con LDAP/Active Directory u OIDC (Okta, Azure AD, Keycloak, Google); ver la [Gu√≠a de autenticaci√≥n externa](/documentation/experimental/server/EXTERNAL_AUTH.md)
- **Control de acceso basado en roles** - Cuatro roles por defecto (Viewer, Researcher, Lead, Admin) con 17+ permisos granulares; define reglas de recursos con patrones glob para restringir configs, hardware o proveedores por equipo
- **Organizaciones y equipos** - Estructura multi-tenant jer√°rquica con cuotas basadas en topes; los l√≠mites de org definen m√°ximos absolutos, los de equipo operan dentro de los l√≠mites de la org
- **Cuotas y l√≠mites de gasto** - Aplica topes de costo (diario/mensual), l√≠mites de concurrencia de trabajos y l√≠mites de tasa de env√≠o a nivel de org, equipo o usuario; acciones: bloquear, advertir o requerir aprobaci√≥n
- **Cola de trabajos con prioridades** - Cinco niveles de prioridad (Low ‚Üí Critical) con planificaci√≥n de fair-share entre equipos, prevenci√≥n de starvation para trabajos con esperas largas y overrides de prioridad de admin
- **Flujos de aprobaci√≥n** - Reglas configurables disparan aprobaciones para trabajos que exceden umbrales de costo, usuarios nuevos o solicitudes de hardware espec√≠ficas; aprueba v√≠a UI, API o respuesta por email
- **Notificaciones por email** - Integraci√≥n SMTP/IMAP para estado de trabajos, solicitudes de aprobaci√≥n, alertas de cuota y notificaciones de finalizaci√≥n
- **API keys y permisos con alcance** - Genera API keys con expiraci√≥n y alcance limitado para pipelines CI/CD
- **Audit logging** - Registra todas las acciones de usuarios con verificaci√≥n de cadena para cumplimiento; ver la [Gu√≠a de auditor√≠a](/documentation/experimental/server/AUDIT.md)

Para detalles de despliegue, consulta la [Gu√≠a Enterprise](/documentation/experimental/server/ENTERPRISE.md).

### Compatibilidad de arquitectura de modelos

| Modelo | Par√°metros | PEFT LoRA | Lycoris | Full-Rank | ControlNet | Cuantizaci√≥n | Flow Matching | Codificadores de texto |
|--------|------------|-----------|---------|-----------|------------|--------------|---------------|------------------------|
| **Stable Diffusion XL** | 3.5B | ‚úì | ‚úì | ‚úì | ‚úì | int8/nf4 | ‚úó | CLIP-L/G |
| **Stable Diffusion 3** | 2B-8B | ‚úì | ‚úì | ‚úì* | ‚úì | int8/fp8/nf4 | ‚úì | CLIP-L/G + T5-XXL |
| **Flux.1** | 12B | ‚úì | ‚úì | ‚úì* | ‚úì | int8/fp8/nf4 | ‚úì | CLIP-L + T5-XXL |
| **Flux.2** | 32B | ‚úì | ‚úì | ‚úì* | ‚úó | int8/fp8/nf4 | ‚úì | Mistral-3 Small |
| **ACE-Step** | 3.5B | ‚úì | ‚úì | ‚úì* | ‚úó | int8 | ‚úì | UMT5 |
| **HeartMuLa** | 3B | ‚úì | ‚úì | ‚úì* | ‚úó | int8 | ‚úó | Ninguno |
| **Chroma 1** | 8.9B | ‚úì | ‚úì | ‚úì* | ‚úó | int8/fp8/nf4 | ‚úì | T5-XXL |
| **Auraflow** | 6.8B | ‚úì | ‚úì | ‚úì* | ‚úì | int8/fp8/nf4 | ‚úì | UMT5-XXL |
| **PixArt Sigma** | 0.6B-0.9B | ‚úó | ‚úì | ‚úì | ‚úì | int8 | ‚úó | T5-XXL |
| **Sana** | 0.6B-4.8B | ‚úó | ‚úì | ‚úì | ‚úó | int8 | ‚úì | Gemma2-2B |
| **Lumina2** | 2B | ‚úì | ‚úì | ‚úì | ‚úó | int8 | ‚úì | Gemma2 |
| **Kwai Kolors** | 5B | ‚úì | ‚úì | ‚úì | ‚úó | ‚úó | ‚úó | ChatGLM-6B |
| **LTX Video** | 5B | ‚úì | ‚úì | ‚úì | ‚úó | int8/fp8 | ‚úì | T5-XXL |
| **LTX Video 2** | 19B | ‚úì | ‚úì | ‚úì* | ‚úó | int8/fp8 | ‚úì | Gemma3 |
| **Wan Video** | 1.3B-14B | ‚úì | ‚úì | ‚úì* | ‚úó | int8 | ‚úì | UMT5 |
| **HiDream** | 17B (8.5B MoE) | ‚úì | ‚úì | ‚úì* | ‚úì | int8/fp8/nf4 | ‚úì | CLIP-L + T5-XXL + Llama |
| **Cosmos2** | 2B-14B | ‚úó | ‚úì | ‚úì | ‚úó | int8 | ‚úì | T5-XXL |
| **OmniGen** | 3.8B | ‚úì | ‚úì | ‚úì | ‚úó | int8/fp8 | ‚úì | T5-XXL |
| **Qwen Image** | 20B | ‚úì | ‚úì | ‚úì* | ‚úó | int8/nf4 (req.) | ‚úì | T5-XXL |
| **SD 1.x/2.x (Legacy)** | 0.9B | ‚úì | ‚úì | ‚úì | ‚úì | int8/nf4 | ‚úó | CLIP-L |

*‚úì = Compatible, ‚úó = No compatible, * = Requiere DeepSpeed para entrenamiento full-rank*

### T√©cnicas avanzadas de entrenamiento

- **TREAD** - Dropout por token para modelos transformer, incluido el entrenamiento de Kontext
- **Entrenamiento con p√©rdida enmascarada** - Mejor convergencia con gu√≠a de segmentaci√≥n/profundidad
- **Regularizaci√≥n de prior** - Mayor estabilidad de entrenamiento para consistencia de personajes
- **Gradient checkpointing** - Intervalos configurables para optimizaci√≥n de memoria/velocidad
- **Funciones de p√©rdida** - L2, Huber, Smooth L1 con soporte de scheduling
- **Ponderaci√≥n SNR** - Ponderaci√≥n Min-SNR gamma para mejorar la din√°mica de entrenamiento
- **Group offloading** - Staging de m√≥dulos por grupo a CPU/disco en Diffusers v0.33+ con streams CUDA opcionales
- **Barridos de adaptadores de validaci√≥n** - Adjunta temporalmente adaptadores LoRA (individuales o presets JSON) durante la validaci√≥n para medir renders solo de adaptador o comparativos sin tocar el training loop
- **Hooks de validaci√≥n externos** - Sustituye el pipeline de validaci√≥n integrado o los pasos post-upload por tus scripts, para ejecutar checks en otra GPU o reenviar artefactos a cualquier proveedor cloud que elijas ([detalles](/documentation/OPTIONS.md#validation_method))
- **Regularizaci√≥n CREPA** - Alineaci√≥n de representaci√≥n entre frames para video DiTs ([gu√≠a](/documentation/experimental/VIDEO_CREPA.md))
- **Formatos de I/O de LoRA** - Carga/guarda LoRAs PEFT en layout est√°ndar de Diffusers o claves estilo ComfyUI `diffusion_model.*` (Flux/Flux2/Lumina2/Z-Image detectan autom√°ticamente entradas ComfyUI)

### Caracter√≠sticas espec√≠ficas del modelo

- **Flux Kontext** - Conditioning de edici√≥n y entrenamiento image-to-image para modelos Flux
- **PixArt two-stage** - Soporte de pipeline eDiff para PixArt Sigma
- **Modelos de flow matching** - Scheduling avanzado con distribuciones beta/uniforme
- **HiDream MoE** - Aumento de p√©rdida de puerta Mixture of Experts
- **Entrenamiento con T5 enmascarado** - Mayor detalle fino para Flux y modelos compatibles
- **Fusi√≥n QKV** - Optimizaciones de memoria y velocidad (Flux, Lumina2)
- **Integraci√≥n TREAD** - Enrutamiento selectivo de tokens para la mayor√≠a de modelos
- **Wan 2.x I2V** - Presets de etapa alta/baja m√°s un fallback de time-embedding 2.1 (ver quickstart de Wan)
- **Classifier-free guidance** - Reintroducci√≥n opcional de CFG para modelos destilados

### Gu√≠as de inicio r√°pido

Hay gu√≠as detalladas de inicio r√°pido disponibles para todos los modelos soportados:

- **[Gu√≠a de TwinFlow Few-Step (RCGM)](/documentation/distillation/TWINFLOW.md)** - Habilita p√©rdida auxiliar RCGM para generaci√≥n de pocos pasos/un paso (modelos de flow o difusi√≥n v√≠a diff2flow)
- **[Gu√≠a de Flux.1](/documentation/quickstart/FLUX.md)** - Incluye soporte de edici√≥n Kontext y fusi√≥n QKV
- **[Gu√≠a de Flux.2](/documentation/quickstart/FLUX2.md)** - **NUEVO**. √öltimo y enorme modelo Flux con codificador de texto Mistral-3
- **[Gu√≠a de Z-Image](/documentation/quickstart/ZIMAGE.md)** - LoRA Base/Turbo con adaptador asistente + aceleraci√≥n TREAD
- **[Gu√≠a de ACE-Step](/documentation/quickstart/ACE_STEP.md)** - **NUEVO**. Entrenamiento de modelo de generaci√≥n de audio (text-to-music)
- **[Gu√≠a de HeartMuLa](/documentation/quickstart/HEARTMULA.md)** - **NUEVO**. Entrenamiento de modelo de audio autoregresivo (text-to-audio)
- **[Gu√≠a de Chroma](/documentation/quickstart/CHROMA.md)** - Transformer de flow-matching de Lodestone con schedules espec√≠ficos de Chroma
- **[Gu√≠a de Stable Diffusion 3](/documentation/quickstart/SD3.md)** - Entrenamiento full y LoRA con ControlNet
- **[Gu√≠a de Stable Diffusion XL](/documentation/quickstart/SDXL.md)** - Pipeline completo de entrenamiento SDXL
- **[Gu√≠a de Auraflow](/documentation/quickstart/AURAFLOW.md)** - Entrenamiento de modelos de flow-matching
- **[Gu√≠a de PixArt Sigma](/documentation/quickstart/SIGMA.md)** - Modelo DiT con soporte de dos etapas
- **[Gu√≠a de Sana](/documentation/quickstart/SANA.md)** - Modelo ligero de flow-matching
- **[Gu√≠a de Lumina2](/documentation/quickstart/LUMINA2.md)** - Modelo de flow-matching de 2B par√°metros
- **[Gu√≠a de Kwai Kolors](/documentation/quickstart/KOLORS.md)** - Basado en SDXL con encoder ChatGLM
- **[Gu√≠a de LongCat-Video](/documentation/quickstart/LONGCAT_VIDEO.md)** - Flow-matching text-to-video e image-to-video con Qwen-2.5-VL
- **[Gu√≠a de LongCat-Video Edit](/documentation/quickstart/LONGCAT_VIDEO_EDIT.md)** - Variante de conditioning-first (image-to-video)
- **[Gu√≠a de LongCat-Image](/documentation/quickstart/LONGCAT_IMAGE.md)** - Modelo biling√ºe de flow-matching 6B con encoder Qwen-2.5-VL
- **[Gu√≠a de LongCat-Image Edit](/documentation/quickstart/LONGCAT_EDIT.md)** - Variante de edici√≥n de imagen que requiere latents de referencia
- **[Gu√≠a de LTX Video](/documentation/quickstart/LTXVIDEO.md)** - Entrenamiento de difusi√≥n de video
- **[Gu√≠a de Hunyuan Video 1.5](/documentation/quickstart/HUNYUANVIDEO.md)** - Flow-matching T2V/I2V de 8.3B con etapas de SR
- **[Gu√≠a de Wan Video](/documentation/quickstart/WAN.md)** - Flow-matching de video con soporte TREAD
- **[Gu√≠a de HiDream](/documentation/quickstart/HIDREAM.md)** - Modelo MoE con funciones avanzadas
- **[Gu√≠a de Cosmos2](/documentation/quickstart/COSMOS2IMAGE.md)** - Generaci√≥n de imagen multimodal
- **[Gu√≠a de OmniGen](/documentation/quickstart/OMNIGEN.md)** - Modelo unificado de generaci√≥n de imagen
- **[Gu√≠a de Qwen Image](/documentation/quickstart/QWEN_IMAGE.md)** - Entrenamiento a gran escala de 20B par√°metros
- **[Gu√≠a de Stable Cascade Stage C](/quickstart/STABLE_CASCADE_C.md)** - LoRAs de prior con validaci√≥n combinada prior+decoder
- **[Gu√≠a de Kandinsky 5.0 Image](/documentation/quickstart/KANDINSKY5_IMAGE.md)** - Generaci√≥n de imagen con Qwen2.5-VL + Flux VAE
- **[Gu√≠a de Kandinsky 5.0 Video](/documentation/quickstart/KANDINSKY5_VIDEO.md)** - Generaci√≥n de video con HunyuanVideo VAE

---

## Requisitos de hardware

### Requisitos generales

- **NVIDIA**: RTX 3080+ recomendado (probado hasta H200)
- **AMD**: 7900 XTX 24GB y MI300X verificados (uso de memoria m√°s alto que NVIDIA)
- **Apple**: M3 Max+ con 24GB+ de memoria unificada para entrenamiento LoRA

### Gu√≠as de memoria por tama√±o de modelo

- **Modelos grandes (12B+)**: A100-80G para full-rank, 24G+ para LoRA/Lycoris
- **Modelos medianos (2B-8B)**: 16G+ para LoRA, 40G+ para entrenamiento full-rank
- **Modelos peque√±os (<2B)**: 12G+ suficiente para la mayor√≠a de tipos de entrenamiento

**Nota**: La cuantizaci√≥n (int8/fp8/nf4) reduce significativamente los requisitos de memoria. Consulta las [gu√≠as de inicio r√°pido](#gu√≠as-de-inicio-r√°pido) para requisitos espec√≠ficos por modelo.

## Instalaci√≥n

SimpleTuner se puede instalar v√≠a pip para la mayor√≠a de los usuarios:

```bash
# Base installation (CPU-only PyTorch)
pip install simpletuner

# CUDA users (NVIDIA GPUs)
pip install 'simpletuner[cuda]'

# ROCm users (AMD GPUs)
pip install 'simpletuner[rocm]'

# Apple Silicon users (M1/M2/M3/M4 Macs)
pip install 'simpletuner[apple]'
```

Para instalaci√≥n manual o setup de desarrollo, consulta la [documentaci√≥n de instalaci√≥n](/documentation/INSTALL.md).

## Soluci√≥n de problemas

Habilita logs de depuraci√≥n para m√°s detalle agregando `export SIMPLETUNER_LOG_LEVEL=DEBUG` a tu archivo de entorno (`config/config.env`).

Para an√°lisis de rendimiento del loop de entrenamiento, configurar `SIMPLETUNER_TRAINING_LOOP_LOG_LEVEL=DEBUG` agrega marcas de tiempo que destacan problemas en tu configuraci√≥n.

Para una lista completa de opciones disponibles, consulta [esta documentaci√≥n](/documentation/OPTIONS.md).
